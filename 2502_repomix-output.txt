This file is a merged representation of the entire codebase, combined into a single document by Repomix.

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded

Additional Info:
----------------

================================================================
Directory Structure
================================================================
.env.example
.gitignore
examples/inference.md
langgraph.json
pyproject.toml
README.md
src/open_deep_research/__init__.py
src/open_deep_research/configuration.py
src/open_deep_research/graph.ipynb
src/open_deep_research/graph.py
src/open_deep_research/prompts.py
src/open_deep_research/state.py
src/open_deep_research/utils.py

================================================================
Files
================================================================

================
File: .env.example
================
OPENAI_API_KEY=sk-xxx
ANTHROPIC_API_KEY=sk-xxx
TAVILY_API_KEY=xxx
GROQ_API_KEY=xxx
PERPLEXITY_API_KEY=xxx

================
File: .gitignore
================
.env
.langgraph_api
/open_deep_research.egg-info/
__pycache__/
*.py[cod]

================
File: examples/inference.md
================
# AI Inference Market and Key Players Overview

The AI inference market is experiencing explosive growth, projected to expand from $24.6 billion in 2024 to $133.2 billion by 2034. This transformation is being driven by innovative companies developing breakthrough optimization technologies that dramatically improve performance while reducing costs. Among these pioneers, Fireworks AI has demonstrated enterprise-grade reliability by processing 140 billion tokens daily, while Together.ai has achieved 4x faster decoding throughput than traditional solutions. Groq's Language Processing Unit (LPU) has emerged as a particularly disruptive force, offering competitive pricing from $0.05 to $0.99 per million tokens while securing a $2.8 billion valuation.

## Key Players Comparison

| Feature | Fireworks AI | Together.ai | Groq |
|---------|-------------|-------------|------|
| Daily Processing | 140B tokens | 400 tokens/sec | Not disclosed |
| Pricing Range | $0.10-$1.20/M tokens | Custom pricing | $0.05-$0.99/M tokens |
| Key Innovation | Parameter-based pricing | FlashAttention-3 | Language Processing Unit |
| Enterprise Users | Uber, DoorDash | Salesforce, Washington Post | Hunch AI, aiXplain |
| Valuation | $552M | $100M ARR | $2.8B |

These players are reshaping the inference landscape through distinct approaches to optimization and pricing, with each targeting different segments of the rapidly expanding market. Their continued innovation suggests further disruption in the AI infrastructure space.

## Global AI Inference Market Analysis

**The AI inference market is projected to grow from $24.6 billion in 2024 to $133.2 billion by 2034, driven by breakthrough optimization technologies that are dramatically improving performance while reducing costs.** Cloud deployment currently dominates with 55% market share, though on-premises solutions are gaining traction for latency-sensitive and security-focused applications.

NVIDIA maintains market leadership with approximately 80% share of AI chips, while competitors like AMD, Intel, and cloud providers are investing heavily in specialized inference solutions. Recent advances in speculative decoding and compilation techniques have enabled up to 2x higher throughput at 50% lower costs for popular models like Llama and Mixtral.

Key barriers to adoption include:
- High infrastructure costs and unclear ROI
- Data quality and quantity challenges
- Integration complexity with existing systems
- Skills gaps in AI/ML expertise
- Privacy and regulatory concerns

North America leads regional adoption with 38% market share, particularly in financial services and healthcare verticals. Microsoft's implementation of NVIDIA inference solutions for Copilot demonstrates the technology's enterprise readiness.

### Sources
- Restack AI Hardware Analysis 2024: https://www.restack.io/p/hardware-innovations-for-ai-technologies-answer-leading-ai-hardware-companies-2024
- NVIDIA Developer Blog: https://developer.nvidia.com/blog/optimize-ai-inference-performance-with-nvidia-full-stack-solutions/
- Market.us AI Inference Report: https://scoop.market.us/ai-inference-server-market-news/

## Fireworks AI Technical Analysis

**Fireworks AI combines an innovative pricing model with proven enterprise performance, demonstrated by processing 140 billion tokens daily with 99.99% API uptime across 12,000 users.** Their tiered pricing structure scales with usage, starting at $0.10 per million tokens for small models and reaching $1.20 per million tokens for large MoE architectures.

The platform offers specialized pricing for different modalities:
- Text generation with parameter-based pricing ($0.10-$1.20/M tokens)
- Image generation at $0.00013 per step
- Speech-to-text processing from $0.0009 per audio minute
- On-demand GPU deployments ranging from $2.90 to $9.99 per hour

A notable implementation at Sourcegraph showcases the platform's capabilities, where StarCoder deployment doubled code completion acceptance rates while cutting backend latency by 50%. The company's recent $52M Series B funding values it at $552M, with Forbes estimating 2023 revenue at $3M.

Enterprise customers including Uber, DoorDash, and Upwork have adopted Fireworks AI's infrastructure, citing lower costs and reduced latency compared to alternatives. The platform's spending limits increase with usage history, from $50/month to custom enterprise tiers exceeding $50,000/month.

### Sources
- Fireworks AI Blog Spring Update: https://fireworks.ai/blog/spring-update-faster-models-dedicated-deployments-postpaid-pricing
- AWS Case Study: https://aws.amazon.com/solutions/case-studies/fireworks-ai-case-study/
- Funding News: https://www.pymnts.com/news/investment-tracker/2024/fireworks-ai-valued-552-million-dollars-after-new-funding-round/

## Together.ai's Inference Stack Analysis

**Together.ai has revolutionized LLM inference by achieving 4x faster decoding throughput than open-source vLLM through an integrated approach combining hardware optimization and algorithmic innovations.** Their Inference Engine 2.0 demonstrates superior performance by processing over 400 tokens per second on Meta's Llama 3 8B model.

The technical foundation relies on four key innovations:
- FlashAttention-3 optimization achieving 75% GPU utilization
- Custom-built draft models trained beyond 10x Chinchilla optimal
- Advanced speculative decoding combining Medusa and Sequoia techniques
- Quality-preserving quantization matching FP16 precision

A notable case study demonstrates their efficiency at scale: using just two A100 GPUs, Together Lite outperforms vLLM running on eight H100 GPUs by 30% in common inference scenarios. This translates to a 12x cost reduction compared to standard deployments.

The Enterprise Platform builds on these innovations while maintaining SOC 2, GDPR, and HIPAA compliance. Major enterprises including Salesforce and The Washington Post have validated its performance in production environments, contributing to Together.ai reaching $100M ARR within 10 months of launch.

### Sources
- Together Inference Engine 2.0 Announcement: https://www.together.ai/blog/together-inference-engine-2
- Enterprise Platform Security: https://www.togetherplatform.com/security-compliance
- Speculative Decoding Implementation: https://www.together.ai/blog/speculative-decoding-for-high-throughput-long-context-inference

## Groq's Inference Engine Performance and Market Traction

**Groq's Language Processing Unit (LPU) has demonstrated unprecedented inference speeds while achieving significant market validation, with an estimated $3.4 million revenue in 2023 and a $2.8 billion valuation following their August 2024 Series D round.**

The LPU's competitive pricing structure ranges from $0.05 to $0.99 per million tokens, depending on model size and input/output requirements. For example, their Llama 3.3 70B implementation charges $0.59 per million input tokens and $0.79 per million output tokens, positioning them favorably against cloud competitors.

Developer adoption has been robust, with notable implementations including:
- Hunch AI Workspace for rapid prototyping
- aiXplain's real-time inference solutions
- Argonne National Laboratory's research applications
- Embodied's Moxie education robot

The platform offers an OpenAI-compatible API supporting multiple models including Llama 3.3, Mixtral 8x7b, and Gemma 2. Integration options include LangChain compatibility and Retrieval Augmented Generation capabilities, enabling developers to incorporate proprietary data into their applications.

### Sources
- Sacra Company Analysis: https://sacra.com/c/groq/
- Groq Pricing Documentation: https://groq.com/pricing/
- ChipStrat Analysis: https://www.chipstrat.com/p/the-rise-of-groq-slow-then-fast
- Groq API Documentation: https://distilabel.argilla.io/1.2.1/api/llm/groq/

## Market and Provider Analysis Summary

The AI inference market is experiencing rapid growth, projected to reach $133.2 billion by 2034, with cloud deployment currently dominating at 55% market share. Among emerging providers, Fireworks AI, Together.ai, and Groq demonstrate distinct competitive advantages in performance and pricing strategies.

| Provider | Key Differentiator | Performance Metric | Revenue/Valuation |
|----------|-------------------|-------------------|-------------------|
| Fireworks AI | Enterprise-grade reliability | 140B tokens/day, 99.99% uptime | $3M (2023), $552M valuation |
| Together.ai | Advanced optimization stack | 4x faster than vLLM, 400 tokens/sec | $100M ARR |
| Groq | Custom LPU architecture | Industry-leading latency | $3.4M (2023), $2.8B valuation |

These providers are addressing key market barriers through innovative pricing models, ranging from $0.05 to $1.20 per million tokens, while delivering specialized solutions for different modalities and use cases. Their success in attracting major enterprise customers suggests growing market maturity, though NVIDIA's 80% chip market share indicates continued infrastructure dependencies.

================
File: langgraph.json
================
{
    "dockerfile_lines": [],
    "graphs": {
      "open_deep_research": "./src/open_deep_research/graph.py:graph"
    },
    "python_version": "3.11",
    "env": "./.env",
    "dependencies": [
      "."
    ]
  }

================
File: pyproject.toml
================
[project]
name = "open_deep_research"
version = "0.0.5"
description = "Planning, research, and report generation."
authors = [
    { name = "Lance Martin" }
]
readme = "README.md"
license = { text = "MIT" }
requires-python = ">=3.9" 
dependencies = [
    "langgraph>=0.2.55",
    "langchain-community>=0.3.9",
    "langchain-openai>=0.3.5",
    "langchain-anthropic>=0.3.8",
    "openai>=1.61.0",
    "tavily-python>=0.5.0",
    "langchain-groq>=0.2.4",
]

[project.optional-dependencies]
dev = ["mypy>=1.11.1", "ruff>=0.6.1"]

[build-system]
requires = ["setuptools>=73.0.0", "wheel"]
build-backend = "setuptools.build_meta"

[tool.setuptools]
packages = ["open_deep_research"]

[tool.setuptools.package-dir]
"open_deep_research" = "src/open_deep_research"

[tool.setuptools.package-data]
"*" = ["py.typed"]

[tool.ruff]
lint.select = [
    "E",    # pycodestyle
    "F",    # pyflakes
    "I",    # isort
    "D",    # pydocstyle
    "D401", # First line should be in imperative mood
    "T201",
    "UP",
]
lint.ignore = [
    "UP006",
    "UP007",
    "UP035",
    "D417",
    "E501",
]

[tool.ruff.lint.per-file-ignores]
"tests/*" = ["D", "UP"]

[tool.ruff.lint.pydocstyle]
convention = "google"

================
File: README.md
================
# Open Deep Research
 
Open Deep Research is a web research assistant that generates comprehensive reports on any topic following a workflow similar to [OpenAI](https://openai.com/index/introducing-deep-research/) and [Gemini](https://blog.google/products/gemini/google-gemini-deep-research/) Deep Research. However, it allows you to customize the models, prompts, report structure, search API, and research depth. Specifically, you can customize:

- provide an outline with a desired report structure
- set the planner model (e.g., DeepSeek, OpenAI reasoning model, etc)
- give feedback on the plan of report sections and iterate until user approval 
- set the search API (e.g., Tavily, Perplexity) and # of searches to run for each research iteration
- set the depth of search for each section (# of iterations of writing, reflection, search, re-write)
- customize the writer model (e.g., Anthropic)

![report-generation](https://github.com/user-attachments/assets/6595d5cd-c981-43ec-8e8b-209e4fefc596)

## 🚀 Quickstart

Ensure you have API keys set for your desired tools.

Select a web search tool (by default Open Deep Research uses Tavily):

* [Tavily API](https://tavily.com/)
* [Perplexity API](https://www.perplexity.ai/hub/blog/introducing-the-sonar-pro-api)

Select a writer model (by default Open Deep Research uses Anthropic Claude 3.5 Sonnet):

* [Anthropic](https://www.anthropic.com/)
* [OpenAI](https://openai.com/)
* [Groq](https://groq.com/)

Select a planner model (by default Open Deep Research uses OpenAI o3-mini):

* [Anthropic](https://www.anthropic.com/)
* [OpenAI](https://openai.com/)
* [Groq](https://groq.com/)

### Using the package

(Recommended: Create a virtual environment):
```
python -m venv open_deep_research
source open_deep_research/bin/activate
```

Install:
```
pip install open-deep-research
```

See [src/open_deep_research/graph.ipynb](src/open_deep_research/graph.ipynb) for an example of usage in a Jupyter notebook.

Import and compile the graph:
```python
from langgraph.checkpoint.memory import MemorySaver
from open_deep_research.graph import builder
memory = MemorySaver()
graph = builder.compile(checkpointer=memory)
```

View the graph:
```python
from IPython.display import Image, display
display(Image(graph.get_graph(xray=1).draw_mermaid_png()))
```

Run the graph with a desired topic and configuration:
```python
import uuid 
thread = {"configurable": {"thread_id": str(uuid.uuid4()),
                           "search_api": "tavily",
                           "planner_provider": "openai",
                           "planner_model": "o3-mini",
                           "writer_provider": "anthropic",
                           "writer_model": "claude-3-5-sonnet-latest",
                           "max_search_depth": 1,
                           }}

topic = "Overview of the AI inference market with focus on Fireworks, Together.ai, Groq"
async for event in graph.astream({"topic":topic,}, thread, stream_mode="updates"):
    print(event)
    print("\n")
```

The graph will stop when the report plan is generated, and you can pass feedback to update the report plan:
```python
from langgraph.types import Command
async for event in graph.astream(Command(resume="Include a revenue estimate (ARR) in the sections"), thread, stream_mode="updates"):
    print(event)
    print("\n")
```

When you are satisfied with the report plan, you can pass `True` to proceed to report generation:
```
# Pass True to approve the report plan and proceed to report generation
async for event in graph.astream(Command(resume=True), thread, stream_mode="updates"):
    print(event)
    print("\n")
```

### Running LangGraph Studio UI locally

Clone the repository:
```bash
git clone https://github.com/langchain-ai/open_deep_research.git
cd open_deep_research
```

Edit the `.env` file with your API keys (e.g., the API keys for default selections are shown below):

```bash
cp .env.example .env
```

Set:
```bash
export TAVILY_API_KEY=<your_tavily_api_key>
export ANTHROPIC_API_KEY=<your_anthropic_api_key>
export OPENAI_API_KEY=<your_openai_api_key>
```

Launch the assistant with the LangGraph server locally, which will open in your browser:

#### Mac

```bash
# Install uv package manager
curl -LsSf https://astral.sh/uv/install.sh | sh

# Install dependencies and start the LangGraph server
uvx --refresh --from "langgraph-cli[inmem]" --with-editable . --python 3.11 langgraph dev
```

#### Windows

```powershell
# Install dependencies 
pip install -e .
pip install langgraph-cli[inmem]

# Start the LangGraph server
langgraph dev
```

Use this to open the Studio UI:
```
- 🚀 API: http://127.0.0.1:2024
- 🎨 Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024
- 📚 API Docs: http://127.0.0.1:2024/docs
```

(1) Provide a `Topic` and hit `Submit`:

<img width="1326" alt="input" src="https://github.com/user-attachments/assets/de264b1b-8ea5-4090-8e72-e1ef1230262f" />

(2) This will generate a report plan and present it to the user for review.

(3) We can pass a string (`"..."`) with feedback to regenerate the plan based on the feedback.

<img width="1326" alt="feedback" src="https://github.com/user-attachments/assets/c308e888-4642-4c74-bc78-76576a2da919" />

(4) Or, we can just pass `true` to accept the plan.

<img width="1480" alt="accept" src="https://github.com/user-attachments/assets/ddeeb33b-fdce-494f-af8b-bd2acc1cef06" />

(5) Once accepted, the report sections will be generated.

<img width="1326" alt="report_gen" src="https://github.com/user-attachments/assets/74ff01cc-e7ed-47b8-bd0c-4ef615253c46" />

The report is produced as markdown.

<img width="1326" alt="report" src="https://github.com/user-attachments/assets/92d9f7b7-3aea-4025-be99-7fb0d4b47289" />

## 📖 Customizing the report

You can customize the research assistant's behavior through several parameters:

- `report_structure`: Define a custom structure for your report (defaults to a standard research report format)
- `number_of_queries`: Number of search queries to generate per section (default: 2)
- `max_search_depth`: Maximum number of reflection and search iterations (default: 2)
- `planner_provider`: Model provider for planning phase (default: "openai", but can be "groq")
- `planner_model`: Specific model for planning (default: "o3-mini", but can be any Groq hosted model such as "deepseek-r1-distill-llama-70b")
- `writer_model`: Model for writing the report (default: "claude-3-5-sonnet-latest")
- `search_api`: API to use for web searches (default: Tavily)

These configurations allow you to fine-tune the research process based on your needs, from adjusting the depth of research to selecting specific AI models for different phases of report generation.

### Model Considerations

(1) With Groq, there are token per minute (TPM) limits if you are on the `on_demand` service tier:
- The `on_demand` service tier has a limit of `6000 TPM`
- You will want a [paid plan](https://github.com/cline/cline/issues/47#issuecomment-2640992272) for section writing with Groq models

(2) `deepseek` [isn't great at function calling](https://api-docs.deepseek.com/guides/reasoning_model). Our assistant uses function calling to generate structured outputs for report sections and search queries within each section.  
- Because, section writing performs a larger number of function calls, OpenAI, Anthropic, and certain OSS models that are stromng at function calling like Groq's `llama-3.3-70b-versatile` are advised.
- If you see the following error, it is likely due to the model not being able to produce structured outputs (see [trace](https://smith.langchain.com/public/8a6da065-3b8b-4a92-8df7-5468da336cbe/r)):
```
groq.APIError: Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.
```

## How it works
   
1. `Plan and Execute` - Open Deep Research follows a [plan-and-execute workflow](https://github.com/assafelovic/gpt-researcher) that separates planning from research, allowing for human-in-the-loop approval of a report plan before the more time-consuming research phase. It uses, by default, a [reasoning model](https://www.youtube.com/watch?v=f0RbwrBcFmc) to plan the report sections. During this phase, it uses web search to gather general information about the report topic to help in planning the report sections. But, it also accepts a report structure from the user to help guide the report sections as well as human feedback on the report plan.
   
2. `Research and Write` - Each section of the report is written in parallel. The research assistant uses web search via [Tavily API](https://tavily.com/) or [Perplexity](https://www.perplexity.ai/hub/blog/introducing-the-sonar-pro-api) to gather information about each section topic. It will reflect on each report section and suggest follow-up questions for web search. This "depth" of research will proceed for any many iterations as the user wants. Any final sections, such as introductions and conclusions, are written after the main body of the report is written, which helps ensure that the report is cohesive and coherent. The planner determines main body versus final sections during the planning phase.

3. `Managing different types` - Open Deep Research is built on LangGraph, which has native support for configuration management [using assistants](https://langchain-ai.github.io/langgraph/concepts/assistants/). The report `structure` is a field in the graph configuration, which allows users to create different assistants for different types of reports. 

## UX

### Local deployment

Follow the [quickstart](#quickstart) to start LangGraph server locally.

### Hosted deployment
 
You can easily deploy to [LangGraph Platform ](https://langchain-ai.github.io/langgraph/concepts/#deployment-options).

================
File: src/open_deep_research/__init__.py
================
"""Planning, research, and report generation."""

__version__ = "0.0.5"

================
File: src/open_deep_research/configuration.py
================
import os
from enum import Enum
from dataclasses import dataclass, fields
from typing import Any, Optional

from langchain_core.runnables import RunnableConfig
from dataclasses import dataclass

DEFAULT_REPORT_STRUCTURE = """Use this structure to create a report on the user-provided topic:

1. Introduction (no research needed)
   - Brief overview of the topic area

2. Main Body Sections:
   - Each section should focus on a sub-topic of the user-provided topic
   
3. Conclusion
   - Aim for 1 structural element (either a list of table) that distills the main body sections 
   - Provide a concise summary of the report"""

class SearchAPI(Enum):
    PERPLEXITY = "perplexity"
    TAVILY = "tavily"

class PlannerProvider(Enum):
    ANTHROPIC = "anthropic"
    OPENAI = "openai"
    GROQ = "groq"

class WriterProvider(Enum):
    ANTHROPIC = "anthropic"
    OPENAI = "openai"
    GROQ = "groq"

@dataclass(kw_only=True)
class Configuration:
    """The configurable fields for the chatbot."""
    report_structure: str = DEFAULT_REPORT_STRUCTURE # Defaults to the default report structure
    number_of_queries: int = 2 # Number of search queries to generate per iteration
    max_search_depth: int = 2 # Maximum number of reflection + search iterations
    planner_provider: PlannerProvider = PlannerProvider.OPENAI  # Defaults to OpenAI as provider
    planner_model: str = "gpt-4o-mini" # Defaults to OpenAI o3-mini as planner model
    # writer_provider: WriterProvider = WriterProvider.ANTHROPIC # Defaults to Anthropic as provider
    writer_provider: WriterProvider = WriterProvider.OPENAI # Defaults to Anthropic as provider
    # writer_model: str = "claude-3-5-sonnet-latest" # Defaults to Anthropic as provider
    writer_model: str = "gpt-4o-mini" # Defaults to Anthropic as provider
    search_api: SearchAPI = SearchAPI.TAVILY # Default to TAVILY

    @classmethod
    def from_runnable_config(
        cls, config: Optional[RunnableConfig] = None
    ) -> "Configuration":
        """Create a Configuration instance from a RunnableConfig."""
        configurable = (
            config["configurable"] if config and "configurable" in config else {}
        )
        values: dict[str, Any] = {
            f.name: os.environ.get(f.name.upper(), configurable.get(f.name))
            for f in fields(cls)
            if f.init
        }
        return cls(**{k: v for k, v in values.items() if v})

================
File: src/open_deep_research/graph.ipynb
================
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U -q open-deep-research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.5\n"
     ]
    }
   ],
   "source": [
    "import open_deep_research   \n",
    "print(open_deep_research.__version__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.types import Command\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from open_deep_research.graph import builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "memory = MemorySaver()\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid \n",
    "from IPython.display import Markdown\n",
    "\n",
    "# Fast config with DeepSeek-R1-Distill-Llama-70B\n",
    "thread = {\"configurable\": {\"thread_id\": str(uuid.uuid4()),\n",
    "                           \"search_api\": \"tavily\",\n",
    "                           \"planner_provider\": \"groq\",\n",
    "                           \"planner_model\": \"deepseek-r1-distill-llama-70b\",\n",
    "                           \"writer_provider\": \"groq\",\n",
    "                           \"writer_model\": \"llama-3.3-70b-versatile\",\n",
    "                           \"max_search_depth\": 1,}\n",
    "                           }\n",
    "\n",
    "# Slow config, more in depth\n",
    "thread = {\"configurable\": {\"thread_id\": str(uuid.uuid4()),\n",
    "                           \"search_api\": \"perplexity\",\n",
    "                           \"planner_provider\": \"openai\",\n",
    "                           \"planner_model\": \"o3-mini\",\n",
    "                           \"writer_provider\": \"anthropic\",\n",
    "                           \"writer_model\": \"claude-3-5-sonnet-latest\",\n",
    "                           \"max_search_depth\": 2,\n",
    "                           }}\n",
    "\n",
    "# Fast config with o3-mini\n",
    "thread = {\"configurable\": {\"thread_id\": str(uuid.uuid4()),\n",
    "                           \"search_api\": \"tavily\",\n",
    "                           \"planner_provider\": \"openai\",\n",
    "                           \"planner_model\": \"o3-mini\",\n",
    "                           \"writer_provider\": \"anthropic\",\n",
    "                           \"writer_model\": \"claude-3-5-sonnet-latest\",\n",
    "                           \"max_search_depth\": 1,\n",
    "                           }}\n",
    "\n",
    "# Create a topic\n",
    "topic = \"Overview of the AI inference market with focus on Fireworks, Together.ai, Groq\"\n",
    "\n",
    "# Run the graph until the interruption\n",
    "async for event in graph.astream({\"topic\":topic,}, thread, stream_mode=\"updates\"):\n",
    "    if '__interrupt__' in event:\n",
    "        interrupt_value = event['__interrupt__'][0].value\n",
    "        display(Markdown(interrupt_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass feedback to update the report plan  \n",
    "async for event in graph.astream(Command(resume=\"Include a revenue estimate (ARR) in the sections focused on Groq, Together.ai, and Fireworks\"), thread, stream_mode=\"updates\"):\n",
    "    if '__interrupt__' in event:\n",
    "        interrupt_value = event['__interrupt__'][0].value\n",
    "        display(Markdown(interrupt_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass True to approve the report plan \n",
    "async for event in graph.astream(Command(resume=True), thread, stream_mode=\"updates\"):\n",
    "    print(event)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# AI Inference Market and Key Players Overview\n",
       "\n",
       "The AI inference market is experiencing explosive growth, projected to expand from $24.6 billion in 2024 to $133.2 billion by 2034. This transformation is being driven by innovative companies developing breakthrough optimization technologies that dramatically improve performance while reducing costs. Among these pioneers, Fireworks AI has demonstrated enterprise-grade reliability by processing 140 billion tokens daily, while Together.ai has achieved 4x faster decoding throughput than traditional solutions. Groq's Language Processing Unit (LPU) has emerged as a particularly disruptive force, offering competitive pricing from $0.05 to $0.99 per million tokens while securing a $2.8 billion valuation.\n",
       "\n",
       "## Key Players Comparison\n",
       "\n",
       "| Feature | Fireworks AI | Together.ai | Groq |\n",
       "|---------|-------------|-------------|------|\n",
       "| Daily Processing | 140B tokens | 400 tokens/sec | Not disclosed |\n",
       "| Pricing Range | $0.10-$1.20/M tokens | Custom pricing | $0.05-$0.99/M tokens |\n",
       "| Key Innovation | Parameter-based pricing | FlashAttention-3 | Language Processing Unit |\n",
       "| Enterprise Users | Uber, DoorDash | Salesforce, Washington Post | Hunch AI, aiXplain |\n",
       "| Valuation | $552M | $100M ARR | $2.8B |\n",
       "\n",
       "These players are reshaping the inference landscape through distinct approaches to optimization and pricing, with each targeting different segments of the rapidly expanding market. Their continued innovation suggests further disruption in the AI infrastructure space.\n",
       "\n",
       "## Global AI Inference Market Analysis\n",
       "\n",
       "**The AI inference market is projected to grow from $24.6 billion in 2024 to $133.2 billion by 2034, driven by breakthrough optimization technologies that are dramatically improving performance while reducing costs.** Cloud deployment currently dominates with 55% market share, though on-premises solutions are gaining traction for latency-sensitive and security-focused applications.\n",
       "\n",
       "NVIDIA maintains market leadership with approximately 80% share of AI chips, while competitors like AMD, Intel, and cloud providers are investing heavily in specialized inference solutions. Recent advances in speculative decoding and compilation techniques have enabled up to 2x higher throughput at 50% lower costs for popular models like Llama and Mixtral.\n",
       "\n",
       "Key barriers to adoption include:\n",
       "- High infrastructure costs and unclear ROI\n",
       "- Data quality and quantity challenges\n",
       "- Integration complexity with existing systems\n",
       "- Skills gaps in AI/ML expertise\n",
       "- Privacy and regulatory concerns\n",
       "\n",
       "North America leads regional adoption with 38% market share, particularly in financial services and healthcare verticals. Microsoft's implementation of NVIDIA inference solutions for Copilot demonstrates the technology's enterprise readiness.\n",
       "\n",
       "### Sources\n",
       "- Restack AI Hardware Analysis 2024: https://www.restack.io/p/hardware-innovations-for-ai-technologies-answer-leading-ai-hardware-companies-2024\n",
       "- NVIDIA Developer Blog: https://developer.nvidia.com/blog/optimize-ai-inference-performance-with-nvidia-full-stack-solutions/\n",
       "- Market.us AI Inference Report: https://scoop.market.us/ai-inference-server-market-news/\n",
       "\n",
       "## Fireworks AI Technical Analysis\n",
       "\n",
       "**Fireworks AI combines an innovative pricing model with proven enterprise performance, demonstrated by processing 140 billion tokens daily with 99.99% API uptime across 12,000 users.** Their tiered pricing structure scales with usage, starting at $0.10 per million tokens for small models and reaching $1.20 per million tokens for large MoE architectures.\n",
       "\n",
       "The platform offers specialized pricing for different modalities:\n",
       "- Text generation with parameter-based pricing ($0.10-$1.20/M tokens)\n",
       "- Image generation at $0.00013 per step\n",
       "- Speech-to-text processing from $0.0009 per audio minute\n",
       "- On-demand GPU deployments ranging from $2.90 to $9.99 per hour\n",
       "\n",
       "A notable implementation at Sourcegraph showcases the platform's capabilities, where StarCoder deployment doubled code completion acceptance rates while cutting backend latency by 50%. The company's recent $52M Series B funding values it at $552M, with Forbes estimating 2023 revenue at $3M.\n",
       "\n",
       "Enterprise customers including Uber, DoorDash, and Upwork have adopted Fireworks AI's infrastructure, citing lower costs and reduced latency compared to alternatives. The platform's spending limits increase with usage history, from $50/month to custom enterprise tiers exceeding $50,000/month.\n",
       "\n",
       "### Sources\n",
       "- Fireworks AI Blog Spring Update: https://fireworks.ai/blog/spring-update-faster-models-dedicated-deployments-postpaid-pricing\n",
       "- AWS Case Study: https://aws.amazon.com/solutions/case-studies/fireworks-ai-case-study/\n",
       "- Funding News: https://www.pymnts.com/news/investment-tracker/2024/fireworks-ai-valued-552-million-dollars-after-new-funding-round/\n",
       "\n",
       "## Together.ai's Inference Stack Analysis\n",
       "\n",
       "**Together.ai has revolutionized LLM inference by achieving 4x faster decoding throughput than open-source vLLM through an integrated approach combining hardware optimization and algorithmic innovations.** Their Inference Engine 2.0 demonstrates superior performance by processing over 400 tokens per second on Meta's Llama 3 8B model.\n",
       "\n",
       "The technical foundation relies on four key innovations:\n",
       "- FlashAttention-3 optimization achieving 75% GPU utilization\n",
       "- Custom-built draft models trained beyond 10x Chinchilla optimal\n",
       "- Advanced speculative decoding combining Medusa and Sequoia techniques\n",
       "- Quality-preserving quantization matching FP16 precision\n",
       "\n",
       "A notable case study demonstrates their efficiency at scale: using just two A100 GPUs, Together Lite outperforms vLLM running on eight H100 GPUs by 30% in common inference scenarios. This translates to a 12x cost reduction compared to standard deployments.\n",
       "\n",
       "The Enterprise Platform builds on these innovations while maintaining SOC 2, GDPR, and HIPAA compliance. Major enterprises including Salesforce and The Washington Post have validated its performance in production environments, contributing to Together.ai reaching $100M ARR within 10 months of launch.\n",
       "\n",
       "### Sources\n",
       "- Together Inference Engine 2.0 Announcement: https://www.together.ai/blog/together-inference-engine-2\n",
       "- Enterprise Platform Security: https://www.togetherplatform.com/security-compliance\n",
       "- Speculative Decoding Implementation: https://www.together.ai/blog/speculative-decoding-for-high-throughput-long-context-inference\n",
       "\n",
       "## Groq's Inference Engine Performance and Market Traction\n",
       "\n",
       "**Groq's Language Processing Unit (LPU) has demonstrated unprecedented inference speeds while achieving significant market validation, with an estimated $3.4 million revenue in 2023 and a $2.8 billion valuation following their August 2024 Series D round.**\n",
       "\n",
       "The LPU's competitive pricing structure ranges from $0.05 to $0.99 per million tokens, depending on model size and input/output requirements. For example, their Llama 3.3 70B implementation charges $0.59 per million input tokens and $0.79 per million output tokens, positioning them favorably against cloud competitors.\n",
       "\n",
       "Developer adoption has been robust, with notable implementations including:\n",
       "- Hunch AI Workspace for rapid prototyping\n",
       "- aiXplain's real-time inference solutions\n",
       "- Argonne National Laboratory's research applications\n",
       "- Embodied's Moxie education robot\n",
       "\n",
       "The platform offers an OpenAI-compatible API supporting multiple models including Llama 3.3, Mixtral 8x7b, and Gemma 2. Integration options include LangChain compatibility and Retrieval Augmented Generation capabilities, enabling developers to incorporate proprietary data into their applications.\n",
       "\n",
       "### Sources\n",
       "- Sacra Company Analysis: https://sacra.com/c/groq/\n",
       "- Groq Pricing Documentation: https://groq.com/pricing/\n",
       "- ChipStrat Analysis: https://www.chipstrat.com/p/the-rise-of-groq-slow-then-fast\n",
       "- Groq API Documentation: https://distilabel.argilla.io/1.2.1/api/llm/groq/\n",
       "\n",
       "## Market and Provider Analysis Summary\n",
       "\n",
       "The AI inference market is experiencing rapid growth, projected to reach $133.2 billion by 2034, with cloud deployment currently dominating at 55% market share. Among emerging providers, Fireworks AI, Together.ai, and Groq demonstrate distinct competitive advantages in performance and pricing strategies.\n",
       "\n",
       "| Provider | Key Differentiator | Performance Metric | Revenue/Valuation |\n",
       "|----------|-------------------|-------------------|-------------------|\n",
       "| Fireworks AI | Enterprise-grade reliability | 140B tokens/day, 99.99% uptime | $3M (2023), $552M valuation |\n",
       "| Together.ai | Advanced optimization stack | 4x faster than vLLM, 400 tokens/sec | $100M ARR |\n",
       "| Groq | Custom LPU architecture | Industry-leading latency | $3.4M (2023), $2.8B valuation |\n",
       "\n",
       "These providers are addressing key market barriers through innovative pricing models, ranging from $0.05 to $1.20 per million tokens, while delivering specialized solutions for different modalities and use cases. Their success in attracting major enterprise customers suggests growing market maturity, though NVIDIA's 80% chip market share indicates continued infrastructure dependencies."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "final_state = graph.get_state(thread)\n",
    "report = final_state.values.get('final_report')\n",
    "Markdown(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open-deep-research-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

================
File: src/open_deep_research/graph.py
================
from typing import Literal

from langchain_core.messages import HumanMessage, SystemMessage
from langchain.chat_models import init_chat_model
from langchain_core.runnables import RunnableConfig

from langgraph.constants import Send
from langgraph.graph import START, END, StateGraph
from langgraph.types import interrupt, Command

from open_deep_research.state import ReportStateInput, ReportStateOutput, Sections, ReportState, SectionState, SectionOutputState, Queries, Feedback
from open_deep_research.prompts import report_planner_query_writer_instructions, report_planner_instructions, query_writer_instructions, section_writer_instructions, final_section_writer_instructions, section_grader_instructions
from open_deep_research.configuration import Configuration
from open_deep_research.utils import tavily_search_async, deduplicate_and_format_sources, format_sections, perplexity_search, get_config_value

# Nodes
async def generate_report_plan(state: ReportState, config: RunnableConfig):
    """ Generate the report plan """

    # Inputs
    topic = state["topic"]
    feedback = state.get("feedback_on_report_plan", None)

    # Get configuration
    configurable = Configuration.from_runnable_config(config)
    report_structure = configurable.report_structure
    number_of_queries = configurable.number_of_queries

    # Convert JSON object to string if necessary
    if isinstance(report_structure, dict):
        report_structure = str(report_structure)

    # Set writer model (model used for query writing and section writing)
    writer_provider = get_config_value(configurable.writer_provider)
    writer_model_name = get_config_value(configurable.writer_model)
    writer_model = init_chat_model(model=writer_model_name, model_provider=writer_provider, temperature=0) 
    structured_llm = writer_model.with_structured_output(Queries)

    # Format system instructions
    system_instructions_query = report_planner_query_writer_instructions.format(topic=topic, report_organization=report_structure, number_of_queries=number_of_queries)

    # Generate queries  
    results = structured_llm.invoke([SystemMessage(content=system_instructions_query)]+[HumanMessage(content="Generate search queries that will help with planning the sections of the report.")])

    # Web search
    query_list = [query.search_query for query in results.queries]

    # Get the search API
    search_api = get_config_value(configurable.search_api)

    # Search the web
    if search_api == "tavily":
        search_results = await tavily_search_async(query_list)
        source_str = deduplicate_and_format_sources(search_results, max_tokens_per_source=1000, include_raw_content=False)
    elif search_api == "perplexity":
        search_results = perplexity_search(query_list)
        source_str = deduplicate_and_format_sources(search_results, max_tokens_per_source=1000, include_raw_content=False)
    else:
        raise ValueError(f"Unsupported search API: {configurable.search_api}")

    # Format system instructions
    system_instructions_sections = report_planner_instructions.format(topic=topic, report_organization=report_structure, context=source_str, feedback=feedback)

    # Set the planner provider
    if isinstance(configurable.planner_provider, str):
        planner_provider = configurable.planner_provider
    else:
        planner_provider = configurable.planner_provider.value

    # Set the planner model
    if isinstance(configurable.planner_model, str):
        planner_model = configurable.planner_model
    else:
        planner_model = configurable.planner_model.value

    # Set the planner model
    if planner_model == "claude-3-7-sonnet-latest":
        planner_llm = init_chat_model(model=planner_model, model_provider=planner_provider, max_tokens=20_000, thinking={"type": "enabled", "budget_tokens": 16_000})
        # with_structured_output uses forced tool calling, which thinking mode with Claude 3.7 does not support. Use bind_tools to generate the report sections
        structured_llm = planner_llm.bind_tools([Sections])
        report_sections = structured_llm.invoke([SystemMessage(content=system_instructions_sections)]+[HumanMessage(content="Generate the sections of the report. Your response must include a 'sections' field containing a list of sections. Each section must have: name, description, plan, research, and content fields.")])
        tool_call = report_sections.tool_calls[0]['args']
        report_sections = Sections.model_validate(tool_call)
    else:
        planner_llm = init_chat_model(model=planner_model, model_provider=planner_provider)
        structured_llm = planner_llm.with_structured_output(Sections)
        report_sections = structured_llm.invoke([SystemMessage(content=system_instructions_sections)]+[HumanMessage(content="Generate the sections of the report. Your response must include a 'sections' field containing a list of sections. Each section must have: name, description, plan, research, and content fields.")])

    # Get sections
    sections = report_sections.sections

    return {"sections": sections}

def human_feedback(state: ReportState, config: RunnableConfig) -> Command[Literal["generate_report_plan","build_section_with_web_research"]]:
    """ Get feedback on the report plan """

    # Get sections
    topic = state["topic"]
    sections = state['sections']
    sections_str = "\n\n".join(
        f"Section: {section.name}\n"
        f"Description: {section.description}\n"
        f"Research needed: {'Yes' if section.research else 'No'}\n"
        for section in sections
    )

    # Get feedback on the report plan from interrupt

    feedback = interrupt(f"Please provide feedback on the following report plan. \n\n{sections_str}\n\n Does the report plan meet your needs? Pass 'true' to approve the report plan or provide feedback to regenerate the report plan:")

    # If the user approves the report plan, kick off section writing
    # if isinstance(feedback, bool) and feedback is True:
    if isinstance(feedback, bool):
        # Treat this as approve and kick off section writing
        return Command(goto=[
            Send("build_section_with_web_research", {"topic": topic, "section": s, "search_iterations": 0}) 
            for s in sections 
            if s.research
        ])
    
    # If the user provides feedback, regenerate the report plan 
    elif isinstance(feedback, str):
        # treat this as feedback
        return Command(goto="generate_report_plan", 
                       update={"feedback_on_report_plan": feedback})
    else:
        raise TypeError(f"Interrupt value of type {type(feedback)} is not supported.")
    
def generate_queries(state: SectionState, config: RunnableConfig):
    """ Generate search queries for a report section """

    # Get state 
    topic = state["topic"]
    section = state["section"]

    # Get configuration
    configurable = Configuration.from_runnable_config(config)
    number_of_queries = configurable.number_of_queries

    # Generate queries 
    writer_provider = get_config_value(configurable.writer_provider)
    writer_model_name = get_config_value(configurable.writer_model)
    writer_model = init_chat_model(model=writer_model_name, model_provider=writer_provider, temperature=0) 
    structured_llm = writer_model.with_structured_output(Queries)

    # Format system instructions
    system_instructions = query_writer_instructions.format(topic=topic, section_topic=section.description, number_of_queries=number_of_queries)

    # Generate queries  
    queries = structured_llm.invoke([SystemMessage(content=system_instructions)]+[HumanMessage(content="Generate search queries on the provided topic.")])

    return {"search_queries": queries.queries}

async def search_web(state: SectionState, config: RunnableConfig):
    """ Search the web for each query, then return a list of raw sources and a formatted string of sources."""
    
    # Get state 
    search_queries = state["search_queries"]

    # Get configuration
    configurable = Configuration.from_runnable_config(config)

    # Web search
    query_list = [query.search_query for query in search_queries]
    
    # Get the search API
    search_api = get_config_value(configurable.search_api)

    # Search the web
    if search_api == "tavily":
        search_results = await tavily_search_async(query_list)
        source_str = deduplicate_and_format_sources(search_results, max_tokens_per_source=5000, include_raw_content=True)
    elif search_api == "perplexity":
        search_results = perplexity_search(query_list)
        source_str = deduplicate_and_format_sources(search_results, max_tokens_per_source=5000, include_raw_content=False)
    else:
        raise ValueError(f"Unsupported search API: {configurable.search_api}")

    return {"source_str": source_str, "search_iterations": state["search_iterations"] + 1}

def write_section(state: SectionState, config: RunnableConfig) -> Command[Literal[END, "search_web"]]:
    """ Write a section of the report """

    # Get state 
    topic = state["topic"]
    section = state["section"]
    source_str = state["source_str"]

    # Get configuration
    configurable = Configuration.from_runnable_config(config)

    # Format system instructions
    system_instructions = section_writer_instructions.format(topic=topic, section_title=section.name, section_topic=section.description, context=source_str, section_content=section.content)

    # Generate section  
    writer_provider = get_config_value(configurable.writer_provider)
    writer_model_name = get_config_value(configurable.writer_model)
    writer_model = init_chat_model(model=writer_model_name, model_provider=writer_provider, temperature=0) 
    section_content = writer_model.invoke([SystemMessage(content=system_instructions)]+[HumanMessage(content="Generate a report section based on the provided sources.")])
    
    # Write content to the section object  
    section.content = section_content.content

    # Grade prompt 
    section_grader_instructions_formatted = section_grader_instructions.format(topic=topic, section_topic=section.description,section=section.content)

    # Feedback 
    structured_llm = writer_model.with_structured_output(Feedback)
    feedback = structured_llm.invoke([SystemMessage(content=section_grader_instructions_formatted)]+[HumanMessage(content="Grade the report and consider follow-up questions for missing information:")])

    if feedback.grade == "pass" or state["search_iterations"] >= configurable.max_search_depth:
        # Publish the section to completed sections 
        return  Command(
        update={"completed_sections": [section]},
        goto=END
    )
    else:
        # Update the existing section with new content and update search queries
        return  Command(
        update={"search_queries": feedback.follow_up_queries, "section": section},
        goto="search_web"
        )
    
def write_final_sections(state: SectionState, config: RunnableConfig):
    """ Write final sections of the report, which do not require web search and use the completed sections as context """

    # Get configuration
    configurable = Configuration.from_runnable_config(config)

    # Get state 
    topic = state["topic"]
    section = state["section"]
    completed_report_sections = state["report_sections_from_research"]
    
    # Format system instructions
    system_instructions = final_section_writer_instructions.format(topic=topic, section_title=section.name, section_topic=section.description, context=completed_report_sections)

    # Generate section  
    writer_provider = get_config_value(configurable.writer_provider)
    writer_model_name = get_config_value(configurable.writer_model)
    writer_model = init_chat_model(model=writer_model_name, model_provider=writer_provider, temperature=0) 
    section_content = writer_model.invoke([SystemMessage(content=system_instructions)]+[HumanMessage(content="Generate a report section based on the provided sources.")])
    
    # Write content to section 
    section.content = section_content.content

    # Write the updated section to completed sections
    return {"completed_sections": [section]}

def gather_completed_sections(state: ReportState):
    """ Gather completed sections from research and format them as context for writing the final sections """    

    # List of completed sections
    completed_sections = state["completed_sections"]

    # Format completed section to str to use as context for final sections
    completed_report_sections = format_sections(completed_sections)

    return {"report_sections_from_research": completed_report_sections}

def initiate_final_section_writing(state: ReportState):
    """ Write any final sections using the Send API to parallelize the process """    

    # Kick off section writing in parallel via Send() API for any sections that do not require research
    return [
        Send("write_final_sections", {"topic": state["topic"], "section": s, "report_sections_from_research": state["report_sections_from_research"]}) 
        for s in state["sections"] 
        if not s.research
    ]

def compile_final_report(state: ReportState):
    """ Compile the final report """    

    # Get sections
    sections = state["sections"]
    completed_sections = {s.name: s.content for s in state["completed_sections"]}

    # Update sections with completed content while maintaining original order
    for section in sections:
        section.content = completed_sections[section.name]

    # Compile final report
    all_sections = "\n\n".join([s.content for s in sections])

    return {"final_report": all_sections}

# Report section sub-graph -- 

# Add nodes 
section_builder = StateGraph(SectionState, output=SectionOutputState)
section_builder.add_node("generate_queries", generate_queries)
section_builder.add_node("search_web", search_web)
section_builder.add_node("write_section", write_section)

# Add edges
section_builder.add_edge(START, "generate_queries")
section_builder.add_edge("generate_queries", "search_web")
section_builder.add_edge("search_web", "write_section")

# Outer graph -- 

# Add nodes
builder = StateGraph(ReportState, input=ReportStateInput, output=ReportStateOutput, config_schema=Configuration)
builder.add_node("generate_report_plan", generate_report_plan)
builder.add_node("human_feedback", human_feedback)
builder.add_node("build_section_with_web_research", section_builder.compile())
builder.add_node("gather_completed_sections", gather_completed_sections)
builder.add_node("write_final_sections", write_final_sections)
builder.add_node("compile_final_report", compile_final_report)

# Add edges
builder.add_edge(START, "generate_report_plan")
builder.add_edge("generate_report_plan", "human_feedback")
builder.add_edge("build_section_with_web_research", "gather_completed_sections")
builder.add_conditional_edges("gather_completed_sections", initiate_final_section_writing, ["write_final_sections"])
builder.add_edge("write_final_sections", "compile_final_report")
builder.add_edge("compile_final_report", END)

graph = builder.compile()

================
File: src/open_deep_research/prompts.py
================
# Prompt to generate search queries to help with planning the report
report_planner_query_writer_instructions="""You are an expert technical writer, helping to plan a report. 

<Report topic>
{topic}
</Report topic>

<Report organization>
{report_organization}
</Report organization>

<Task>
Your goal is to generate {number_of_queries} search queries that will help gather comprehensive information for planning the report sections. 

The queries should:

1. Be related to the topic of the report
2. Help satisfy the requirements specified in the report organization

Make the queries specific enough to find high-quality, relevant sources while covering the breadth needed for the report structure.
</Task>
"""

# Prompt to generate the report plan
report_planner_instructions="""I want a plan for a report. 

<Task>
Generate a list of sections for the report.

Each section should have the fields:

- Name - Name for this section of the report.
- Description - Brief overview of the main topics covered in this section.
- Research - Whether to perform web research for this section of the report.
- Content - The content of the section, which you will leave blank for now.

For example, introduction and conclusion will not require research because they will distill information from other parts of the report.
</Task>

<Topic>
The topic of the report is:
{topic}
</Topic>

<Report organization>
The report should follow this organization: 
{report_organization}
</Report organization>

<Context>
Here is context to use to plan the sections of the report: 
{context}
</Context>

<Feedback>
Here is feedback on the report structure from review (if any):
{feedback}
</Feedback>
"""

# Query writer instructions
query_writer_instructions="""You are an expert technical writer crafting targeted web search queries that will gather comprehensive information for writing a technical report section.

<Report topic>
{topic}
</Report topic>

<Section topic>
{section_topic}
</Section topic>

<Task>
Your goal is to generate {number_of_queries} search queries that will help gather comprehensive information above the section topic. 

The queries should:

1. Be related to the topic 
2. Examine different aspects of the topic

Make the queries specific enough to find high-quality, relevant sources.
</Task>
"""

# Section writer instructions
section_writer_instructions = """You are an expert technical writer crafting one section of a technical report.

<Report topic>
{topic}
</Report topic>

<Section topic>
{section_topic}
</Section topic>

<Existing section content (if populated)>
{section_content}
</Existing section content>

<Source material>
{context}
</Source material>

<Guidelines for writing>
1. If the existing section content is not populated, write a new section from scratch.
2. If the existing section content is populated, write a new section that synthesizes the existing section content with the new information.
</Guidelines for writing>

<Length and style>
- Strict 150-200 word limit
- No marketing language
- Technical focus
- Write in simple, clear language
- Start with your most important insight in **bold**
- Use short paragraphs (2-3 sentences max)
- Use ## for section title (Markdown format)
- Only use ONE structural element IF it helps clarify your point:
  * Either a focused table comparing 2-3 key items (using Markdown table syntax)
  * Or a short list (3-5 items) using proper Markdown list syntax:
    - Use `*` or `-` for unordered lists
    - Use `1.` for ordered lists
    - Ensure proper indentation and spacing
- End with ### Sources that references the below source material formatted as:
  * List each source with title, date, and URL
  * Format: `- Title : URL`
</Length and style>

<Quality checks>
- Exactly 150-200 words (excluding title and sources)
- Careful use of only ONE structural element (table or list) and only if it helps clarify your point
- One specific example / case study
- Starts with bold insight
- No preamble prior to creating the section content
- Sources cited at end
</Quality checks>
"""

# Instructions for section grading
section_grader_instructions = """Review a report section relative to the specified topic:

<Report topic>
{topic}
</Report topic>

<section topic>
{section_topic}
</section topic>

<section content>
{section}
</section content>

<task>
Evaluate whether the section adequately covers the topic by checking technical accuracy and depth.

If the section fails any criteria, generate specific follow-up search queries to gather missing information.
</task>

<format>
    grade: Literal["pass","fail"] = Field(
        description="Evaluation result indicating whether the response meets requirements ('pass') or needs revision ('fail')."
    )
    follow_up_queries: List[SearchQuery] = Field(
        description="List of follow-up search queries.",
    )
</format>
"""

final_section_writer_instructions="""You are an expert technical writer crafting a section that synthesizes information from the rest of the report.

<Report topic>
{topic}
</Report topic>

<Section topic> 
{section_topic}
</Section topic>

<Available report content>
{context}
</Available report content>

<Task>
1. Section-Specific Approach:

For Introduction:
- Use # for report title (Markdown format)
- 50-100 word limit
- Write in simple and clear language
- Focus on the core motivation for the report in 1-2 paragraphs
- Use a clear narrative arc to introduce the report
- Include NO structural elements (no lists or tables)
- No sources section needed

For Conclusion/Summary:
- Use ## for section title (Markdown format)
- 100-150 word limit
- For comparative reports:
    * Must include a focused comparison table using Markdown table syntax
    * Table should distill insights from the report
    * Keep table entries clear and concise
- For non-comparative reports: 
    * Only use ONE structural element IF it helps distill the points made in the report:
    * Either a focused table comparing items present in the report (using Markdown table syntax)
    * Or a short list using proper Markdown list syntax:
      - Use `*` or `-` for unordered lists
      - Use `1.` for ordered lists
      - Ensure proper indentation and spacing
- End with specific next steps or implications
- No sources section needed

3. Writing Approach:
- Use concrete details over general statements
- Make every word count
- Focus on your single most important point
</Task>

<Quality Checks>
- For introduction: 50-100 word limit, # for report title, no structural elements, no sources section
- For conclusion: 100-150 word limit, ## for section title, only ONE structural element at most, no sources section
- Markdown format
- Do not include word count or any preamble in your response
</Quality Checks>"""

================
File: src/open_deep_research/state.py
================
from typing import Annotated, List, TypedDict, Literal
from pydantic import BaseModel, Field
import operator

class Section(BaseModel):
    name: str = Field(
        description="Name for this section of the report.",
    )
    description: str = Field(
        description="Brief overview of the main topics and concepts to be covered in this section.",
    )
    research: bool = Field(
        description="Whether to perform web research for this section of the report."
    )
    content: str = Field(
        description="The content of the section."
    )   

class Sections(BaseModel):
    sections: List[Section] = Field(
        description="Sections of the report.",
    )

class SearchQuery(BaseModel):
    search_query: str = Field(None, description="Query for web search.")

class Queries(BaseModel):
    queries: List[SearchQuery] = Field(
        description="List of search queries.",
    )

class Feedback(BaseModel):
    grade: Literal["pass","fail"] = Field(
        description="Evaluation result indicating whether the response meets requirements ('pass') or needs revision ('fail')."
    )
    follow_up_queries: List[SearchQuery] = Field(
        description="List of follow-up search queries.",
    )

class ReportStateInput(TypedDict):
    topic: str # Report topic
    
class ReportStateOutput(TypedDict):
    final_report: str # Final report

class ReportState(TypedDict):
    topic: str # Report topic    
    feedback_on_report_plan: str # Feedback on the report plan
    sections: list[Section] # List of report sections 
    completed_sections: Annotated[list, operator.add] # Send() API key
    report_sections_from_research: str # String of any completed sections from research to write final sections
    final_report: str # Final report

class SectionState(TypedDict):
    topic: str # Report topic
    section: Section # Report section  
    search_iterations: int # Number of search iterations done
    search_queries: list[SearchQuery] # List of search queries
    source_str: str # String of formatted source content from web search
    report_sections_from_research: str # String of any completed sections from research to write final sections
    completed_sections: list[Section] # Final key we duplicate in outer state for Send() API

class SectionOutputState(TypedDict):
    completed_sections: list[Section] # Final key we duplicate in outer state for Send() API

================
File: src/open_deep_research/utils.py
================
import os
import asyncio
import requests

from tavily import TavilyClient, AsyncTavilyClient
from open_deep_research.state import Section
from langsmith import traceable

tavily_client = TavilyClient()
tavily_async_client = AsyncTavilyClient()

def get_config_value(value):
    """
    Helper function to handle both string and enum cases of configuration values
    """
    return value if isinstance(value, str) else value.value

def deduplicate_and_format_sources(search_response, max_tokens_per_source, include_raw_content=True):
    """
    Takes a list of search responses and formats them into a readable string.
    Limits the raw_content to approximately max_tokens_per_source.
 
    Args:
        search_responses: List of search response dicts, each containing:
            - query: str
            - results: List of dicts with fields:
                - title: str
                - url: str
                - content: str
                - score: float
                - raw_content: str|None
        max_tokens_per_source: int
        include_raw_content: bool
            
    Returns:
        str: Formatted string with deduplicated sources
    """
     # Collect all results
    sources_list = []
    for response in search_response:
        sources_list.extend(response['results'])
    
    # Deduplicate by URL
    unique_sources = {source['url']: source for source in sources_list}

    # Format output
    formatted_text = "Sources:\n\n"
    for i, source in enumerate(unique_sources.values(), 1):
        formatted_text += f"Source {source['title']}:\n===\n"
        formatted_text += f"URL: {source['url']}\n===\n"
        formatted_text += f"Most relevant content from source: {source['content']}\n===\n"
        if include_raw_content:
            # Using rough estimate of 4 characters per token
            char_limit = max_tokens_per_source * 4
            # Handle None raw_content
            raw_content = source.get('raw_content', '')
            if raw_content is None:
                raw_content = ''
                print(f"Warning: No raw_content found for source {source['url']}")
            if len(raw_content) > char_limit:
                raw_content = raw_content[:char_limit] + "... [truncated]"
            formatted_text += f"Full source content limited to {max_tokens_per_source} tokens: {raw_content}\n\n"
                
    return formatted_text.strip()

def format_sections(sections: list[Section]) -> str:
    """ Format a list of sections into a string """
    formatted_str = ""
    for idx, section in enumerate(sections, 1):
        formatted_str += f"""
{'='*60}
Section {idx}: {section.name}
{'='*60}
Description:
{section.description}
Requires Research: 
{section.research}

Content:
{section.content if section.content else '[Not yet written]'}

"""
    return formatted_str

@traceable
async def tavily_search_async(search_queries):
    """
    Performs concurrent web searches using the Tavily API.

    Args:
        search_queries (List[SearchQuery]): List of search queries to process

    Returns:
            List[dict]: List of search responses from Tavily API, one per query. Each response has format:
                {
                    'query': str, # The original search query
                    'follow_up_questions': None,      
                    'answer': None,
                    'images': list,
                    'results': [                     # List of search results
                        {
                            'title': str,            # Title of the webpage
                            'url': str,              # URL of the result
                            'content': str,          # Summary/snippet of content
                            'score': float,          # Relevance score
                            'raw_content': str|None  # Full page content if available
                        },
                        ...
                    ]
                }
    """
    
    search_tasks = []
    for query in search_queries:
            search_tasks.append(
                tavily_async_client.search(
                    query,
                    max_results=5,
                    include_raw_content=True,
                    topic="general"
                )
            )

    # Execute all searches concurrently
    search_docs = await asyncio.gather(*search_tasks)

    return search_docs

@traceable
def perplexity_search(search_queries):
    """Search the web using the Perplexity API.
    
    Args:
        search_queries (List[SearchQuery]): List of search queries to process
  
    Returns:
        List[dict]: List of search responses from Perplexity API, one per query. Each response has format:
            {
                'query': str,                    # The original search query
                'follow_up_questions': None,      
                'answer': None,
                'images': list,
                'results': [                     # List of search results
                    {
                        'title': str,            # Title of the search result
                        'url': str,              # URL of the result
                        'content': str,          # Summary/snippet of content
                        'score': float,          # Relevance score
                        'raw_content': str|None  # Full content or None for secondary citations
                    },
                    ...
                ]
            }
    """

    headers = {
        "accept": "application/json",
        "content-type": "application/json",
        "Authorization": f"Bearer {os.getenv('PERPLEXITY_API_KEY')}"
    }
    
    search_docs = []
    for query in search_queries:

        payload = {
            "model": "sonar-pro",
            "messages": [
                {
                    "role": "system",
                    "content": "Search the web and provide factual information with sources."
                },
                {
                    "role": "user",
                    "content": query
                }
            ]
        }
        
        response = requests.post(
            "https://api.perplexity.ai/chat/completions",
            headers=headers,
            json=payload
        )
        response.raise_for_status()  # Raise exception for bad status codes
        
        # Parse the response
        data = response.json()
        content = data["choices"][0]["message"]["content"]
        citations = data.get("citations", ["https://perplexity.ai"])
        
        # Create results list for this query
        results = []
        
        # First citation gets the full content
        results.append({
            "title": f"Perplexity Search, Source 1",
            "url": citations[0],
            "content": content,
            "raw_content": content,
            "score": 1.0  # Adding score to match Tavily format
        })
        
        # Add additional citations without duplicating content
        for i, citation in enumerate(citations[1:], start=2):
            results.append({
                "title": f"Perplexity Search, Source {i}",
                "url": citation,
                "content": "See primary source for full content",
                "raw_content": None,
                "score": 0.5  # Lower score for secondary sources
            })
        
        # Format response to match Tavily structure
        search_docs.append({
            "query": query,
            "follow_up_questions": None,
            "answer": None,
            "images": [],
            "results": results
        })
    
    return search_docs



================================================================
End of Codebase
================================================================
