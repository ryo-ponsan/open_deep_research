This file is a merged representation of the entire codebase, combined into a single document by Repomix.

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded

Additional Info:
----------------

================================================================
Directory Structure
================================================================
.env.example
.gitignore
2502_repomix-output.txt
examples/arxiv.md
examples/inference-market-gpt45.md
examples/inference-market.md
examples/pubmed.md
langgraph.json
pyproject.toml
README.md
src/open_deep_research/__init__.py
src/open_deep_research/configuration.py
src/open_deep_research/graph.ipynb
src/open_deep_research/graph.py
src/open_deep_research/prompts.py
src/open_deep_research/state.py
src/open_deep_research/utils.py

================================================================
Files
================================================================

================
File: .env.example
================
OPENAI_API_KEY=sk-xxx
ANTHROPIC_API_KEY=sk-xxx
TAVILY_API_KEY=xxx
GROQ_API_KEY=xxx
PERPLEXITY_API_KEY=xxx
LINKUP_API_KEY=xxx

================
File: .gitignore
================
.env
.langgraph_api
/open_deep_research.egg-info/
__pycache__/
*.py[cod]
.repomix-output.txt

================
File: 2502_repomix-output.txt
================
This file is a merged representation of the entire codebase, combined into a single document by Repomix.

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded

Additional Info:
----------------

================================================================
Directory Structure
================================================================
.env.example
.gitignore
examples/inference.md
langgraph.json
pyproject.toml
README.md
src/open_deep_research/__init__.py
src/open_deep_research/configuration.py
src/open_deep_research/graph.ipynb
src/open_deep_research/graph.py
src/open_deep_research/prompts.py
src/open_deep_research/state.py
src/open_deep_research/utils.py

================================================================
Files
================================================================

================
File: .env.example
================
OPENAI_API_KEY=sk-xxx
ANTHROPIC_API_KEY=sk-xxx
TAVILY_API_KEY=xxx
GROQ_API_KEY=xxx
PERPLEXITY_API_KEY=xxx

================
File: .gitignore
================
.env
.langgraph_api
/open_deep_research.egg-info/
__pycache__/
*.py[cod]

================
File: examples/inference.md
================
# AI Inference Market and Key Players Overview

The AI inference market is experiencing explosive growth, projected to expand from $24.6 billion in 2024 to $133.2 billion by 2034. This transformation is being driven by innovative companies developing breakthrough optimization technologies that dramatically improve performance while reducing costs. Among these pioneers, Fireworks AI has demonstrated enterprise-grade reliability by processing 140 billion tokens daily, while Together.ai has achieved 4x faster decoding throughput than traditional solutions. Groq's Language Processing Unit (LPU) has emerged as a particularly disruptive force, offering competitive pricing from $0.05 to $0.99 per million tokens while securing a $2.8 billion valuation.

## Key Players Comparison

| Feature | Fireworks AI | Together.ai | Groq |
|---------|-------------|-------------|------|
| Daily Processing | 140B tokens | 400 tokens/sec | Not disclosed |
| Pricing Range | $0.10-$1.20/M tokens | Custom pricing | $0.05-$0.99/M tokens |
| Key Innovation | Parameter-based pricing | FlashAttention-3 | Language Processing Unit |
| Enterprise Users | Uber, DoorDash | Salesforce, Washington Post | Hunch AI, aiXplain |
| Valuation | $552M | $100M ARR | $2.8B |

These players are reshaping the inference landscape through distinct approaches to optimization and pricing, with each targeting different segments of the rapidly expanding market. Their continued innovation suggests further disruption in the AI infrastructure space.

## Global AI Inference Market Analysis

**The AI inference market is projected to grow from $24.6 billion in 2024 to $133.2 billion by 2034, driven by breakthrough optimization technologies that are dramatically improving performance while reducing costs.** Cloud deployment currently dominates with 55% market share, though on-premises solutions are gaining traction for latency-sensitive and security-focused applications.

NVIDIA maintains market leadership with approximately 80% share of AI chips, while competitors like AMD, Intel, and cloud providers are investing heavily in specialized inference solutions. Recent advances in speculative decoding and compilation techniques have enabled up to 2x higher throughput at 50% lower costs for popular models like Llama and Mixtral.

Key barriers to adoption include:
- High infrastructure costs and unclear ROI
- Data quality and quantity challenges
- Integration complexity with existing systems
- Skills gaps in AI/ML expertise
- Privacy and regulatory concerns

North America leads regional adoption with 38% market share, particularly in financial services and healthcare verticals. Microsoft's implementation of NVIDIA inference solutions for Copilot demonstrates the technology's enterprise readiness.

### Sources
- Restack AI Hardware Analysis 2024: https://www.restack.io/p/hardware-innovations-for-ai-technologies-answer-leading-ai-hardware-companies-2024
- NVIDIA Developer Blog: https://developer.nvidia.com/blog/optimize-ai-inference-performance-with-nvidia-full-stack-solutions/
- Market.us AI Inference Report: https://scoop.market.us/ai-inference-server-market-news/

## Fireworks AI Technical Analysis

**Fireworks AI combines an innovative pricing model with proven enterprise performance, demonstrated by processing 140 billion tokens daily with 99.99% API uptime across 12,000 users.** Their tiered pricing structure scales with usage, starting at $0.10 per million tokens for small models and reaching $1.20 per million tokens for large MoE architectures.

The platform offers specialized pricing for different modalities:
- Text generation with parameter-based pricing ($0.10-$1.20/M tokens)
- Image generation at $0.00013 per step
- Speech-to-text processing from $0.0009 per audio minute
- On-demand GPU deployments ranging from $2.90 to $9.99 per hour

A notable implementation at Sourcegraph showcases the platform's capabilities, where StarCoder deployment doubled code completion acceptance rates while cutting backend latency by 50%. The company's recent $52M Series B funding values it at $552M, with Forbes estimating 2023 revenue at $3M.

Enterprise customers including Uber, DoorDash, and Upwork have adopted Fireworks AI's infrastructure, citing lower costs and reduced latency compared to alternatives. The platform's spending limits increase with usage history, from $50/month to custom enterprise tiers exceeding $50,000/month.

### Sources
- Fireworks AI Blog Spring Update: https://fireworks.ai/blog/spring-update-faster-models-dedicated-deployments-postpaid-pricing
- AWS Case Study: https://aws.amazon.com/solutions/case-studies/fireworks-ai-case-study/
- Funding News: https://www.pymnts.com/news/investment-tracker/2024/fireworks-ai-valued-552-million-dollars-after-new-funding-round/

## Together.ai's Inference Stack Analysis

**Together.ai has revolutionized LLM inference by achieving 4x faster decoding throughput than open-source vLLM through an integrated approach combining hardware optimization and algorithmic innovations.** Their Inference Engine 2.0 demonstrates superior performance by processing over 400 tokens per second on Meta's Llama 3 8B model.

The technical foundation relies on four key innovations:
- FlashAttention-3 optimization achieving 75% GPU utilization
- Custom-built draft models trained beyond 10x Chinchilla optimal
- Advanced speculative decoding combining Medusa and Sequoia techniques
- Quality-preserving quantization matching FP16 precision

A notable case study demonstrates their efficiency at scale: using just two A100 GPUs, Together Lite outperforms vLLM running on eight H100 GPUs by 30% in common inference scenarios. This translates to a 12x cost reduction compared to standard deployments.

The Enterprise Platform builds on these innovations while maintaining SOC 2, GDPR, and HIPAA compliance. Major enterprises including Salesforce and The Washington Post have validated its performance in production environments, contributing to Together.ai reaching $100M ARR within 10 months of launch.

### Sources
- Together Inference Engine 2.0 Announcement: https://www.together.ai/blog/together-inference-engine-2
- Enterprise Platform Security: https://www.togetherplatform.com/security-compliance
- Speculative Decoding Implementation: https://www.together.ai/blog/speculative-decoding-for-high-throughput-long-context-inference

## Groq's Inference Engine Performance and Market Traction

**Groq's Language Processing Unit (LPU) has demonstrated unprecedented inference speeds while achieving significant market validation, with an estimated $3.4 million revenue in 2023 and a $2.8 billion valuation following their August 2024 Series D round.**

The LPU's competitive pricing structure ranges from $0.05 to $0.99 per million tokens, depending on model size and input/output requirements. For example, their Llama 3.3 70B implementation charges $0.59 per million input tokens and $0.79 per million output tokens, positioning them favorably against cloud competitors.

Developer adoption has been robust, with notable implementations including:
- Hunch AI Workspace for rapid prototyping
- aiXplain's real-time inference solutions
- Argonne National Laboratory's research applications
- Embodied's Moxie education robot

The platform offers an OpenAI-compatible API supporting multiple models including Llama 3.3, Mixtral 8x7b, and Gemma 2. Integration options include LangChain compatibility and Retrieval Augmented Generation capabilities, enabling developers to incorporate proprietary data into their applications.

### Sources
- Sacra Company Analysis: https://sacra.com/c/groq/
- Groq Pricing Documentation: https://groq.com/pricing/
- ChipStrat Analysis: https://www.chipstrat.com/p/the-rise-of-groq-slow-then-fast
- Groq API Documentation: https://distilabel.argilla.io/1.2.1/api/llm/groq/

## Market and Provider Analysis Summary

The AI inference market is experiencing rapid growth, projected to reach $133.2 billion by 2034, with cloud deployment currently dominating at 55% market share. Among emerging providers, Fireworks AI, Together.ai, and Groq demonstrate distinct competitive advantages in performance and pricing strategies.

| Provider | Key Differentiator | Performance Metric | Revenue/Valuation |
|----------|-------------------|-------------------|-------------------|
| Fireworks AI | Enterprise-grade reliability | 140B tokens/day, 99.99% uptime | $3M (2023), $552M valuation |
| Together.ai | Advanced optimization stack | 4x faster than vLLM, 400 tokens/sec | $100M ARR |
| Groq | Custom LPU architecture | Industry-leading latency | $3.4M (2023), $2.8B valuation |

These providers are addressing key market barriers through innovative pricing models, ranging from $0.05 to $1.20 per million tokens, while delivering specialized solutions for different modalities and use cases. Their success in attracting major enterprise customers suggests growing market maturity, though NVIDIA's 80% chip market share indicates continued infrastructure dependencies.

================
File: langgraph.json
================
{
    "dockerfile_lines": [],
    "graphs": {
      "open_deep_research": "./src/open_deep_research/graph.py:graph"
    },
    "python_version": "3.11",
    "env": "./.env",
    "dependencies": [
      "."
    ]
  }

================
File: pyproject.toml
================
[project]
name = "open_deep_research"
version = "0.0.5"
description = "Planning, research, and report generation."
authors = [
    { name = "Lance Martin" }
]
readme = "README.md"
license = { text = "MIT" }
requires-python = ">=3.9" 
dependencies = [
    "langgraph>=0.2.55",
    "langchain-community>=0.3.9",
    "langchain-openai>=0.3.5",
    "langchain-anthropic>=0.3.8",
    "openai>=1.61.0",
    "tavily-python>=0.5.0",
    "langchain-groq>=0.2.4",
]

[project.optional-dependencies]
dev = ["mypy>=1.11.1", "ruff>=0.6.1"]

[build-system]
requires = ["setuptools>=73.0.0", "wheel"]
build-backend = "setuptools.build_meta"

[tool.setuptools]
packages = ["open_deep_research"]

[tool.setuptools.package-dir]
"open_deep_research" = "src/open_deep_research"

[tool.setuptools.package-data]
"*" = ["py.typed"]

[tool.ruff]
lint.select = [
    "E",    # pycodestyle
    "F",    # pyflakes
    "I",    # isort
    "D",    # pydocstyle
    "D401", # First line should be in imperative mood
    "T201",
    "UP",
]
lint.ignore = [
    "UP006",
    "UP007",
    "UP035",
    "D417",
    "E501",
]

[tool.ruff.lint.per-file-ignores]
"tests/*" = ["D", "UP"]

[tool.ruff.lint.pydocstyle]
convention = "google"

================
File: README.md
================
# Open Deep Research
 
Open Deep Research is a web research assistant that generates comprehensive reports on any topic following a workflow similar to [OpenAI](https://openai.com/index/introducing-deep-research/) and [Gemini](https://blog.google/products/gemini/google-gemini-deep-research/) Deep Research. However, it allows you to customize the models, prompts, report structure, search API, and research depth. Specifically, you can customize:

- provide an outline with a desired report structure
- set the planner model (e.g., DeepSeek, OpenAI reasoning model, etc)
- give feedback on the plan of report sections and iterate until user approval 
- set the search API (e.g., Tavily, Perplexity) and # of searches to run for each research iteration
- set the depth of search for each section (# of iterations of writing, reflection, search, re-write)
- customize the writer model (e.g., Anthropic)

![report-generation](https://github.com/user-attachments/assets/6595d5cd-c981-43ec-8e8b-209e4fefc596)

## ðŸš€ Quickstart

Ensure you have API keys set for your desired tools.

Select a web search tool (by default Open Deep Research uses Tavily):

* [Tavily API](https://tavily.com/)
* [Perplexity API](https://www.perplexity.ai/hub/blog/introducing-the-sonar-pro-api)

Select a writer model (by default Open Deep Research uses Anthropic Claude 3.5 Sonnet):

* [Anthropic](https://www.anthropic.com/)
* [OpenAI](https://openai.com/)
* [Groq](https://groq.com/)

Select a planner model (by default Open Deep Research uses OpenAI o3-mini):

* [Anthropic](https://www.anthropic.com/)
* [OpenAI](https://openai.com/)
* [Groq](https://groq.com/)

### Using the package

(Recommended: Create a virtual environment):
```
python -m venv open_deep_research
source open_deep_research/bin/activate
```

Install:
```
pip install open-deep-research
```

See [src/open_deep_research/graph.ipynb](src/open_deep_research/graph.ipynb) for an example of usage in a Jupyter notebook.

Import and compile the graph:
```python
from langgraph.checkpoint.memory import MemorySaver
from open_deep_research.graph import builder
memory = MemorySaver()
graph = builder.compile(checkpointer=memory)
```

View the graph:
```python
from IPython.display import Image, display
display(Image(graph.get_graph(xray=1).draw_mermaid_png()))
```

Run the graph with a desired topic and configuration:
```python
import uuid 
thread = {"configurable": {"thread_id": str(uuid.uuid4()),
                           "search_api": "tavily",
                           "planner_provider": "openai",
                           "planner_model": "o3-mini",
                           "writer_provider": "anthropic",
                           "writer_model": "claude-3-5-sonnet-latest",
                           "max_search_depth": 1,
                           }}

topic = "Overview of the AI inference market with focus on Fireworks, Together.ai, Groq"
async for event in graph.astream({"topic":topic,}, thread, stream_mode="updates"):
    print(event)
    print("\n")
```

The graph will stop when the report plan is generated, and you can pass feedback to update the report plan:
```python
from langgraph.types import Command
async for event in graph.astream(Command(resume="Include a revenue estimate (ARR) in the sections"), thread, stream_mode="updates"):
    print(event)
    print("\n")
```

When you are satisfied with the report plan, you can pass `True` to proceed to report generation:
```
# Pass True to approve the report plan and proceed to report generation
async for event in graph.astream(Command(resume=True), thread, stream_mode="updates"):
    print(event)
    print("\n")
```

### Running LangGraph Studio UI locally

Clone the repository:
```bash
git clone https://github.com/langchain-ai/open_deep_research.git
cd open_deep_research
```

Edit the `.env` file with your API keys (e.g., the API keys for default selections are shown below):

```bash
cp .env.example .env
```

Set:
```bash
export TAVILY_API_KEY=<your_tavily_api_key>
export ANTHROPIC_API_KEY=<your_anthropic_api_key>
export OPENAI_API_KEY=<your_openai_api_key>
```

Launch the assistant with the LangGraph server locally, which will open in your browser:

#### Mac

```bash
# Install uv package manager
curl -LsSf https://astral.sh/uv/install.sh | sh

# Install dependencies and start the LangGraph server
uvx --refresh --from "langgraph-cli[inmem]" --with-editable . --python 3.11 langgraph dev
```

#### Windows

```powershell
# Install dependencies 
pip install -e .
pip install langgraph-cli[inmem]

# Start the LangGraph server
langgraph dev
```

Use this to open the Studio UI:
```
- ðŸš€ API: http://127.0.0.1:2024
- ðŸŽ¨ Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024
- ðŸ“š API Docs: http://127.0.0.1:2024/docs
```

(1) Provide a `Topic` and hit `Submit`:

<img width="1326" alt="input" src="https://github.com/user-attachments/assets/de264b1b-8ea5-4090-8e72-e1ef1230262f" />

(2) This will generate a report plan and present it to the user for review.

(3) We can pass a string (`"..."`) with feedback to regenerate the plan based on the feedback.

<img width="1326" alt="feedback" src="https://github.com/user-attachments/assets/c308e888-4642-4c74-bc78-76576a2da919" />

(4) Or, we can just pass `true` to accept the plan.

<img width="1480" alt="accept" src="https://github.com/user-attachments/assets/ddeeb33b-fdce-494f-af8b-bd2acc1cef06" />

(5) Once accepted, the report sections will be generated.

<img width="1326" alt="report_gen" src="https://github.com/user-attachments/assets/74ff01cc-e7ed-47b8-bd0c-4ef615253c46" />

The report is produced as markdown.

<img width="1326" alt="report" src="https://github.com/user-attachments/assets/92d9f7b7-3aea-4025-be99-7fb0d4b47289" />

## ðŸ“– Customizing the report

You can customize the research assistant's behavior through several parameters:

- `report_structure`: Define a custom structure for your report (defaults to a standard research report format)
- `number_of_queries`: Number of search queries to generate per section (default: 2)
- `max_search_depth`: Maximum number of reflection and search iterations (default: 2)
- `planner_provider`: Model provider for planning phase (default: "openai", but can be "groq")
- `planner_model`: Specific model for planning (default: "o3-mini", but can be any Groq hosted model such as "deepseek-r1-distill-llama-70b")
- `writer_model`: Model for writing the report (default: "claude-3-5-sonnet-latest")
- `search_api`: API to use for web searches (default: Tavily)

These configurations allow you to fine-tune the research process based on your needs, from adjusting the depth of research to selecting specific AI models for different phases of report generation.

### Model Considerations

(1) With Groq, there are token per minute (TPM) limits if you are on the `on_demand` service tier:
- The `on_demand` service tier has a limit of `6000 TPM`
- You will want a [paid plan](https://github.com/cline/cline/issues/47#issuecomment-2640992272) for section writing with Groq models

(2) `deepseek` [isn't great at function calling](https://api-docs.deepseek.com/guides/reasoning_model). Our assistant uses function calling to generate structured outputs for report sections and search queries within each section.  
- Because, section writing performs a larger number of function calls, OpenAI, Anthropic, and certain OSS models that are stromng at function calling like Groq's `llama-3.3-70b-versatile` are advised.
- If you see the following error, it is likely due to the model not being able to produce structured outputs (see [trace](https://smith.langchain.com/public/8a6da065-3b8b-4a92-8df7-5468da336cbe/r)):
```
groq.APIError: Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.
```

## How it works
   
1. `Plan and Execute` - Open Deep Research follows a [plan-and-execute workflow](https://github.com/assafelovic/gpt-researcher) that separates planning from research, allowing for human-in-the-loop approval of a report plan before the more time-consuming research phase. It uses, by default, a [reasoning model](https://www.youtube.com/watch?v=f0RbwrBcFmc) to plan the report sections. During this phase, it uses web search to gather general information about the report topic to help in planning the report sections. But, it also accepts a report structure from the user to help guide the report sections as well as human feedback on the report plan.
   
2. `Research and Write` - Each section of the report is written in parallel. The research assistant uses web search via [Tavily API](https://tavily.com/) or [Perplexity](https://www.perplexity.ai/hub/blog/introducing-the-sonar-pro-api) to gather information about each section topic. It will reflect on each report section and suggest follow-up questions for web search. This "depth" of research will proceed for any many iterations as the user wants. Any final sections, such as introductions and conclusions, are written after the main body of the report is written, which helps ensure that the report is cohesive and coherent. The planner determines main body versus final sections during the planning phase.

3. `Managing different types` - Open Deep Research is built on LangGraph, which has native support for configuration management [using assistants](https://langchain-ai.github.io/langgraph/concepts/assistants/). The report `structure` is a field in the graph configuration, which allows users to create different assistants for different types of reports. 

## UX

### Local deployment

Follow the [quickstart](#quickstart) to start LangGraph server locally.

### Hosted deployment
 
You can easily deploy to [LangGraph Platform ](https://langchain-ai.github.io/langgraph/concepts/#deployment-options).

================
File: src/open_deep_research/__init__.py
================
"""Planning, research, and report generation."""

__version__ = "0.0.5"

================
File: src/open_deep_research/configuration.py
================
import os
from enum import Enum
from dataclasses import dataclass, fields
from typing import Any, Optional

from langchain_core.runnables import RunnableConfig
from dataclasses import dataclass

DEFAULT_REPORT_STRUCTURE = """Use this structure to create a report on the user-provided topic:

1. Introduction (no research needed)
   - Brief overview of the topic area

2. Main Body Sections:
   - Each section should focus on a sub-topic of the user-provided topic
   
3. Conclusion
   - Aim for 1 structural element (either a list of table) that distills the main body sections 
   - Provide a concise summary of the report"""

class SearchAPI(Enum):
    PERPLEXITY = "perplexity"
    TAVILY = "tavily"

class PlannerProvider(Enum):
    ANTHROPIC = "anthropic"
    OPENAI = "openai"
    GROQ = "groq"

class WriterProvider(Enum):
    ANTHROPIC = "anthropic"
    OPENAI = "openai"
    GROQ = "groq"

@dataclass(kw_only=True)
class Configuration:
    """The configurable fields for the chatbot."""
    report_structure: str = DEFAULT_REPORT_STRUCTURE # Defaults to the default report structure
    number_of_queries: int = 2 # Number of search queries to generate per iteration
    max_search_depth: int = 2 # Maximum number of reflection + search iterations
    planner_provider: PlannerProvider = PlannerProvider.OPENAI  # Defaults to OpenAI as provider
    planner_model: str = "gpt-4o-mini" # Defaults to OpenAI o3-mini as planner model
    # writer_provider: WriterProvider = WriterProvider.ANTHROPIC # Defaults to Anthropic as provider
    writer_provider: WriterProvider = WriterProvider.OPENAI # Defaults to Anthropic as provider
    # writer_model: str = "claude-3-5-sonnet-latest" # Defaults to Anthropic as provider
    writer_model: str = "gpt-4o-mini" # Defaults to Anthropic as provider
    search_api: SearchAPI = SearchAPI.TAVILY # Default to TAVILY

    @classmethod
    def from_runnable_config(
        cls, config: Optional[RunnableConfig] = None
    ) -> "Configuration":
        """Create a Configuration instance from a RunnableConfig."""
        configurable = (
            config["configurable"] if config and "configurable" in config else {}
        )
        values: dict[str, Any] = {
            f.name: os.environ.get(f.name.upper(), configurable.get(f.name))
            for f in fields(cls)
            if f.init
        }
        return cls(**{k: v for k, v in values.items() if v})

================
File: src/open_deep_research/graph.ipynb
================
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U -q open-deep-research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.5\n"
     ]
    }
   ],
   "source": [
    "import open_deep_research   \n",
    "print(open_deep_research.__version__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.types import Command\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from open_deep_research.graph import builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "memory = MemorySaver()\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid \n",
    "from IPython.display import Markdown\n",
    "\n",
    "# Fast config with DeepSeek-R1-Distill-Llama-70B\n",
    "thread = {\"configurable\": {\"thread_id\": str(uuid.uuid4()),\n",
    "                           \"search_api\": \"tavily\",\n",
    "                           \"planner_provider\": \"groq\",\n",
    "                           \"planner_model\": \"deepseek-r1-distill-llama-70b\",\n",
    "                           \"writer_provider\": \"groq\",\n",
    "                           \"writer_model\": \"llama-3.3-70b-versatile\",\n",
    "                           \"max_search_depth\": 1,}\n",
    "                           }\n",
    "\n",
    "# Slow config, more in depth\n",
    "thread = {\"configurable\": {\"thread_id\": str(uuid.uuid4()),\n",
    "                           \"search_api\": \"perplexity\",\n",
    "                           \"planner_provider\": \"openai\",\n",
    "                           \"planner_model\": \"o3-mini\",\n",
    "                           \"writer_provider\": \"anthropic\",\n",
    "                           \"writer_model\": \"claude-3-5-sonnet-latest\",\n",
    "                           \"max_search_depth\": 2,\n",
    "                           }}\n",
    "\n",
    "# Fast config with o3-mini\n",
    "thread = {\"configurable\": {\"thread_id\": str(uuid.uuid4()),\n",
    "                           \"search_api\": \"tavily\",\n",
    "                           \"planner_provider\": \"openai\",\n",
    "                           \"planner_model\": \"o3-mini\",\n",
    "                           \"writer_provider\": \"anthropic\",\n",
    "                           \"writer_model\": \"claude-3-5-sonnet-latest\",\n",
    "                           \"max_search_depth\": 1,\n",
    "                           }}\n",
    "\n",
    "# Create a topic\n",
    "topic = \"Overview of the AI inference market with focus on Fireworks, Together.ai, Groq\"\n",
    "\n",
    "# Run the graph until the interruption\n",
    "async for event in graph.astream({\"topic\":topic,}, thread, stream_mode=\"updates\"):\n",
    "    if '__interrupt__' in event:\n",
    "        interrupt_value = event['__interrupt__'][0].value\n",
    "        display(Markdown(interrupt_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass feedback to update the report plan  \n",
    "async for event in graph.astream(Command(resume=\"Include a revenue estimate (ARR) in the sections focused on Groq, Together.ai, and Fireworks\"), thread, stream_mode=\"updates\"):\n",
    "    if '__interrupt__' in event:\n",
    "        interrupt_value = event['__interrupt__'][0].value\n",
    "        display(Markdown(interrupt_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass True to approve the report plan \n",
    "async for event in graph.astream(Command(resume=True), thread, stream_mode=\"updates\"):\n",
    "    print(event)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# AI Inference Market and Key Players Overview\n",
       "\n",
       "The AI inference market is experiencing explosive growth, projected to expand from $24.6 billion in 2024 to $133.2 billion by 2034. This transformation is being driven by innovative companies developing breakthrough optimization technologies that dramatically improve performance while reducing costs. Among these pioneers, Fireworks AI has demonstrated enterprise-grade reliability by processing 140 billion tokens daily, while Together.ai has achieved 4x faster decoding throughput than traditional solutions. Groq's Language Processing Unit (LPU) has emerged as a particularly disruptive force, offering competitive pricing from $0.05 to $0.99 per million tokens while securing a $2.8 billion valuation.\n",
       "\n",
       "## Key Players Comparison\n",
       "\n",
       "| Feature | Fireworks AI | Together.ai | Groq |\n",
       "|---------|-------------|-------------|------|\n",
       "| Daily Processing | 140B tokens | 400 tokens/sec | Not disclosed |\n",
       "| Pricing Range | $0.10-$1.20/M tokens | Custom pricing | $0.05-$0.99/M tokens |\n",
       "| Key Innovation | Parameter-based pricing | FlashAttention-3 | Language Processing Unit |\n",
       "| Enterprise Users | Uber, DoorDash | Salesforce, Washington Post | Hunch AI, aiXplain |\n",
       "| Valuation | $552M | $100M ARR | $2.8B |\n",
       "\n",
       "These players are reshaping the inference landscape through distinct approaches to optimization and pricing, with each targeting different segments of the rapidly expanding market. Their continued innovation suggests further disruption in the AI infrastructure space.\n",
       "\n",
       "## Global AI Inference Market Analysis\n",
       "\n",
       "**The AI inference market is projected to grow from $24.6 billion in 2024 to $133.2 billion by 2034, driven by breakthrough optimization technologies that are dramatically improving performance while reducing costs.** Cloud deployment currently dominates with 55% market share, though on-premises solutions are gaining traction for latency-sensitive and security-focused applications.\n",
       "\n",
       "NVIDIA maintains market leadership with approximately 80% share of AI chips, while competitors like AMD, Intel, and cloud providers are investing heavily in specialized inference solutions. Recent advances in speculative decoding and compilation techniques have enabled up to 2x higher throughput at 50% lower costs for popular models like Llama and Mixtral.\n",
       "\n",
       "Key barriers to adoption include:\n",
       "- High infrastructure costs and unclear ROI\n",
       "- Data quality and quantity challenges\n",
       "- Integration complexity with existing systems\n",
       "- Skills gaps in AI/ML expertise\n",
       "- Privacy and regulatory concerns\n",
       "\n",
       "North America leads regional adoption with 38% market share, particularly in financial services and healthcare verticals. Microsoft's implementation of NVIDIA inference solutions for Copilot demonstrates the technology's enterprise readiness.\n",
       "\n",
       "### Sources\n",
       "- Restack AI Hardware Analysis 2024: https://www.restack.io/p/hardware-innovations-for-ai-technologies-answer-leading-ai-hardware-companies-2024\n",
       "- NVIDIA Developer Blog: https://developer.nvidia.com/blog/optimize-ai-inference-performance-with-nvidia-full-stack-solutions/\n",
       "- Market.us AI Inference Report: https://scoop.market.us/ai-inference-server-market-news/\n",
       "\n",
       "## Fireworks AI Technical Analysis\n",
       "\n",
       "**Fireworks AI combines an innovative pricing model with proven enterprise performance, demonstrated by processing 140 billion tokens daily with 99.99% API uptime across 12,000 users.** Their tiered pricing structure scales with usage, starting at $0.10 per million tokens for small models and reaching $1.20 per million tokens for large MoE architectures.\n",
       "\n",
       "The platform offers specialized pricing for different modalities:\n",
       "- Text generation with parameter-based pricing ($0.10-$1.20/M tokens)\n",
       "- Image generation at $0.00013 per step\n",
       "- Speech-to-text processing from $0.0009 per audio minute\n",
       "- On-demand GPU deployments ranging from $2.90 to $9.99 per hour\n",
       "\n",
       "A notable implementation at Sourcegraph showcases the platform's capabilities, where StarCoder deployment doubled code completion acceptance rates while cutting backend latency by 50%. The company's recent $52M Series B funding values it at $552M, with Forbes estimating 2023 revenue at $3M.\n",
       "\n",
       "Enterprise customers including Uber, DoorDash, and Upwork have adopted Fireworks AI's infrastructure, citing lower costs and reduced latency compared to alternatives. The platform's spending limits increase with usage history, from $50/month to custom enterprise tiers exceeding $50,000/month.\n",
       "\n",
       "### Sources\n",
       "- Fireworks AI Blog Spring Update: https://fireworks.ai/blog/spring-update-faster-models-dedicated-deployments-postpaid-pricing\n",
       "- AWS Case Study: https://aws.amazon.com/solutions/case-studies/fireworks-ai-case-study/\n",
       "- Funding News: https://www.pymnts.com/news/investment-tracker/2024/fireworks-ai-valued-552-million-dollars-after-new-funding-round/\n",
       "\n",
       "## Together.ai's Inference Stack Analysis\n",
       "\n",
       "**Together.ai has revolutionized LLM inference by achieving 4x faster decoding throughput than open-source vLLM through an integrated approach combining hardware optimization and algorithmic innovations.** Their Inference Engine 2.0 demonstrates superior performance by processing over 400 tokens per second on Meta's Llama 3 8B model.\n",
       "\n",
       "The technical foundation relies on four key innovations:\n",
       "- FlashAttention-3 optimization achieving 75% GPU utilization\n",
       "- Custom-built draft models trained beyond 10x Chinchilla optimal\n",
       "- Advanced speculative decoding combining Medusa and Sequoia techniques\n",
       "- Quality-preserving quantization matching FP16 precision\n",
       "\n",
       "A notable case study demonstrates their efficiency at scale: using just two A100 GPUs, Together Lite outperforms vLLM running on eight H100 GPUs by 30% in common inference scenarios. This translates to a 12x cost reduction compared to standard deployments.\n",
       "\n",
       "The Enterprise Platform builds on these innovations while maintaining SOC 2, GDPR, and HIPAA compliance. Major enterprises including Salesforce and The Washington Post have validated its performance in production environments, contributing to Together.ai reaching $100M ARR within 10 months of launch.\n",
       "\n",
       "### Sources\n",
       "- Together Inference Engine 2.0 Announcement: https://www.together.ai/blog/together-inference-engine-2\n",
       "- Enterprise Platform Security: https://www.togetherplatform.com/security-compliance\n",
       "- Speculative Decoding Implementation: https://www.together.ai/blog/speculative-decoding-for-high-throughput-long-context-inference\n",
       "\n",
       "## Groq's Inference Engine Performance and Market Traction\n",
       "\n",
       "**Groq's Language Processing Unit (LPU) has demonstrated unprecedented inference speeds while achieving significant market validation, with an estimated $3.4 million revenue in 2023 and a $2.8 billion valuation following their August 2024 Series D round.**\n",
       "\n",
       "The LPU's competitive pricing structure ranges from $0.05 to $0.99 per million tokens, depending on model size and input/output requirements. For example, their Llama 3.3 70B implementation charges $0.59 per million input tokens and $0.79 per million output tokens, positioning them favorably against cloud competitors.\n",
       "\n",
       "Developer adoption has been robust, with notable implementations including:\n",
       "- Hunch AI Workspace for rapid prototyping\n",
       "- aiXplain's real-time inference solutions\n",
       "- Argonne National Laboratory's research applications\n",
       "- Embodied's Moxie education robot\n",
       "\n",
       "The platform offers an OpenAI-compatible API supporting multiple models including Llama 3.3, Mixtral 8x7b, and Gemma 2. Integration options include LangChain compatibility and Retrieval Augmented Generation capabilities, enabling developers to incorporate proprietary data into their applications.\n",
       "\n",
       "### Sources\n",
       "- Sacra Company Analysis: https://sacra.com/c/groq/\n",
       "- Groq Pricing Documentation: https://groq.com/pricing/\n",
       "- ChipStrat Analysis: https://www.chipstrat.com/p/the-rise-of-groq-slow-then-fast\n",
       "- Groq API Documentation: https://distilabel.argilla.io/1.2.1/api/llm/groq/\n",
       "\n",
       "## Market and Provider Analysis Summary\n",
       "\n",
       "The AI inference market is experiencing rapid growth, projected to reach $133.2 billion by 2034, with cloud deployment currently dominating at 55% market share. Among emerging providers, Fireworks AI, Together.ai, and Groq demonstrate distinct competitive advantages in performance and pricing strategies.\n",
       "\n",
       "| Provider | Key Differentiator | Performance Metric | Revenue/Valuation |\n",
       "|----------|-------------------|-------------------|-------------------|\n",
       "| Fireworks AI | Enterprise-grade reliability | 140B tokens/day, 99.99% uptime | $3M (2023), $552M valuation |\n",
       "| Together.ai | Advanced optimization stack | 4x faster than vLLM, 400 tokens/sec | $100M ARR |\n",
       "| Groq | Custom LPU architecture | Industry-leading latency | $3.4M (2023), $2.8B valuation |\n",
       "\n",
       "These providers are addressing key market barriers through innovative pricing models, ranging from $0.05 to $1.20 per million tokens, while delivering specialized solutions for different modalities and use cases. Their success in attracting major enterprise customers suggests growing market maturity, though NVIDIA's 80% chip market share indicates continued infrastructure dependencies."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "final_state = graph.get_state(thread)\n",
    "report = final_state.values.get('final_report')\n",
    "Markdown(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open-deep-research-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

================
File: src/open_deep_research/graph.py
================
from typing import Literal

from langchain_core.messages import HumanMessage, SystemMessage
from langchain.chat_models import init_chat_model
from langchain_core.runnables import RunnableConfig

from langgraph.constants import Send
from langgraph.graph import START, END, StateGraph
from langgraph.types import interrupt, Command

from open_deep_research.state import ReportStateInput, ReportStateOutput, Sections, ReportState, SectionState, SectionOutputState, Queries, Feedback
from open_deep_research.prompts import report_planner_query_writer_instructions, report_planner_instructions, query_writer_instructions, section_writer_instructions, final_section_writer_instructions, section_grader_instructions
from open_deep_research.configuration import Configuration
from open_deep_research.utils import tavily_search_async, deduplicate_and_format_sources, format_sections, perplexity_search, get_config_value

# Nodes
async def generate_report_plan(state: ReportState, config: RunnableConfig):
    """ Generate the report plan """

    # Inputs
    topic = state["topic"]
    feedback = state.get("feedback_on_report_plan", None)

    # Get configuration
    configurable = Configuration.from_runnable_config(config)
    report_structure = configurable.report_structure
    number_of_queries = configurable.number_of_queries

    # Convert JSON object to string if necessary
    if isinstance(report_structure, dict):
        report_structure = str(report_structure)

    # Set writer model (model used for query writing and section writing)
    writer_provider = get_config_value(configurable.writer_provider)
    writer_model_name = get_config_value(configurable.writer_model)
    writer_model = init_chat_model(model=writer_model_name, model_provider=writer_provider, temperature=0) 
    structured_llm = writer_model.with_structured_output(Queries)

    # Format system instructions
    system_instructions_query = report_planner_query_writer_instructions.format(topic=topic, report_organization=report_structure, number_of_queries=number_of_queries)

    # Generate queries  
    results = structured_llm.invoke([SystemMessage(content=system_instructions_query)]+[HumanMessage(content="Generate search queries that will help with planning the sections of the report.")])

    # Web search
    query_list = [query.search_query for query in results.queries]

    # Get the search API
    search_api = get_config_value(configurable.search_api)

    # Search the web
    if search_api == "tavily":
        search_results = await tavily_search_async(query_list)
        source_str = deduplicate_and_format_sources(search_results, max_tokens_per_source=1000, include_raw_content=False)
    elif search_api == "perplexity":
        search_results = perplexity_search(query_list)
        source_str = deduplicate_and_format_sources(search_results, max_tokens_per_source=1000, include_raw_content=False)
    else:
        raise ValueError(f"Unsupported search API: {configurable.search_api}")

    # Format system instructions
    system_instructions_sections = report_planner_instructions.format(topic=topic, report_organization=report_structure, context=source_str, feedback=feedback)

    # Set the planner provider
    if isinstance(configurable.planner_provider, str):
        planner_provider = configurable.planner_provider
    else:
        planner_provider = configurable.planner_provider.value

    # Set the planner model
    if isinstance(configurable.planner_model, str):
        planner_model = configurable.planner_model
    else:
        planner_model = configurable.planner_model.value

    # Set the planner model
    if planner_model == "claude-3-7-sonnet-latest":
        planner_llm = init_chat_model(model=planner_model, model_provider=planner_provider, max_tokens=20_000, thinking={"type": "enabled", "budget_tokens": 16_000})
        # with_structured_output uses forced tool calling, which thinking mode with Claude 3.7 does not support. Use bind_tools to generate the report sections
        structured_llm = planner_llm.bind_tools([Sections])
        report_sections = structured_llm.invoke([SystemMessage(content=system_instructions_sections)]+[HumanMessage(content="Generate the sections of the report. Your response must include a 'sections' field containing a list of sections. Each section must have: name, description, plan, research, and content fields.")])
        tool_call = report_sections.tool_calls[0]['args']
        report_sections = Sections.model_validate(tool_call)
    else:
        planner_llm = init_chat_model(model=planner_model, model_provider=planner_provider)
        structured_llm = planner_llm.with_structured_output(Sections)
        report_sections = structured_llm.invoke([SystemMessage(content=system_instructions_sections)]+[HumanMessage(content="Generate the sections of the report. Your response must include a 'sections' field containing a list of sections. Each section must have: name, description, plan, research, and content fields.")])

    # Get sections
    sections = report_sections.sections

    return {"sections": sections}

def human_feedback(state: ReportState, config: RunnableConfig) -> Command[Literal["generate_report_plan","build_section_with_web_research"]]:
    """ Get feedback on the report plan """

    # Get sections
    topic = state["topic"]
    sections = state['sections']
    sections_str = "\n\n".join(
        f"Section: {section.name}\n"
        f"Description: {section.description}\n"
        f"Research needed: {'Yes' if section.research else 'No'}\n"
        for section in sections
    )

    # Get feedback on the report plan from interrupt

    feedback = interrupt(f"Please provide feedback on the following report plan. \n\n{sections_str}\n\n Does the report plan meet your needs? Pass 'true' to approve the report plan or provide feedback to regenerate the report plan:")

    # If the user approves the report plan, kick off section writing
    # if isinstance(feedback, bool) and feedback is True:
    if isinstance(feedback, bool):
        # Treat this as approve and kick off section writing
        return Command(goto=[
            Send("build_section_with_web_research", {"topic": topic, "section": s, "search_iterations": 0}) 
            for s in sections 
            if s.research
        ])
    
    # If the user provides feedback, regenerate the report plan 
    elif isinstance(feedback, str):
        # treat this as feedback
        return Command(goto="generate_report_plan", 
                       update={"feedback_on_report_plan": feedback})
    else:
        raise TypeError(f"Interrupt value of type {type(feedback)} is not supported.")
    
def generate_queries(state: SectionState, config: RunnableConfig):
    """ Generate search queries for a report section """

    # Get state 
    topic = state["topic"]
    section = state["section"]

    # Get configuration
    configurable = Configuration.from_runnable_config(config)
    number_of_queries = configurable.number_of_queries

    # Generate queries 
    writer_provider = get_config_value(configurable.writer_provider)
    writer_model_name = get_config_value(configurable.writer_model)
    writer_model = init_chat_model(model=writer_model_name, model_provider=writer_provider, temperature=0) 
    structured_llm = writer_model.with_structured_output(Queries)

    # Format system instructions
    system_instructions = query_writer_instructions.format(topic=topic, section_topic=section.description, number_of_queries=number_of_queries)

    # Generate queries  
    queries = structured_llm.invoke([SystemMessage(content=system_instructions)]+[HumanMessage(content="Generate search queries on the provided topic.")])

    return {"search_queries": queries.queries}

async def search_web(state: SectionState, config: RunnableConfig):
    """ Search the web for each query, then return a list of raw sources and a formatted string of sources."""
    
    # Get state 
    search_queries = state["search_queries"]

    # Get configuration
    configurable = Configuration.from_runnable_config(config)

    # Web search
    query_list = [query.search_query for query in search_queries]
    
    # Get the search API
    search_api = get_config_value(configurable.search_api)

    # Search the web
    if search_api == "tavily":
        search_results = await tavily_search_async(query_list)
        source_str = deduplicate_and_format_sources(search_results, max_tokens_per_source=5000, include_raw_content=True)
    elif search_api == "perplexity":
        search_results = perplexity_search(query_list)
        source_str = deduplicate_and_format_sources(search_results, max_tokens_per_source=5000, include_raw_content=False)
    else:
        raise ValueError(f"Unsupported search API: {configurable.search_api}")

    return {"source_str": source_str, "search_iterations": state["search_iterations"] + 1}

def write_section(state: SectionState, config: RunnableConfig) -> Command[Literal[END, "search_web"]]:
    """ Write a section of the report """

    # Get state 
    topic = state["topic"]
    section = state["section"]
    source_str = state["source_str"]

    # Get configuration
    configurable = Configuration.from_runnable_config(config)

    # Format system instructions
    system_instructions = section_writer_instructions.format(topic=topic, section_title=section.name, section_topic=section.description, context=source_str, section_content=section.content)

    # Generate section  
    writer_provider = get_config_value(configurable.writer_provider)
    writer_model_name = get_config_value(configurable.writer_model)
    writer_model = init_chat_model(model=writer_model_name, model_provider=writer_provider, temperature=0) 
    section_content = writer_model.invoke([SystemMessage(content=system_instructions)]+[HumanMessage(content="Generate a report section based on the provided sources.")])
    
    # Write content to the section object  
    section.content = section_content.content

    # Grade prompt 
    section_grader_instructions_formatted = section_grader_instructions.format(topic=topic, section_topic=section.description,section=section.content)

    # Feedback 
    structured_llm = writer_model.with_structured_output(Feedback)
    feedback = structured_llm.invoke([SystemMessage(content=section_grader_instructions_formatted)]+[HumanMessage(content="Grade the report and consider follow-up questions for missing information:")])

    if feedback.grade == "pass" or state["search_iterations"] >= configurable.max_search_depth:
        # Publish the section to completed sections 
        return  Command(
        update={"completed_sections": [section]},
        goto=END
    )
    else:
        # Update the existing section with new content and update search queries
        return  Command(
        update={"search_queries": feedback.follow_up_queries, "section": section},
        goto="search_web"
        )
    
def write_final_sections(state: SectionState, config: RunnableConfig):
    """ Write final sections of the report, which do not require web search and use the completed sections as context """

    # Get configuration
    configurable = Configuration.from_runnable_config(config)

    # Get state 
    topic = state["topic"]
    section = state["section"]
    completed_report_sections = state["report_sections_from_research"]
    
    # Format system instructions
    system_instructions = final_section_writer_instructions.format(topic=topic, section_title=section.name, section_topic=section.description, context=completed_report_sections)

    # Generate section  
    writer_provider = get_config_value(configurable.writer_provider)
    writer_model_name = get_config_value(configurable.writer_model)
    writer_model = init_chat_model(model=writer_model_name, model_provider=writer_provider, temperature=0) 
    section_content = writer_model.invoke([SystemMessage(content=system_instructions)]+[HumanMessage(content="Generate a report section based on the provided sources.")])
    
    # Write content to section 
    section.content = section_content.content

    # Write the updated section to completed sections
    return {"completed_sections": [section]}

def gather_completed_sections(state: ReportState):
    """ Gather completed sections from research and format them as context for writing the final sections """    

    # List of completed sections
    completed_sections = state["completed_sections"]

    # Format completed section to str to use as context for final sections
    completed_report_sections = format_sections(completed_sections)

    return {"report_sections_from_research": completed_report_sections}

def initiate_final_section_writing(state: ReportState):
    """ Write any final sections using the Send API to parallelize the process """    

    # Kick off section writing in parallel via Send() API for any sections that do not require research
    return [
        Send("write_final_sections", {"topic": state["topic"], "section": s, "report_sections_from_research": state["report_sections_from_research"]}) 
        for s in state["sections"] 
        if not s.research
    ]

def compile_final_report(state: ReportState):
    """ Compile the final report """    

    # Get sections
    sections = state["sections"]
    completed_sections = {s.name: s.content for s in state["completed_sections"]}

    # Update sections with completed content while maintaining original order
    for section in sections:
        section.content = completed_sections[section.name]

    # Compile final report
    all_sections = "\n\n".join([s.content for s in sections])

    return {"final_report": all_sections}

# Report section sub-graph -- 

# Add nodes 
section_builder = StateGraph(SectionState, output=SectionOutputState)
section_builder.add_node("generate_queries", generate_queries)
section_builder.add_node("search_web", search_web)
section_builder.add_node("write_section", write_section)

# Add edges
section_builder.add_edge(START, "generate_queries")
section_builder.add_edge("generate_queries", "search_web")
section_builder.add_edge("search_web", "write_section")

# Outer graph -- 

# Add nodes
builder = StateGraph(ReportState, input=ReportStateInput, output=ReportStateOutput, config_schema=Configuration)
builder.add_node("generate_report_plan", generate_report_plan)
builder.add_node("human_feedback", human_feedback)
builder.add_node("build_section_with_web_research", section_builder.compile())
builder.add_node("gather_completed_sections", gather_completed_sections)
builder.add_node("write_final_sections", write_final_sections)
builder.add_node("compile_final_report", compile_final_report)

# Add edges
builder.add_edge(START, "generate_report_plan")
builder.add_edge("generate_report_plan", "human_feedback")
builder.add_edge("build_section_with_web_research", "gather_completed_sections")
builder.add_conditional_edges("gather_completed_sections", initiate_final_section_writing, ["write_final_sections"])
builder.add_edge("write_final_sections", "compile_final_report")
builder.add_edge("compile_final_report", END)

graph = builder.compile()

================
File: src/open_deep_research/prompts.py
================
# Prompt to generate search queries to help with planning the report
report_planner_query_writer_instructions="""You are an expert technical writer, helping to plan a report. 

<Report topic>
{topic}
</Report topic>

<Report organization>
{report_organization}
</Report organization>

<Task>
Your goal is to generate {number_of_queries} search queries that will help gather comprehensive information for planning the report sections. 

The queries should:

1. Be related to the topic of the report
2. Help satisfy the requirements specified in the report organization

Make the queries specific enough to find high-quality, relevant sources while covering the breadth needed for the report structure.
</Task>
"""

# Prompt to generate the report plan
report_planner_instructions="""I want a plan for a report. 

<Task>
Generate a list of sections for the report.

Each section should have the fields:

- Name - Name for this section of the report.
- Description - Brief overview of the main topics covered in this section.
- Research - Whether to perform web research for this section of the report.
- Content - The content of the section, which you will leave blank for now.

For example, introduction and conclusion will not require research because they will distill information from other parts of the report.
</Task>

<Topic>
The topic of the report is:
{topic}
</Topic>

<Report organization>
The report should follow this organization: 
{report_organization}
</Report organization>

<Context>
Here is context to use to plan the sections of the report: 
{context}
</Context>

<Feedback>
Here is feedback on the report structure from review (if any):
{feedback}
</Feedback>
"""

# Query writer instructions
query_writer_instructions="""You are an expert technical writer crafting targeted web search queries that will gather comprehensive information for writing a technical report section.

<Report topic>
{topic}
</Report topic>

<Section topic>
{section_topic}
</Section topic>

<Task>
Your goal is to generate {number_of_queries} search queries that will help gather comprehensive information above the section topic. 

The queries should:

1. Be related to the topic 
2. Examine different aspects of the topic

Make the queries specific enough to find high-quality, relevant sources.
</Task>
"""

# Section writer instructions
section_writer_instructions = """You are an expert technical writer crafting one section of a technical report.

<Report topic>
{topic}
</Report topic>

<Section topic>
{section_topic}
</Section topic>

<Existing section content (if populated)>
{section_content}
</Existing section content>

<Source material>
{context}
</Source material>

<Guidelines for writing>
1. If the existing section content is not populated, write a new section from scratch.
2. If the existing section content is populated, write a new section that synthesizes the existing section content with the new information.
</Guidelines for writing>

<Length and style>
- Strict 150-200 word limit
- No marketing language
- Technical focus
- Write in simple, clear language
- Start with your most important insight in **bold**
- Use short paragraphs (2-3 sentences max)
- Use ## for section title (Markdown format)
- Only use ONE structural element IF it helps clarify your point:
  * Either a focused table comparing 2-3 key items (using Markdown table syntax)
  * Or a short list (3-5 items) using proper Markdown list syntax:
    - Use `*` or `-` for unordered lists
    - Use `1.` for ordered lists
    - Ensure proper indentation and spacing
- End with ### Sources that references the below source material formatted as:
  * List each source with title, date, and URL
  * Format: `- Title : URL`
</Length and style>

<Quality checks>
- Exactly 150-200 words (excluding title and sources)
- Careful use of only ONE structural element (table or list) and only if it helps clarify your point
- One specific example / case study
- Starts with bold insight
- No preamble prior to creating the section content
- Sources cited at end
</Quality checks>
"""

# Instructions for section grading
section_grader_instructions = """Review a report section relative to the specified topic:

<Report topic>
{topic}
</Report topic>

<section topic>
{section_topic}
</section topic>

<section content>
{section}
</section content>

<task>
Evaluate whether the section adequately covers the topic by checking technical accuracy and depth.

If the section fails any criteria, generate specific follow-up search queries to gather missing information.
</task>

<format>
    grade: Literal["pass","fail"] = Field(
        description="Evaluation result indicating whether the response meets requirements ('pass') or needs revision ('fail')."
    )
    follow_up_queries: List[SearchQuery] = Field(
        description="List of follow-up search queries.",
    )
</format>
"""

final_section_writer_instructions="""You are an expert technical writer crafting a section that synthesizes information from the rest of the report.

<Report topic>
{topic}
</Report topic>

<Section topic> 
{section_topic}
</Section topic>

<Available report content>
{context}
</Available report content>

<Task>
1. Section-Specific Approach:

For Introduction:
- Use # for report title (Markdown format)
- 50-100 word limit
- Write in simple and clear language
- Focus on the core motivation for the report in 1-2 paragraphs
- Use a clear narrative arc to introduce the report
- Include NO structural elements (no lists or tables)
- No sources section needed

For Conclusion/Summary:
- Use ## for section title (Markdown format)
- 100-150 word limit
- For comparative reports:
    * Must include a focused comparison table using Markdown table syntax
    * Table should distill insights from the report
    * Keep table entries clear and concise
- For non-comparative reports: 
    * Only use ONE structural element IF it helps distill the points made in the report:
    * Either a focused table comparing items present in the report (using Markdown table syntax)
    * Or a short list using proper Markdown list syntax:
      - Use `*` or `-` for unordered lists
      - Use `1.` for ordered lists
      - Ensure proper indentation and spacing
- End with specific next steps or implications
- No sources section needed

3. Writing Approach:
- Use concrete details over general statements
- Make every word count
- Focus on your single most important point
</Task>

<Quality Checks>
- For introduction: 50-100 word limit, # for report title, no structural elements, no sources section
- For conclusion: 100-150 word limit, ## for section title, only ONE structural element at most, no sources section
- Markdown format
- Do not include word count or any preamble in your response
</Quality Checks>"""

================
File: src/open_deep_research/state.py
================
from typing import Annotated, List, TypedDict, Literal
from pydantic import BaseModel, Field
import operator

class Section(BaseModel):
    name: str = Field(
        description="Name for this section of the report.",
    )
    description: str = Field(
        description="Brief overview of the main topics and concepts to be covered in this section.",
    )
    research: bool = Field(
        description="Whether to perform web research for this section of the report."
    )
    content: str = Field(
        description="The content of the section."
    )   

class Sections(BaseModel):
    sections: List[Section] = Field(
        description="Sections of the report.",
    )

class SearchQuery(BaseModel):
    search_query: str = Field(None, description="Query for web search.")

class Queries(BaseModel):
    queries: List[SearchQuery] = Field(
        description="List of search queries.",
    )

class Feedback(BaseModel):
    grade: Literal["pass","fail"] = Field(
        description="Evaluation result indicating whether the response meets requirements ('pass') or needs revision ('fail')."
    )
    follow_up_queries: List[SearchQuery] = Field(
        description="List of follow-up search queries.",
    )

class ReportStateInput(TypedDict):
    topic: str # Report topic
    
class ReportStateOutput(TypedDict):
    final_report: str # Final report

class ReportState(TypedDict):
    topic: str # Report topic    
    feedback_on_report_plan: str # Feedback on the report plan
    sections: list[Section] # List of report sections 
    completed_sections: Annotated[list, operator.add] # Send() API key
    report_sections_from_research: str # String of any completed sections from research to write final sections
    final_report: str # Final report

class SectionState(TypedDict):
    topic: str # Report topic
    section: Section # Report section  
    search_iterations: int # Number of search iterations done
    search_queries: list[SearchQuery] # List of search queries
    source_str: str # String of formatted source content from web search
    report_sections_from_research: str # String of any completed sections from research to write final sections
    completed_sections: list[Section] # Final key we duplicate in outer state for Send() API

class SectionOutputState(TypedDict):
    completed_sections: list[Section] # Final key we duplicate in outer state for Send() API

================
File: src/open_deep_research/utils.py
================
import os
import asyncio
import requests

from tavily import TavilyClient, AsyncTavilyClient
from open_deep_research.state import Section
from langsmith import traceable

tavily_client = TavilyClient()
tavily_async_client = AsyncTavilyClient()

def get_config_value(value):
    """
    Helper function to handle both string and enum cases of configuration values
    """
    return value if isinstance(value, str) else value.value

def deduplicate_and_format_sources(search_response, max_tokens_per_source, include_raw_content=True):
    """
    Takes a list of search responses and formats them into a readable string.
    Limits the raw_content to approximately max_tokens_per_source.
 
    Args:
        search_responses: List of search response dicts, each containing:
            - query: str
            - results: List of dicts with fields:
                - title: str
                - url: str
                - content: str
                - score: float
                - raw_content: str|None
        max_tokens_per_source: int
        include_raw_content: bool
            
    Returns:
        str: Formatted string with deduplicated sources
    """
     # Collect all results
    sources_list = []
    for response in search_response:
        sources_list.extend(response['results'])
    
    # Deduplicate by URL
    unique_sources = {source['url']: source for source in sources_list}

    # Format output
    formatted_text = "Sources:\n\n"
    for i, source in enumerate(unique_sources.values(), 1):
        formatted_text += f"Source {source['title']}:\n===\n"
        formatted_text += f"URL: {source['url']}\n===\n"
        formatted_text += f"Most relevant content from source: {source['content']}\n===\n"
        if include_raw_content:
            # Using rough estimate of 4 characters per token
            char_limit = max_tokens_per_source * 4
            # Handle None raw_content
            raw_content = source.get('raw_content', '')
            if raw_content is None:
                raw_content = ''
                print(f"Warning: No raw_content found for source {source['url']}")
            if len(raw_content) > char_limit:
                raw_content = raw_content[:char_limit] + "... [truncated]"
            formatted_text += f"Full source content limited to {max_tokens_per_source} tokens: {raw_content}\n\n"
                
    return formatted_text.strip()

def format_sections(sections: list[Section]) -> str:
    """ Format a list of sections into a string """
    formatted_str = ""
    for idx, section in enumerate(sections, 1):
        formatted_str += f"""
{'='*60}
Section {idx}: {section.name}
{'='*60}
Description:
{section.description}
Requires Research: 
{section.research}

Content:
{section.content if section.content else '[Not yet written]'}

"""
    return formatted_str

@traceable
async def tavily_search_async(search_queries):
    """
    Performs concurrent web searches using the Tavily API.

    Args:
        search_queries (List[SearchQuery]): List of search queries to process

    Returns:
            List[dict]: List of search responses from Tavily API, one per query. Each response has format:
                {
                    'query': str, # The original search query
                    'follow_up_questions': None,      
                    'answer': None,
                    'images': list,
                    'results': [                     # List of search results
                        {
                            'title': str,            # Title of the webpage
                            'url': str,              # URL of the result
                            'content': str,          # Summary/snippet of content
                            'score': float,          # Relevance score
                            'raw_content': str|None  # Full page content if available
                        },
                        ...
                    ]
                }
    """
    
    search_tasks = []
    for query in search_queries:
            search_tasks.append(
                tavily_async_client.search(
                    query,
                    max_results=5,
                    include_raw_content=True,
                    topic="general"
                )
            )

    # Execute all searches concurrently
    search_docs = await asyncio.gather(*search_tasks)

    return search_docs

@traceable
def perplexity_search(search_queries):
    """Search the web using the Perplexity API.
    
    Args:
        search_queries (List[SearchQuery]): List of search queries to process
  
    Returns:
        List[dict]: List of search responses from Perplexity API, one per query. Each response has format:
            {
                'query': str,                    # The original search query
                'follow_up_questions': None,      
                'answer': None,
                'images': list,
                'results': [                     # List of search results
                    {
                        'title': str,            # Title of the search result
                        'url': str,              # URL of the result
                        'content': str,          # Summary/snippet of content
                        'score': float,          # Relevance score
                        'raw_content': str|None  # Full content or None for secondary citations
                    },
                    ...
                ]
            }
    """

    headers = {
        "accept": "application/json",
        "content-type": "application/json",
        "Authorization": f"Bearer {os.getenv('PERPLEXITY_API_KEY')}"
    }
    
    search_docs = []
    for query in search_queries:

        payload = {
            "model": "sonar-pro",
            "messages": [
                {
                    "role": "system",
                    "content": "Search the web and provide factual information with sources."
                },
                {
                    "role": "user",
                    "content": query
                }
            ]
        }
        
        response = requests.post(
            "https://api.perplexity.ai/chat/completions",
            headers=headers,
            json=payload
        )
        response.raise_for_status()  # Raise exception for bad status codes
        
        # Parse the response
        data = response.json()
        content = data["choices"][0]["message"]["content"]
        citations = data.get("citations", ["https://perplexity.ai"])
        
        # Create results list for this query
        results = []
        
        # First citation gets the full content
        results.append({
            "title": f"Perplexity Search, Source 1",
            "url": citations[0],
            "content": content,
            "raw_content": content,
            "score": 1.0  # Adding score to match Tavily format
        })
        
        # Add additional citations without duplicating content
        for i, citation in enumerate(citations[1:], start=2):
            results.append({
                "title": f"Perplexity Search, Source {i}",
                "url": citation,
                "content": "See primary source for full content",
                "raw_content": None,
                "score": 0.5  # Lower score for secondary sources
            })
        
        # Format response to match Tavily structure
        search_docs.append({
            "query": query,
            "follow_up_questions": None,
            "answer": None,
            "images": [],
            "results": results
        })
    
    return search_docs



================================================================
End of Codebase
================================================================

================
File: examples/arxiv.md
================
# Obesity Among Young Adults in the United States: A Growing Public Health Challenge

The obesity epidemic among young adults in the United States represents a complex public health crisis shaped by interconnected social, economic, and environmental factors. Recent research reveals that over one-third of US adults suffer from obesity, with rates disproportionately affecting disadvantaged communities. This health challenge extends beyond individual choices, as built environment characteristics and socioeconomic conditions explain up to 90% of obesity prevalence variation across American cities. Understanding these systemic influences is crucial for developing effective interventions that address both individual and community-level factors contributing to obesity among young adults.

## Obesity Prevalence and Trends in US Young Adults

**Over one-third of US adults suffer from obesity, with the condition showing strong correlations to socioeconomic and environmental factors that disproportionately affect disadvantaged communities.** National data reveals systematic variations in obesity rates that map closely to neighborhood characteristics and built environment features.

Advanced analysis using satellite imagery and machine learning has demonstrated that built environment characteristics explain 72-90% of obesity prevalence variation at the census tract level across major US cities. These correlations are particularly pronounced in disadvantaged neighborhoods where multiple social determinants of health intersect.

Key factors associated with higher adult obesity rates include:
- Lower median household income
- Limited health insurance coverage
- Higher concentration of rental housing
- Reduced access to physical activity resources
- Higher poverty rates

A comprehensive study in Shelby County, Tennessee exemplifies these patterns, showing significantly higher obesity prevalence in areas with multiple socioeconomic challenges. The findings suggest that addressing structural and environmental factors may be as crucial as individual interventions for reducing obesity rates.

### Sources
- Association Between Neighborhood Factors and Adult Obesity in Shelby County, Tennessee (2022): http://arxiv.org/abs/2208.05335v1
- Using Deep Learning to Examine the Association between the Built Environment and Neighborhood Adult Obesity Prevalence (2017): http://arxiv.org/abs/1711.00885v1
- Progress of the anti-obesity of Berberine (2025): http://arxiv.org/abs/2501.02282v1

## Socioeconomic Determinants of Obesity in Young Adults

**Social and economic disparities create stark differences in obesity prevalence among young adults, with disadvantaged neighborhoods showing up to 90% higher rates compared to affluent areas.** Research from Shelby County, Tennessee demonstrates how multiple socioeconomic factors intersect to influence obesity risk through both direct and indirect pathways.

Key social determinants shaping obesity outcomes include:
* Median household income - Affects access to healthy food options
* Insurance status - Determines preventive care availability
* Housing conditions - Influences exposure to obesity-promoting environments
* Education level - Impacts health literacy and dietary choices
* Geographic location - Correlates with neighborhood resources

Advanced geospatial analysis reveals that built environment characteristics explain 72-90% of obesity variation across cities. In Shelby County, census tracts with higher percentages of uninsured residents, home renters, and individuals living below the poverty level demonstrated significantly elevated obesity rates.

These findings emphasize the need for obesity interventions that address systemic inequalities rather than focusing solely on individual behavior modification. Public health initiatives must consider how social determinants create barriers to healthy weight maintenance.

### Sources
- Association Between Neighborhood Factors and Adult Obesity in Shelby County, Tennessee: http://arxiv.org/abs/2208.05335v1
- Using Deep Learning to Examine the Association between the Built Environment and Neighborhood Adult Obesity Prevalence: http://arxiv.org/abs/1711.00885v1

## Built Environment's Impact on Obesity

**The physical design of urban spaces significantly influences obesity rates, with walkability and food accessibility emerging as critical factors that can increase obesity risk by up to 42% in underserved areas.** Research demonstrates that neighborhood characteristics create complex ecosystems affecting dietary health and physical activity patterns.

The built environment shapes obesity risk through three primary mechanisms: food accessibility, physical activity opportunities, and socioeconomic factors. Studies reveal that areas with limited walkability and higher concentrations of fast-food establishments, particularly through online food delivery platforms, create "cyber food swamps" that contribute to unhealthy dietary choices. A 10% increase in accessible fast-food options raises the probability of unhealthy food orders by 22%.

Key built environment factors affecting obesity include:
* Walking infrastructure and neighborhood walkability
* Distance to healthy food retailers versus fast food
* Availability of recreational facilities
* Transportation access
* Socioeconomic status of the area

Recent research in tertiary education campuses demonstrates that improving walkability can increase positive walking experiences by 9.75%, suggesting that targeted modifications to the built environment could help reduce obesity rates.

### Sources
- Using Tableau and Google Map API for Understanding the Impact of Walkability on Dublin City: http://arxiv.org/abs/2310.07563v1
- Exploring the Causal Relationship between Walkability and Affective Walking Experience: http://arxiv.org/abs/2311.06262v1
- Cyber Food Swamps: Investigating the Impacts of Online-to-Offline Food Delivery Platforms: http://arxiv.org/abs/2409.16601v2
- The association between neighborhood obesogenic factors and prostate cancer risk and mortality: http://arxiv.org/abs/2405.18456v1

## Machine Learning Applications in Obesity Analysis

**Advanced machine learning and deep learning techniques are revolutionizing obesity research by uncovering complex patterns in environmental, behavioral, and socioeconomic factors, with prediction accuracies reaching up to 88% for adolescent obesity risk.**

Recent studies using deep learning analysis of satellite imagery have demonstrated that built environment features can explain 72-90% of obesity prevalence variation across U.S. cities. This breakthrough enables automated assessment of neighborhood characteristics that influence obesity rates at the census tract level.

Machine learning models have identified key social determinants of health strongly correlated with adult obesity, including:
* Median household income
* Housing status (rental vs. ownership)
* Insurance coverage
* Race and ethnicity demographics
* Age distribution
* Marital status

Novel applications include DeepHealthNet, which achieves 88.4% accuracy in adolescent obesity prediction by analyzing physical activity patterns and health metrics. Similarly, recurrent neural networks analyzing longitudinal patient records and wearable device data have achieved 77-86% accuracy in predicting obesity status improvements.

These insights are particularly valuable for public health decision-making, enabling targeted interventions in disadvantaged neighborhoods where obesity prevalence is significantly higher.

### Sources
- Using Deep Learning to Examine the Built Environment and Neighborhood Adult Obesity: http://arxiv.org/abs/1711.00885v1
- DeepHealthNet: Adolescent Obesity Prediction System: http://arxiv.org/abs/2308.14657v2
- Association Between Neighborhood Factors and Adult Obesity in Shelby County, Tennessee: http://arxiv.org/abs/2208.05335v1
- Recurrent Neural Networks based Obesity Status Prediction: http://arxiv.org/abs/1809.07828v1

## Current Interventions and Policy Recommendations

**Current obesity interventions targeting young adults must shift from individual-focused approaches to addressing systemic neighborhood-level factors that drive health disparities.** Research demonstrates that built environment characteristics explain up to 90% of obesity prevalence variation across cities, highlighting the critical role of structural determinants.

Recent geospatial analyses have identified key social determinants that shape obesity rates in disadvantaged communities, including housing stability, food access, and neighborhood infrastructure. The Shelby County, Tennessee case study reveals significant associations between obesity prevalence and multiple socioeconomic factors, particularly in areas with lower median household incomes and higher percentages of uninsured residents.

To develop more effective interventions, policymakers should prioritize:
* Implementing zoning policies that promote physical activity
* Improving access to healthy food options in underserved areas
* Addressing housing stability through rental assistance programs
* Expanding health insurance coverage in high-risk communities
* Investing in neighborhood infrastructure improvements

These evidence-based policy measures represent a crucial shift toward addressing the root causes of obesity through coordinated community-level interventions rather than focusing solely on individual behavior change.

### Sources
- Association Between Neighborhood Factors and Adult Obesity in Shelby County, Tennessee: http://arxiv.org/abs/2208.05335v1
- Using Deep Learning to Examine the Built Environment and Neighborhood Adult Obesity Prevalence: http://arxiv.org/abs/1711.00885v1
- Structured psychosocial stress and the US obesity epidemic: http://arxiv.org/abs/q-bio/0312011v1

# Obesity in Young Adults: A Complex Public Health Challenge

The rising prevalence of obesity among young adults in the United States represents a critical public health challenge shaped by interconnected social, economic, and environmental factors. Recent research reveals that over one-third of US adults suffer from obesity, with rates disproportionately affecting disadvantaged communities. Advanced analysis demonstrates that neighborhood characteristics and built environment features explain up to 90% of obesity prevalence variation across major cities, highlighting how systemic inequalities create barriers to maintaining healthy weight.

## Key Findings and Future Directions

The evidence demonstrates that obesity in young adults stems from complex interactions between built environment, socioeconomic factors, and healthcare access. Machine learning analyses have revolutionized our understanding of these relationships, achieving prediction accuracies up to 88% for obesity risk. The research points to critical areas requiring immediate intervention:

* Built Environment Modifications
  - Improve neighborhood walkability
  - Increase access to recreational facilities
  - Address food desert challenges
  - Regulate "cyber food swamps"

* Policy Interventions
  - Expand health insurance coverage
  - Implement supportive housing policies
  - Develop targeted community programs
  - Enhance public transportation access

Success in reducing obesity rates will require coordinated efforts that address these systemic factors rather than focusing solely on individual behavior change. Future initiatives must prioritize evidence-based structural interventions that promote health equity across all communities.

================
File: examples/inference-market-gpt45.md
================
# Introduction

The AI inference market is rapidly expanding, driven by growing demand for real-time data processing and advancements in specialized hardware and cloud-based solutions. This report examines three innovative companiesâ€”Fireworks AI, Together.ai, and Groqâ€”that are shaping the competitive landscape. Fireworks AI offers flexible, multimodal inference solutions; Together.ai emphasizes optimized performance for open-source models; and Groq delivers unmatched speed through custom hardware. By analyzing their technologies, market positioning, and performance metrics, this report provides insights into how these key players are influencing the future of AI inference.

## Market Overview of AI Inference

**The global AI inference server market is experiencing rapid growth, projected to expand from USD 38.4 billion in 2023 to USD 166.7 billion by 2031, at a CAGR of 18%.** This growth is driven by increasing demand for real-time data processing, advancements in AI technologies, and widespread adoption of cloud-based and edge computing solutions.

North America currently dominates the market, accounting for approximately 38% of global revenue, due to its advanced technological infrastructure, significant R&D investments, and presence of major industry players such as NVIDIA, Intel, and Dell. Asia-Pacific is expected to exhibit the highest growth rate, driven by rapid digital transformation initiatives and government support for AI adoption, particularly in China, India, and Japan.

Key factors influencing market growth include:

- Rising adoption of AI-driven applications in healthcare, finance, automotive, and retail sectors.
- Increased deployment of specialized hardware (GPUs, TPUs, FPGAs) optimized for AI workloads.
- Growing preference for cloud-based deployment models due to scalability and cost-effectiveness.

However, high initial implementation costs, complexity of integration, and data privacy concerns remain significant challenges.

### Sources

- AI Inference Server Market Size, Scope, Growth, and Forecast : https://www.verifiedmarketresearch.com/product/ai-inference-server-market/
- AI Server Market Size & Share, Growth Forecasts Report 2032 : https://www.gminsights.com/industry-analysis/ai-server-market
- AI Inference Server Market Forecast To 2032 : https://www.businessresearchinsights.com/market-reports/ai-inference-server-market-118293

## Deep Dive: Fireworks AI

**Fireworks AI provides a flexible inference platform optimized for deploying and fine-tuning large language models (LLMs), emphasizing ease of use, scalability, and performance customization.**

The platform supports two primary deployment modes: serverless inference and dedicated deployments. Serverless inference allows quick experimentation with popular pre-deployed models like Llama 3.1 405B, billed per token without guaranteed SLAs. Dedicated deployments offer private, GPU-based infrastructure with performance guarantees, supporting both base models and efficient Low-Rank Adaptation (LoRA) addons.

Fireworks AI's Document Inlining feature notably extends text-based models into multimodal capabilities, enabling visual reasoning tasks by seamlessly integrating image and PDF content. Performance optimization techniques include quantization, batching, and caching, tailored to specific use cases such as chatbots and coding assistants requiring low latency.

Competitively, Fireworks AI positions itself against providers like OpenAI and Cohere, with a recent Series B funding round of $52M, total funding of $77M, and estimated annual recurring revenue (ARR) around $6M.

- Founded: 2022
- Headquarters: Redwood City, CA
- Employees: ~60
- Key Investors: Sequoia Capital, NVIDIA, AMD Ventures

### Sources
- Overview - Fireworks AI Docs : https://docs.fireworks.ai/models/overview  
- Performance optimization - Fireworks AI Docs : https://docs.fireworks.ai/faq/deployment/performance/optimization  
- DeepSeek R1 Just Got Eyes with Fireworks AI Document Inlining : https://fireworks.ai/blog/deepseek-r1-got-eyes  
- Fireworks AI 2025 Company Profile: Valuation, Funding & Investors : https://pitchbook.com/profiles/company/561272-14  
- Fireworks AI: Contact Details, Revenue, Funding, Employees and Company Profile : https://siliconvalleyjournals.com/company/fireworks-ai/  
- Fireworks AI - Overview, News & Similar companies - ZoomInfo : https://www.zoominfo.com/c/fireworks-ai-inc/5000025791  
- Fireworks AI Stock Price, Funding, Valuation, Revenue & Financial : https://www.cbinsights.com/company/fireworks-ai/financials

## Deep Dive: Together.ai

**Together.ai differentiates itself in the AI inference market through its comprehensive cloud platform, optimized for rapid inference, extensive model selection, and flexible GPU infrastructure.**

Together.ai provides a robust cloud-based solution for training, fine-tuning, and deploying generative AI models, emphasizing high-performance inference capabilities. Its inference engine leverages proprietary technologies such as FlashAttention-3 and speculative decoding, achieving inference speeds up to four times faster than competitors. The platform supports over 100 open-source models, including popular large language models (LLMs) like Llama-2 and RedPajama, enabling developers to quickly experiment and deploy tailored AI solutions.

Together.ai's flexible GPU clusters, featuring NVIDIA H100 and H200 GPUs interconnected via high-speed Infiniband networks, facilitate scalable distributed training and inference workloads. This infrastructure positions Together.ai competitively against GPU cloud providers like CoreWeave and Lambda Labs, particularly for startups and enterprises requiring variable compute resources.

Financially, Together.ai has demonstrated rapid growth, reaching an estimated $130M ARR in 2024, driven by increasing demand for generative AI applications and developer-friendly tooling.

### Sources
- Together AI: Reviews, Features, Pricing, Guides, and Alternatives : https://aipure.ai/products/together-ai
- Together AI revenue, valuation & growth rate | Sacra : https://sacra.com/c/together-ai/
- AI Solutions with Together.ai: Inference, Fine-Tuning & Models : https://pwraitools.com/generative-ai-tools/ai-solutions-with-together-ai-inference-fine-tuning-and-models/

## Deep Dive: Groq

**Groq's vertically integrated Tensor Streaming Processor (TSP) architecture delivers unmatched inference performance and energy efficiency, significantly outperforming traditional GPUs.**

Groq's TSP chip achieves inference speeds of 500-700 tokens per second on large language models, representing a 5-10x improvement over Nvidia's latest GPUs. Independent benchmarks confirm Groq's LPU (Language Processing Unit) reaches 276 tokens per second on Meta's Llama 3.3 70B model, maintaining consistent performance across varying context lengths without typical latency trade-offs.

Groq's unique hardware-software co-design eliminates external memory dependencies, embedding memory directly on-chip. This approach reduces data movement, resulting in up to 10x greater energy efficiency compared to GPUs. GroqCloud, the company's cloud inference platform, supports popular open-source models and has attracted over 360,000 developers.

Financially, Groq has raised $640 million in a Series D round at a $2.8 billion valuation, reflecting strong market confidence. Groq plans to deploy over 108,000 LPUs by early 2025, positioning itself as a leading provider of low-latency AI inference infrastructure.

### Sources
- Groq revenue, valuation & funding | Sacra : https://sacra.com/c/groq/
- Groq Raises $640M To Meet Soaring Demand for Fast AI Inference : https://groq.com/news_press/groq-raises-640m-to-meet-soaring-demand-for-fast-ai-inference/
- New AI Inference Speed Benchmark for Llama 3.3 70B, Powered by Groq : https://groq.com/new-ai-inference-speed-benchmark-for-llama-3-3-70b-powered-by-groq/
- Groq Inference Performance, Quality, & Cost Savings : https://groq.com/inference/
- GroqThoughts PowerPaper 2024 : https://groq.com/wp-content/uploads/2024/07/GroqThoughts_PowerPaper_2024.pdf

## Comparative Analysis

**Fireworks AI, Together.ai, and Groq each offer distinct strengths in AI inference, targeting different market segments and performance needs.**

Fireworks AI emphasizes speed and scalability through its proprietary FireAttention inference engine, delivering multi-modal capabilities (text, image, audio) with low latency. It prioritizes data privacy, maintaining HIPAA and SOC2 compliance, and offers flexible deployment options including serverless and on-demand models.

Together.ai differentiates itself by providing optimized inference for over 200 open-source large language models (LLMs). It achieves sub-100ms latency through automated infrastructure optimizations such as token caching, load balancing, and model quantization. Its cost-effective approach makes it attractive for developers requiring extensive model variety and scalability.

Groq specializes in hardware-accelerated inference, leveraging its custom Tensor Streaming Processor (TSP) chip architecture. GroqCloud provides ultra-low latency inference performance (500-700 tokens/second), significantly outperforming traditional GPUs. Groq targets latency-sensitive enterprise applications, including conversational AI and autonomous systems, with both cloud and on-premises deployment options.

| Feature             | Fireworks AI                 | Together.ai                  | Groq                          |
|---------------------|------------------------------|------------------------------|-------------------------------|
| Technology          | Proprietary inference engine | Optimized open-source models | Custom hardware (TSP chips)   |
| Market Positioning  | Multi-modal, privacy-focused | Cost-effective, scalable     | Ultra-low latency enterprise  |
| Revenue Estimates   | Not publicly available       | Not publicly available       | $3.4M (2023)                  |
| Performance Metrics | Low latency, multi-modal     | Sub-100ms latency            | 500-700 tokens/sec inference  |

### Sources
- Fireworks AI vs GroqCloud Platform Comparison 2025 | PeerSpot : https://www.peerspot.com/products/comparisons/fireworks-ai_vs_groqcloud-platform
- Fireworks AI vs Together Inference Comparison 2025 | PeerSpot : https://www.peerspot.com/products/comparisons/fireworks-ai_vs_together-inference
- Top 10 AI Inference Platforms in 2025 - DEV Community : https://dev.to/lina_lam_9ee459f98b67e9d5/top-10-ai-inference-platforms-in-2025-56kd
- Groq revenue, valuation & funding | Sacra : https://sacra.com/c/groq/

## Conclusion and Synthesis

The AI inference market is rapidly expanding, projected to reach $166.7 billion by 2031, driven by demand for real-time processing and specialized hardware. Fireworks AI, Together.ai, and Groq each offer distinct competitive advantages:

| Feature            | Fireworks AI                      | Together.ai                      | Groq                             |
|--------------------|-----------------------------------|----------------------------------|----------------------------------|
| Core Strength      | Multi-modal, privacy-focused      | Extensive open-source support    | Custom hardware, ultra-low latency |
| Technology         | Proprietary inference engine      | Optimized GPU infrastructure     | Tensor Streaming Processor (TSP) |
| Revenue Estimates  | ~$6M ARR                          | ~$130M ARR                       | ~$3.4M ARR                       |
| Performance        | Low latency, flexible deployment  | Sub-100ms latency                | 500-700 tokens/sec inference     |

Next steps include monitoring Groq's hardware adoption, evaluating Together.ai's scalability for diverse models, and assessing Fireworks AI's multimodal capabilities for specialized enterprise applications.

================
File: examples/inference-market.md
================
# The AI Inference Market: Analyzing Emerging Leaders

The AI inference market is experiencing unprecedented growth, projected to reach $133.2 billion by 2034, as specialized providers challenge traditional semiconductor dominance. While established chip manufacturers control over 80% of the market, new entrants like Fireworks, Together.ai, and Groq are reshaping the competitive landscape through innovative approaches to inference optimization and pricing.

This analysis examines how these emerging players are disrupting the market through differentiated technologies, aggressive pricing strategies, and superior performance metrics, particularly in the rapidly expanding cloud-based inference segment that now represents 55% of total market share. Their success highlights a fundamental shift in how AI computation is being delivered and monetized.

## AI Inference Market Overview

**The global AI inference market is experiencing unprecedented growth, projected to reach $133.2 billion by 2034, with a transformative shift occurring in market dynamics as new specialized providers challenge traditional semiconductor dominance.**

While established chip manufacturers (NVIDIA, AMD, Intel) control 80-82% of the market, emerging players are gaining traction through differentiated approaches. The market expansion is particularly evident in cloud-based deployments, which now represent 55% of total market share.

Key factors driving market evolution include:
* Increasing demand for real-time processing capabilities
* Shift toward token-based pricing models
* Rising adoption of specialized AI hardware
* Growth in open-source model deployment
* Integration of edge computing solutions

North America maintains market leadership with 38% global share, generating $9.34 billion in revenue (2024). This dominance stems from robust digital infrastructure and concentrated presence of technology companies, particularly in the United States where revenue reaches $8.6 billion.

The market shows sustained growth potential, supported by ongoing infrastructure investments and technological innovation, particularly in cloud-based deployments where North America maintains clear leadership.

### Sources
- AI Inference Server Market Forecast : https://www.einpresswire.com/article/779610673/ai-inference-server-market-supports-new-technology-with-usd-133-2-billion-by-2034-regional-growth-at-usd-9-34-billion
- SemiAnalysis Market Report : https://semianalysis.com/2024/02/21/groq-inference-tokenomics-speed-but/
- Markets and Markets AI Inference Report : https://www.marketsandmarkets.com/Market-Reports/ai-inference-market-189921964.html

## Fireworks.ai Profile

**Fireworks.ai has emerged as a significant AI inference provider by focusing on performance optimization, reaching a $552M valuation in 2024 with an estimated $44M in annual revenue.** Their platform serves over 25 billion tokens daily to more than 23,000 developers through a tiered pricing structure that scales with usage.

The company's technical differentiation comes from custom optimizations like FireAttention, which demonstrates superior performance metrics compared to competitors. Benchmark tests show up to 5.6x higher throughput and 12.2x lower latency versus vLLM for Mixtral 8x7B models in fp8 format.

Their pricing model combines usage-based tiers with flexible deployment options:
* Basic tier: $50/month spending limit
* Growth tier: $500/month spending limit
* Scale tier: $5,000/month spending limit
* Enterprise tier: Custom limits with dedicated support
* On-demand GPU deployments: $2.90-$9.99 per hour

Notable enterprise customers including DoorDash, Quora, and Upwork validate their approach. Since founding in 2022, Fireworks has secured $77M in funding from investors like Benchmark and Sequoia Capital.

### Sources
- Fireworks AI Valued at $552M: https://www.pymnts.com/news/investment-tracker/2024/fireworks-ai-valued-552-million-dollars-after-new-funding-round/
- FireAttention v3 Performance Metrics: https://fireworks.ai/blog/fireattention-v3
- AWS Case Study: https://aws.amazon.com/solutions/case-studies/fireworks-ai-case-study/

## Together.ai Profile

**Together.ai has established itself as a major AI inference provider by combining competitive pricing with superior technical performance, reaching a $3.3B valuation in early 2024.** Their platform supports over 200 open-source models and serves both individual developers and enterprise customers through a tiered pricing structure.

The company's technical advantage stems from their integrated inference stack, which delivers up to 400 tokens per second on Llama models. This performance translates to significant cost savings, with their 70B parameter models priced at $0.88 per million tokensâ€”substantially below market rates.

Their pricing strategy segments customers into three tiers:
- Build: Pay-as-you-go with $1 free credit for developers
- Scale: Reserved GPU instances for production workloads
- Enterprise: Private deployments with custom optimization

Notable enterprise adoption includes Salesforce, Zoom, and The Washington Post, validating their platform's capabilities. Together.ai's recent $305M Series B funding demonstrates strong market confidence in their approach to democratizing AI infrastructure.

### Sources
- Together.ai Series B Announcement: https://www.together.ai/blog/together-ai-announcing-305m-series-b
- Together.ai Pricing Strategy: https://canvasbusinessmodel.com/blogs/marketing-strategy/together-ai-marketing-strategy
- Salesforce Ventures Investment: https://salesforceventures.com/perspectives/welcome-together-ai/

## Groq Profile

**Groq's Language Processing Unit (LPU) represents a radical departure from traditional GPU architectures, delivering superior inference performance at significantly lower costs.** Their proprietary tensor-streaming processor achieves 241 tokens per second for Llama 2 Chat (70B), more than double competing solutions, while maintaining exceptional energy efficiency at 1-3 joules per token.

The company's aggressive pricing strategy undercuts competitors, offering Mixtral 8x7B inference at $0.24 per million tokens compared to Fireworks' $0.50. This pricing advantage stems from lower manufacturing costs ($6,000 per 14nm wafer vs. $16,000 for NVIDIA's 5nm H100) and architectural efficiencies.

Key competitive advantages:
- Superior inference speed: Up to 18x faster than cloud competitors
- Cost efficiency: $20,000 per LPU vs $25,000+ for NVIDIA H100
- Energy optimization: 80 TB/s bandwidth with 750 TOPS at INT8

Recently valued at $2.8 billion after raising $640M, Groq has gained significant traction with over 360,000 developers on GroqCloud. While 2023 revenue was modest at $3.4M, planned deployment of 108,000 LPUs by Q1 2025 positions them for substantial growth in the expanding inference market.

### Sources
- Groq Report Analysis: https://notice-reports.s3.amazonaws.com/Groq%20Report%202024.12.23_17.58.23.pdf
- SemiAnalysis Pricing Study: https://semianalysis.com/2024/02/21/groq-inference-tokenomics-speed-but/
- Groq Funding Announcement: https://www.prnewswire.com/news-releases/groq-raises-640m-to-meet-soaring-demand-for-fast-ai-inference-302214097.html

## Comparative Performance Analysis

**Recent benchmarks reveal Groq as the current performance leader in LLM inference, with Together.ai and Fireworks competing for second position across key metrics.** Independent testing from ArtificialAnalysis.ai shows significant variations in core performance indicators:

| Provider | TTFT (seconds) | Tokens/Second | Cost (per 1M tokens) |
|----------|---------------|---------------|---------------------|
| Groq | 0.22 | 241 | $0.27 |
| Together | 0.50 | 117 | $0.88 |
| Fireworks | 0.40 | 98 | $0.90 |

Performance advantages can vary significantly based on specific workloads and model sizes. Together.ai's Inference Engine 2.0 demonstrates strong performance with smaller models, while Fireworks maintains consistent performance across their model range.

A notable limitation emerges with larger inputs - Groq shows a 560% increase in TTFT when processing 10K versus 1K input tokens. This suggests optimal use cases may differ between providers despite headline performance metrics.

The competitive landscape remains dynamic, with providers regularly releasing optimization updates that can significantly impact these metrics.

### Sources
- ArtificialAnalysis.ai LLM Benchmark: https://wandb.ai/capecape/benchmark_llama_70b/reports/Is-the-new-Cerebras-API-the-fastest-LLM-service-provider
- Comparative Analysis of AI API Providers: https://friendli.ai/blog/comparative-analysis-ai-api-provider
- Together Inference Engine Analysis: https://www.together.ai/blog/together-inference-engine-v1

## Conclusion and Market Outlook

The AI inference market is rapidly evolving with specialized providers challenging traditional semiconductor dominance. Our analysis reveals distinct competitive advantages among emerging leaders:

| Provider | Key Strength | Performance | Pricing | Market Position |
|----------|--------------|-------------|----------|-----------------|
| Groq | Custom LPU Architecture | 241 tokens/sec | $0.24/M tokens | $2.8B valuation, disruptive hardware |
| Together.ai | Model Variety | 117 tokens/sec | $0.88/M tokens | $3.3B valuation, broad adoption |
| Fireworks | Optimization Tech | 98 tokens/sec | $0.90/M tokens | $552M valuation, developer focus |

Looking ahead, Groq's superior performance metrics and aggressive pricing position them to capture significant market share, particularly in high-throughput applications. Together.ai's extensive model support and enterprise relationships suggest continued growth in the mid-market segment, while Fireworks' optimization technology provides a strong foundation for specialized use cases. As the market expands toward $133.2B by 2034, these providers are well-positioned to challenge NVIDIA's dominance through differentiated approaches to inference delivery.

================
File: examples/pubmed.md
================
# Diabetic Nephropathy Treatment: Current Approaches and Future Directions

Diabetic nephropathy has emerged as the leading cause of end-stage renal disease worldwide, affecting approximately 40% of diabetes patients. The condition's progressive nature and complex pathophysiology demand early intervention through comprehensive treatment strategies. Recent advances in therapeutic options, from SGLT2 inhibitors to non-steroidal mineralocorticoid receptor antagonists, have transformed the management landscape. This report examines current treatment protocols, emerging therapies, and diagnostic approaches, with particular emphasis on the growing importance of personalized medicine and integrated care models in improving patient outcomes.

## Key Treatment Advances and Future Directions

Modern diabetic nephropathy management has evolved into a sophisticated, multi-faceted approach that combines established treatments with innovative therapies. The emergence of the four-pillar treatment strategy, incorporating RAS blockers, SGLT2 inhibitors, GLP-1 receptor agonists, and finerenone, represents a significant advancement in care standards. Technological progress in diagnostic tools, particularly multiparametric MRI and novel biomarkers, enables earlier intervention and more precise monitoring of disease progression.

Key developments driving treatment evolution:
* Integration of multiple therapeutic agents for enhanced outcomes
* Adoption of personalized medicine approaches using proteomics
* Implementation of comprehensive care models showing cost-effective results
* Advanced imaging techniques enabling non-invasive monitoring
* Emergence of novel biomarkers for earlier detection

The future of diabetic nephropathy treatment lies in closing the evidence-to-practice gap and expanding access to these advanced therapeutic options.

## Prevalence and Mechanisms of Diabetic Nephropathy

**Diabetic nephropathy has become the leading cause of end-stage renal disease worldwide, affecting approximately 40% of diabetes patients and contributing to 38% of renal disease cases in regions like the Philippines.**

The pathogenesis involves complex interactions between metabolic and hemodynamic factors. Hyperglycemia triggers increased production of advanced glycation end-products (AGEs) and activates inflammatory pathways, while concurrent hypertension amplifies kidney damage through elevated glomerular pressure. The condition typically develops over 10-15 years as these mechanisms progressively damage the kidney's filtering system.

Key risk factors that accelerate nephropathy progression include:
* Poorly controlled blood glucose (HbA1c >7%)
* Sustained hypertension (>130/80 mmHg)
* Genetic variants in ACE and APOL1 genes
* Obesity and smoking
* Limited access to regular screening

Recent guidelines from KDIGO emphasize the importance of early detection and holistic care through multidisciplinary teams. The initial presentation typically involves microalbuminuria, which can progress to overt proteinuria and declining glomerular filtration rate without intervention. Research shows that aggressive early treatment can delay or prevent progression, particularly when addressing both glycemic control and blood pressure management.

### Sources
- Diabetic Nephropathy: StatPearls : https://pubmed.ncbi.nlm.nih.gov/30480939/
- Current status of diabetes mellitus care in the Philippines : https://pubmed.ncbi.nlm.nih.gov/38382166/
- Lifestyle Modifications in Delaying CKD Progression : https://pubmed.ncbi.nlm.nih.gov/36874334/

## Biomarkers for Early Detection of Diabetic Nephropathy

**The landscape of diabetic nephropathy detection is rapidly evolving beyond traditional microalbuminuria testing, as emerging biomarkers offer more precise and earlier disease identification.** While microalbuminuria remains the clinical standard, its limited predictive power has driven research into more sophisticated detection methods.

Recent studies have identified several promising biomarker categories that can detect kidney damage before albumin changes become apparent. These include markers of specific nephron damage sites, oxidative stress indicators, and inflammatory signals. A comprehensive 2024 review highlighted five key biomarker categories:

- Glomerular damage markers
- Tubular damage indicators
- Oxidative stress biomarkers
- Inflammatory biomarkers
- Novel molecular markers (miRNAs, proteomics, metabolomics)

A significant advancement comes from combining multiple biomarker types. For example, integrating serum creatinine with cystatin C measurements has demonstrated superior accuracy in detecting early kidney dysfunction, particularly when using newer race-free prediction equations. This multi-marker approach reflects the complex pathophysiology of diabetic kidney disease and enables more personalized intervention strategies.

### Sources
- Insights into the Novel Biomarkers Expressed in Diabetic Nephropathy (2024): https://pubmed.ncbi.nlm.nih.gov/39415582/
- Diagnostic challenges of diabetic kidney disease (2023): https://pubmed.ncbi.nlm.nih.gov/37545693/
- Urinary biomarkers for early diabetic nephropathy (2014): https://pubmed.ncbi.nlm.nih.gov/25060761/

## Treatment Protocols for Diabetic Nephropathy

**Modern diabetic nephropathy management requires a comprehensive approach combining established treatments with emerging therapeutic options to effectively slow disease progression and protect kidney function.** The foundation remains strict glycemic control (HbA1c <7%) and blood pressure management (<130/80 mmHg in patients with albuminuria).

Renin-angiotensin system (RAS) blockers, particularly ACE inhibitors and ARBs, continue as first-line treatments for their dual action on blood pressure and nephroprotection. Recent evidence supports combination therapy with newer agents for enhanced outcomes.

Key therapeutic advances include:
* SGLT2 inhibitors (dapagliflozin, empagliflozin) - reduce disease progression by promoting urinary potassium excretion and normalizing plasma potassium levels
* Non-steroidal mineralocorticoid receptor antagonists (finerenone) - decrease albuminuria and cardiovascular complications
* Lifestyle modifications - Mediterranean diet adherence and regular exercise show significant benefits
* Antioxidant interventions - target oxidative stress mechanisms

The SONAR trial demonstrated that atrasentan, an endothelin receptor antagonist, significantly decreased renal events in diabetic kidney disease patients. Regular monitoring of kidney function, albuminuria, and electrolyte levels remains essential for optimizing treatment outcomes.

### Sources
- What Not to Overlook in the Management of Patients with Type 2 Diabetes Mellitus: https://pubmed.ncbi.nlm.nih.gov/39062970/
- Lifestyle Modifications and Nutritional and Therapeutic Interventions: https://pubmed.ncbi.nlm.nih.gov/36874334/
- Diabetic Kidney Disease: https://pubmed.ncbi.nlm.nih.gov/25905328/
- Impaired distal renal potassium handling in diabetic mice: https://pubmed.ncbi.nlm.nih.gov/38779755/

## Recent Advances in Diabetic Nephropathy Treatment

**The emergence of a four-pillar treatment approach represents a paradigm shift in diabetic nephropathy management, moving beyond the traditional reliance on RAS blockade alone to include multiple complementary therapeutic agents.** This comprehensive strategy has demonstrated superior cardiorenal protection compared to single-agent approaches.

The four essential pillars of modern treatment include:

* RAS blockers (ACE inhibitors/ARBs) as foundational therapy
* SGLT2 inhibitors for reducing kidney disease progression
* GLP-1 receptor agonists for glycemic control and renoprotection
* Finerenone, a non-steroidal mineralocorticoid receptor antagonist, for additional protection

Recent clinical trials suggest that combining these therapies may provide additive benefits, though ongoing studies are still evaluating optimal combinations. The PRIORITY study exemplifies the movement toward personalized medicine, using urinary proteomics to predict treatment response and guide therapy selection.

Implementation challenges persist, with many eligible patients not receiving recommended combinations. Healthcare systems are addressing this through specialized clinics and electronic health record-based decision support tools to narrow the evidence-to-practice gap.

### Sources
- Finerenone: Do We Really Need an Additional Therapy in Type 2 Diabetes Mellitus and Kidney Disease?: https://pubmed.ncbi.nlm.nih.gov/39862018/
- Slowing the Progression of Chronic Kidney Disease in Patients with Type 2 Diabetes Using Four Pillars of Therapy: https://pubmed.ncbi.nlm.nih.gov/39259460/
- Updated evidence on cardiovascular and renal effects of GLP-1 receptor agonists: https://pubmed.ncbi.nlm.nih.gov/39548500/

## Noninvasive MRI Techniques for Diabetic Nephropathy Assessment

**Multiparametric MRI represents a breakthrough in noninvasive renal assessment, enabling detailed evaluation of kidney structure and function without radiation or contrast agents.** This technology combines multiple specialized imaging sequences to provide comprehensive insights into kidney health.

The diffusion-weighted imaging (DWI) sequence measures water molecule movement, offering early detection of interstitial fibrosis and predictive value for renal function deterioration in diabetic nephropathy. Blood oxygen level-dependent (BOLD) MRI assesses tissue oxygenation by detecting deoxyhemoglobin levels, proving particularly valuable for monitoring chronic kidney disease progression.

Key MRI sequences and their clinical applications:
- T1/T2 Relaxometry: Evaluates tissue water content and fibrosis; corticomedullary changes correlate with filtration rate
- DWI: Measures microstructural changes and fibrosis development
- BOLD: Monitors tissue oxygenation and predicts functional decline
- Arterial Spin Labeling: Assesses renal hemodynamics without contrast

While these techniques show promise for early disease detection and monitoring, further clinical trials are needed before widespread implementation. The technology's potential for personalized treatment decisions and virtual biopsy capabilities represents a significant advance in diabetic nephropathy management.

### Sources
- Multiparametric MRI: can we assess renal function differently? (2024): https://pubmed.ncbi.nlm.nih.gov/40008350/
- Noninvasive Assessment of Diabetic Kidney Disease With MRI: Hype or Hope? (2023): https://pubmed.ncbi.nlm.nih.gov/37675919/

## Integrated Care and Systemic Challenges in Diabetic Nephropathy Management

**Quality improvement collaboratives in integrated diabetes care settings can significantly improve patient outcomes while remaining cost-effective, with studies showing increased life expectancy of nearly one year for male patients and 0.76 years for female patients.** The success of such integrated approaches demonstrates the critical importance of coordinated care between specialists in managing diabetic nephropathy.

However, implementing effective integrated care faces several systemic barriers that must be addressed:

* Limited specialist availability in rural regions
* Poor communication between healthcare providers
* Insurance coverage restrictions
* Lack of standardized protocols
* Delayed specialist referrals

A notable example comes from a Netherlands study of integrated diabetes care across 37 general practices and 13 outpatient clinics. Their collaborative care model reduced cardiovascular event risk (hazard ratio: 0.83 for men, 0.98 for women) and cardiovascular mortality (hazard ratio: 0.78 for men, 0.88 for women). The program cost approximately â‚¬22 per patient initially, with lifetime costs increasing by â‚¬860 for men and â‚¬645 for women â€“ proving highly cost-effective at under â‚¬2,000 per quality-adjusted life year.

### Sources
- Cost-effectiveness of a quality improvement collaborative focusing on patients with diabetes: https://pubmed.ncbi.nlm.nih.gov/20808258/

# Diabetic Nephropathy Treatment: Current Approaches and Future Directions

Diabetic nephropathy has emerged as the leading cause of end-stage renal disease globally, affecting 40% of diabetes patients and demanding increasingly sophisticated treatment approaches. The evolution of treatment strategies from single-agent protocols to comprehensive four-pillar approaches, combined with advances in early detection and monitoring, has transformed the management landscape. This report examines current best practices, emerging therapies, and the critical role of integrated care in improving patient outcomes.

## Key Findings and Treatment Framework

Modern diabetic nephropathy management has evolved into a multi-faceted approach requiring careful coordination of therapeutic strategies. The evidence supports a structured treatment framework that combines established protocols with emerging innovations.

* Foundation Treatments
  - Glycemic control (HbA1c <7%)
  - Blood pressure management (<130/80 mmHg)
  - RAS blockers (ACE inhibitors/ARBs)
  - Lifestyle modifications

* Emerging Therapeutic Advances
  - SGLT2 inhibitors for disease progression
  - Non-steroidal mineralocorticoid receptor antagonists
  - GLP-1 receptor agonists
  - Multiparametric MRI for monitoring

The path forward requires addressing implementation challenges through integrated care models while leveraging new diagnostic tools and biomarkers for earlier intervention. Success depends on bridging the evidence-to-practice gap through specialized clinics and improved coordination among healthcare providers.

================
File: langgraph.json
================
{
    "dockerfile_lines": [],
    "graphs": {
      "open_deep_research": "./src/open_deep_research/graph.py:graph"
    },
    "python_version": "3.11",
    "env": "./.env",
    "dependencies": [
      "."
    ]
  }

================
File: pyproject.toml
================
[project]
name = "open_deep_research"
version = "0.0.7"
description = "Planning, research, and report generation."
authors = [
    { name = "Lance Martin" }
]
readme = "README.md"
license = { text = "MIT" }
requires-python = ">=3.9"
dependencies = [
    "langgraph>=0.2.55",
    "langchain-community>=0.3.9",
    "langchain-openai>=0.3.7",
    "langchain-anthropic>=0.3.9",
    "openai>=1.61.0",
    "tavily-python>=0.5.0",
    "langchain-groq>=0.2.4",
    "exa-py>=1.8.9",
    "arxiv>=2.1.3",
    "pymupdf>=1.25.3",
    "xmltodict>=0.14.2",
    "linkup-sdk>=0.2.3",
]

[project.optional-dependencies]
dev = ["mypy>=1.11.1", "ruff>=0.6.1"]

[build-system]
requires = ["setuptools>=73.0.0", "wheel"]
build-backend = "setuptools.build_meta"

[tool.setuptools]
packages = ["open_deep_research"]

[tool.setuptools.package-dir]
"open_deep_research" = "src/open_deep_research"

[tool.setuptools.package-data]
"*" = ["py.typed"]

[tool.ruff]
lint.select = [
    "E",    # pycodestyle
    "F",    # pyflakes
    "I",    # isort
    "D",    # pydocstyle
    "D401", # First line should be in imperative mood
    "T201",
    "UP",
]
lint.ignore = [
    "UP006",
    "UP007",
    "UP035",
    "D417",
    "E501",
]

[tool.ruff.lint.per-file-ignores]
"tests/*" = ["D", "UP"]

[tool.ruff.lint.pydocstyle]
convention = "google"

================
File: README.md
================
# Open Deep Research
 
Open Deep Research is a web research assistant that generates comprehensive reports on any topic following a workflow similar to [OpenAI](https://openai.com/index/introducing-deep-research/) and [Gemini](https://blog.google/products/gemini/google-gemini-deep-research/) Deep Research. However, it allows you to customize the models, prompts, report structure, search API, and research depth. Specifically, you can customize:

- provide an outline with a desired report structure
- set the planner model (e.g., DeepSeek, OpenAI reasoning model, etc)
- give feedback on the plan of report sections and iterate until user approval 
- set the search API (e.g., Tavily, Perplexity) and # of searches to run for each research iteration
- set the depth of search for each section (# of iterations of writing, reflection, search, re-write)
- customize the writer model (e.g., Anthropic)

![report-generation](https://github.com/user-attachments/assets/6595d5cd-c981-43ec-8e8b-209e4fefc596)

## ðŸš€ Quickstart

Ensure you have API keys set for your desired tools.

Select a web search tool (by default Open Deep Research uses Tavily):

* [Tavily API](https://tavily.com/) - General web search
* [Perplexity API](https://www.perplexity.ai/hub/blog/introducing-the-sonar-pro-api) - General web search
* [Exa API](https://exa.ai/) - Powerful neural search for web content
* [ArXiv](https://arxiv.org/) - Academic papers in physics, mathematics, computer science, and more
* [PubMed](https://pubmed.ncbi.nlm.nih.gov/) - Biomedical literature from MEDLINE, life science journals, and online books
* [Linkup API](https://www.linkup.so/) - General web search

Select a writer model (by default Open Deep Research uses Anthropic Claude 3.5 Sonnet):

* [Anthropic](https://www.anthropic.com/)
* [OpenAI](https://openai.com/)
* [Groq](https://groq.com/)

Select a planner model (by default Open Deep Research uses Claude 3.7 Sonnet with thinking enabled):

* [Anthropic](https://www.anthropic.com/)
* [OpenAI](https://openai.com/)
* [Groq](https://groq.com/)

### Using the package

(Recommended: Create a virtual environment):
```bash
python -m venv open_deep_research
source open_deep_research/bin/activate
```

Install:
```bash
pip install open-deep-research
```

Ensure API keys are set for web search and planner / writer models, for example:
```bash
export TAVILY_API_KEY=<your_tavily_api_key>
export ANTHROPIC_API_KEY=<your_anthropic_api_key>
```

See [src/open_deep_research/graph.ipynb](src/open_deep_research/graph.ipynb) for an example of usage in a Jupyter notebook.

Import and compile the graph:
```python
from langgraph.checkpoint.memory import MemorySaver
from open_deep_research.graph import builder
memory = MemorySaver()
graph = builder.compile(checkpointer=memory)
```

View the graph:
```python
from IPython.display import Image, display
display(Image(graph.get_graph(xray=1).draw_mermaid_png()))
```

Run the graph with a desired topic and configuration:
```python
import uuid 
thread = {"configurable": {"thread_id": str(uuid.uuid4()),
                           "search_api": "tavily",
                           "planner_provider": "openai",
                           "planner_model": "claude-3-7-sonnet-latest",
                           "writer_provider": "anthropic",
                           "writer_model": "claude-3-5-sonnet-latest",
                           "max_search_depth": 1,
                           }}

topic = "Overview of the AI inference market with focus on Fireworks, Together.ai, Groq"
async for event in graph.astream({"topic":topic,}, thread, stream_mode="updates"):
    print(event)
    print("\n")
```

The graph will stop when the report plan is generated, and you can pass feedback to update the report plan:
```python
from langgraph.types import Command
async for event in graph.astream(Command(resume="Include a revenue estimate (ARR) in the sections"), thread, stream_mode="updates"):
    print(event)
    print("\n")
```

When you are satisfied with the report plan, you can pass `True` to proceed to report generation:
```python
# Pass True to approve the report plan and proceed to report generation
async for event in graph.astream(Command(resume=True), thread, stream_mode="updates"):
    print(event)
    print("\n")
```

### Running LangGraph Studio UI locally

Clone the repository:
```bash
git clone https://github.com/langchain-ai/open_deep_research.git
cd open_deep_research
```

Edit the `.env` file with your API keys (e.g., the API keys for default selections are shown below):

```bash
cp .env.example .env
```

Set whatever APIs needed for your model and search tool choices
```bash
export TAVILY_API_KEY=<your_tavily_api_key>
export ANTHROPIC_API_KEY=<your_anthropic_api_key>
export OPENAI_API_KEY=<your_openai_api_key>
export PERPLEXITY_API_KEY=<your_perplexity_api_key>
export EXA_API_KEY=<your_exa_api_key>
export PUBMED_API_KEY=<your_pubmed_api_key>
export PUBMED_EMAIL=<your_email@example.com>
export LINKUP_API_KEY=<your_linkup_api_key>
```

Launch the assistant with the LangGraph server locally, which will open in your browser:

#### Mac

```bash
# Install uv package manager
curl -LsSf https://astral.sh/uv/install.sh | sh

# Install dependencies and start the LangGraph server
uvx --refresh --from "langgraph-cli[inmem]" --with-editable . --python 3.11 langgraph dev
```

#### Windows

```powershell
# Install dependencies 
pip install -e .
pip install langgraph-cli[inmem]

# Start the LangGraph server
langgraph dev
```

Use this to open the Studio UI:
```
- ðŸš€ API: http://127.0.0.1:2024
- ðŸŽ¨ Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024
- ðŸ“š API Docs: http://127.0.0.1:2024/docs
```

(1) Provide a `Topic` and hit `Submit`:

<img width="1326" alt="input" src="https://github.com/user-attachments/assets/de264b1b-8ea5-4090-8e72-e1ef1230262f" />

(2) This will generate a report plan and present it to the user for review.

(3) We can pass a string (`"..."`) with feedback to regenerate the plan based on the feedback.

<img width="1326" alt="feedback" src="https://github.com/user-attachments/assets/c308e888-4642-4c74-bc78-76576a2da919" />

(4) Or, we can just pass `true` to accept the plan.

<img width="1480" alt="accept" src="https://github.com/user-attachments/assets/ddeeb33b-fdce-494f-af8b-bd2acc1cef06" />

(5) Once accepted, the report sections will be generated.

<img width="1326" alt="report_gen" src="https://github.com/user-attachments/assets/74ff01cc-e7ed-47b8-bd0c-4ef615253c46" />

The report is produced as markdown.

<img width="1326" alt="report" src="https://github.com/user-attachments/assets/92d9f7b7-3aea-4025-be99-7fb0d4b47289" />

## ðŸ“– Customizing the report

You can customize the research assistant's behavior through several parameters:

- `report_structure`: Define a custom structure for your report (defaults to a standard research report format)
- `number_of_queries`: Number of search queries to generate per section (default: 2)
- `max_search_depth`: Maximum number of reflection and search iterations (default: 2)
- `planner_provider`: Model provider for planning phase (default: "openai", but can be "groq")
- `planner_model`: Specific model for planning (default: "o3-mini", but can be any Groq hosted model such as "deepseek-r1-distill-llama-70b")
- `writer_model`: Model for writing the report (default: "claude-3-5-sonnet-latest")
- `search_api`: API to use for web searches (default: "tavily", options include "perplexity", "exa", "arxiv", "pubmed", "linkup")

These configurations allow you to fine-tune the research process based on your needs, from adjusting the depth of research to selecting specific AI models for different phases of report generation.

### Search API Configuration

Not all search APIs support additional configuration parameters. Here are the ones that do:

- **Exa**: `max_characters`, `num_results`, `include_domains`, `exclude_domains`, `subpages`
  - Note: `include_domains` and `exclude_domains` cannot be used together
  - Particularly useful when you need to narrow your research to specific trusted sources, ensure information accuracy, or when your research requires using specified domains (e.g., academic journals, government sites)
  - Provides AI-generated summaries tailored to your specific query, making it easier to extract relevant information from search results
- **ArXiv**: `load_max_docs`, `get_full_documents`, `load_all_available_meta`
- **PubMed**: `top_k_results`, `email`, `api_key`, `doc_content_chars_max`
- **Linkup**: `depth`

Example with Exa configuration:
```python
thread = {"configurable": {"thread_id": str(uuid.uuid4()),
                           "search_api": "exa",
                           "search_api_config": {
                               "num_results": 5,
                               "include_domains": ["nature.com", "sciencedirect.com"]
                           },
                           # Other configuration...
                           }}
```

### Model Considerations

(1) With Groq, there are token per minute (TPM) limits if you are on the `on_demand` service tier:
- The `on_demand` service tier has a limit of `6000 TPM`
- You will want a [paid plan](https://github.com/cline/cline/issues/47#issuecomment-2640992272) for section writing with Groq models

(2) `deepseek` [isn't great at function calling](https://api-docs.deepseek.com/guides/reasoning_model). Our assistant uses function calling to generate structured outputs for report sections and search queries within each section.  
- Because, section writing performs a larger number of function calls, OpenAI, Anthropic, and certain OSS models that are stromng at function calling like Groq's `llama-3.3-70b-versatile` are advised.
- If you see the following error, it is likely due to the model not being able to produce structured outputs (see [trace](https://smith.langchain.com/public/8a6da065-3b8b-4a92-8df7-5468da336cbe/r)):
```
groq.APIError: Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.
```

## How it works
   
1. `Plan and Execute` - Open Deep Research follows a [plan-and-execute workflow](https://github.com/assafelovic/gpt-researcher) that separates planning from research, allowing for human-in-the-loop approval of a report plan before the more time-consuming research phase. It uses, by default, a [reasoning model](https://www.youtube.com/watch?v=f0RbwrBcFmc) to plan the report sections. During this phase, it uses web search to gather general information about the report topic to help in planning the report sections. But, it also accepts a report structure from the user to help guide the report sections as well as human feedback on the report plan.
   
2. `Research and Write` - Each section of the report is written in parallel. The research assistant uses web search via [Tavily API](https://tavily.com/), [Perplexity](https://www.perplexity.ai/hub/blog/introducing-the-sonar-pro-api), [Exa](https://exa.ai/), [ArXiv](https://arxiv.org/), [PubMed](https://pubmed.ncbi.nlm.nih.gov/) or [Linkup](https://www.linkup.so/) to gather information about each section topic. It will reflect on each report section and suggest follow-up questions for web search. This "depth" of research will proceed for any many iterations as the user wants. Any final sections, such as introductions and conclusions, are written after the main body of the report is written, which helps ensure that the report is cohesive and coherent. The planner determines main body versus final sections during the planning phase.

3. `Managing different types` - Open Deep Research is built on LangGraph, which has native support for configuration management [using assistants](https://langchain-ai.github.io/langgraph/concepts/assistants/). The report `structure` is a field in the graph configuration, which allows users to create different assistants for different types of reports. 

## UX

### Local deployment

Follow the [quickstart](#-quickstart) to start LangGraph server locally.

### Hosted deployment
 
You can easily deploy to [LangGraph Platform](https://langchain-ai.github.io/langgraph/concepts/#deployment-options).

================
File: src/open_deep_research/__init__.py
================
"""Planning, research, and report generation."""

__version__ = "0.0.7"

================
File: src/open_deep_research/configuration.py
================
import os
from enum import Enum
from dataclasses import dataclass, fields
from typing import Any, Optional, Dict 

from langchain_core.runnables import RunnableConfig
from dataclasses import dataclass

DEFAULT_REPORT_STRUCTURE = """Use this structure to create a report on the user-provided topic:

1. Introduction (no research needed)
   - Brief overview of the topic area

2. Main Body Sections:
   - Each section should focus on a sub-topic of the user-provided topic
   
3. Conclusion
   - Aim for 1 structural element (either a list of table) that distills the main body sections 
   - Provide a concise summary of the report"""

class SearchAPI(Enum):
    PERPLEXITY = "perplexity"
    TAVILY = "tavily"
    EXA = "exa"
    ARXIV = "arxiv"
    PUBMED = "pubmed"
    LINKUP = "linkup"

class PlannerProvider(Enum):
    ANTHROPIC = "anthropic"
    OPENAI = "openai"
    GROQ = "groq"

class WriterProvider(Enum):
    ANTHROPIC = "anthropic"
    OPENAI = "openai"
    GROQ = "groq"

@dataclass(kw_only=True)
class Configuration:
    """The configurable fields for the chatbot."""
    report_structure: str = DEFAULT_REPORT_STRUCTURE # Defaults to the default report structure
    number_of_queries: int = 2 # Number of search queries to generate per iteration
    max_search_depth: int = 2 # Maximum number of reflection + search iterations
    planner_provider: PlannerProvider = PlannerProvider.OPENAI  # Defaults to OpenAI as provider
    planner_model: str = "gpt-4o-mini" # Defaults to OpenAI o3-mini as planner model
    # planner
    # planner_model: str = "claude-3-7-sonnet-latest" # Defaults to claude-3-7-sonnet-latest
    writer_provider: WriterProvider = WriterProvider.OPENAI # Defaults to Anthropic as provider
    writer_model: str = "gpt-4o-mini" # Defaults to Anthropic as provider
    # writer_provider: WriterProvider = WriterProvider.ANTHROPIC # Defaults to Anthropic as provider
    # writer_model: str = "claude-3-5-sonnet-latest" # Defaults to claude-3-5-sonnet-latest

    search_api: SearchAPI = SearchAPI.TAVILY # Default to TAVILY
    search_api_config: Optional[Dict[str, Any]] = None 

    @classmethod
    def from_runnable_config(
        cls, config: Optional[RunnableConfig] = None
    ) -> "Configuration":
        """Create a Configuration instance from a RunnableConfig."""
        configurable = (
            config["configurable"] if config and "configurable" in config else {}
        )
        values: dict[str, Any] = {
            f.name: os.environ.get(f.name.upper(), configurable.get(f.name))
            for f in fields(cls)
            if f.init
        }
        return cls(**{k: v for k, v in values.items() if v})

================
File: src/open_deep_research/graph.ipynb
================
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install -U -q open-deep-research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.7\n"
     ]
    }
   ],
   "source": [
    "import open_deep_research   \n",
    "print(open_deep_research.__version__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.types import Command\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from open_deep_research.graph import builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "memory = MemorySaver()\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "# Set the API keys used for any model or search API selections below\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "_set_env(\"ANTHROPIC_API_KEY\")\n",
    "_set_env(\"TAVILY_API_KEY\")\n",
    "_set_env(\"GROQ_API_KEY\")\n",
    "_set_env(\"PERPLEXITY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Please provide feedback on the following report plan. \n",
       "                        \n",
       "\n",
       "Section: Introduction\n",
       "Description: Introduces the AI inference market and provides a brief overview of the focus on Fireworks, Together.ai, and Groq.\n",
       "Research needed: No\n",
       "\n",
       "\n",
       "Section: AI Inference Market Overview\n",
       "Description: Provides context on the dynamics, trends, and key drivers in the AI inference market, setting the stage for a deeper dive into specific providers.\n",
       "Research needed: No\n",
       "\n",
       "\n",
       "Section: Analysis of Fireworks and Together.ai\n",
       "Description: Examines the features, pricing, integrations, deployment strategies, and performance metrics of Fireworks and Together.ai, drawing on comparative insights from multiple sources.\n",
       "Research needed: No\n",
       "\n",
       "\n",
       "Section: Analysis of Groq\n",
       "Description: Reviews Groq's innovative inference solutions with a focus on performance benchmarks, latency, and throughput, highlighting its market position and technological strengths.\n",
       "Research needed: No\n",
       "\n",
       "\n",
       "Section: Comparative Analysis\n",
       "Description: Synthesizes the comparisons between the three providers, focusing on differences and similarities in features, pricing, performance, and overall market impact.\n",
       "Research needed: No\n",
       "\n",
       "\n",
       "Section: Conclusion and Summary\n",
       "Description: Provides a concise wrap-up of the report, distilling the main insights into a summary list or table and offering final thoughts on the AI inference market.\n",
       "Research needed: No\n",
       "\n",
       "\n",
       "                        \n",
       "Does the report plan meet your needs?\n",
       "Pass 'true' to approve the report plan.\n",
       "Or, provide feedback to regenerate the report plan:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import uuid \n",
    "from IPython.display import Markdown\n",
    "\n",
    "REPORT_STRUCTURE = \"\"\"Use this structure to create a report on the user-provided topic:\n",
    "\n",
    "1. Introduction (no research needed)\n",
    "   - Brief overview of the topic area\n",
    "\n",
    "2. Main Body Sections:\n",
    "   - Each section should focus on a sub-topic of the user-provided topic\n",
    "   \n",
    "3. Conclusion\n",
    "   - Aim for 1 structural element (either a list of table) that distills the main body sections \n",
    "   - Provide a concise summary of the report\"\"\"\n",
    "\n",
    "# Claude 3.7 Sonnet for planning with perplexity search\n",
    "thread = {\"configurable\": {\"thread_id\": str(uuid.uuid4()),\n",
    "                           \"search_api\": \"perplexity\",\n",
    "                           \"planner_provider\": \"anthropic\",\n",
    "                           \"planner_model\": \"claude-3-7-sonnet-latest\",\n",
    "                           \"writer_provider\": \"anthropic\",\n",
    "                           \"writer_model\": \"claude-3-5-sonnet-latest\",\n",
    "                           \"max_search_depth\": 2,\n",
    "                           \"report_structure\": REPORT_STRUCTURE,\n",
    "                           }}\n",
    "\n",
    "# DeepSeek-R1-Distill-Llama-70B for planning\n",
    "thread = {\"configurable\": {\"thread_id\": str(uuid.uuid4()),\n",
    "                           \"search_api\": \"tavily\",\n",
    "                           \"planner_provider\": \"groq\",\n",
    "                           \"planner_model\": \"deepseek-r1-distill-llama-70b\",\n",
    "                           \"writer_provider\": \"groq\",\n",
    "                           \"writer_model\": \"llama-3.3-70b-versatile\",\n",
    "                           \"report_structure\": REPORT_STRUCTURE,\n",
    "                           \"max_search_depth\": 1,}\n",
    "                           }\n",
    "\n",
    "# Fast config (less search depth) with o3-mini for planning and Claude 3.5 Sonnet for writing\n",
    "thread = {\"configurable\": {\"thread_id\": str(uuid.uuid4()),\n",
    "                           \"search_api\": \"tavily\",\n",
    "                           \"planner_provider\": \"openai\",\n",
    "                           \"planner_model\": \"o3-mini\",\n",
    "                           \"writer_provider\": \"anthropic\",\n",
    "                           \"writer_model\": \"claude-3-5-sonnet-latest\",\n",
    "                           \"max_search_depth\": 1,\n",
    "                           \"report_structure\": REPORT_STRUCTURE,\n",
    "                           }}\n",
    "\n",
    "# Create a topic\n",
    "topic = \"Overview of the AI inference market with focus on Fireworks, Together.ai, Groq\"\n",
    "\n",
    "# Run the graph until the interruption\n",
    "async for event in graph.astream({\"topic\":topic,}, thread, stream_mode=\"updates\"):\n",
    "    if '__interrupt__' in event:\n",
    "        interrupt_value = event['__interrupt__'][0].value\n",
    "        display(Markdown(interrupt_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Please provide feedback on the following report plan. \n",
       "                        \n",
       "\n",
       "Section: Introduction\n",
       "Description: Provides a brief overview of the AI inference market, its relevance, and introduces the three key players: Fireworks, Together.ai, and Groq.\n",
       "Research needed: No\n",
       "\n",
       "\n",
       "Section: Fireworks AI Overview\n",
       "Description: Covers Fireworks AIâ€™s offerings in the inference market, including key performance metrics, product features, model quality, speed, and latency. Emphasizes revenue estimates (ARR) as part of its market positioning.\n",
       "Research needed: Yes\n",
       "\n",
       "\n",
       "Section: Together.ai Overview\n",
       "Description: Explores Together.aiâ€™s role within the AI inference space. Discusses product features, integration details, user reviews, and performance metrics along with ARR revenue estimates.\n",
       "Research needed: Yes\n",
       "\n",
       "\n",
       "Section: Groq AI Overview\n",
       "Description: Examines Groqâ€™s AI inference solutions with a focus on benchmark performance, inference speed, and cost efficiency. Includes an analysis of ARR revenue and how its technical performance shapes its market position.\n",
       "Research needed: Yes\n",
       "\n",
       "\n",
       "Section: Market Comparison and Trends\n",
       "Description: Provides a comparative analysis highlighting the strengths, weaknesses, and differentiating factors of Fireworks, Together.ai, and Groq. Discusses trends like cost, performance metrics, and revenue (ARR) estimates.\n",
       "Research needed: Yes\n",
       "\n",
       "\n",
       "Section: Conclusion\n",
       "Description: Summarizes key findings from the individual sections and the comparative analysis. Offers a concise distillation of the market landscape using a summary table or list to highlight major points including ARR insights.\n",
       "Research needed: No\n",
       "\n",
       "\n",
       "                        \n",
       "Does the report plan meet your needs?\n",
       "Pass 'true' to approve the report plan.\n",
       "Or, provide feedback to regenerate the report plan:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pass feedback to update the report plan  \n",
    "async for event in graph.astream(Command(resume=\"Include individuals sections for Together.ai, Groq, and Fireworks with revenue estimates (ARR)\"), thread, stream_mode=\"updates\"):\n",
    "    if '__interrupt__' in event:\n",
    "        interrupt_value = event['__interrupt__'][0].value\n",
    "        display(Markdown(interrupt_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'human_feedback': None}\n",
      "\n",
      "\n",
      "{'build_section_with_web_research': {'completed_sections': [Section(name='Groq AI Overview', description='Examines Groqâ€™s AI inference solutions with a focus on benchmark performance, inference speed, and cost efficiency. Includes an analysis of ARR revenue and how its technical performance shapes its market position.', research=True, content=\"## Groq AI Overview\\n\\nGroq has emerged as a significant player in the AI inference market with its innovative Language Processing Unit (LPU) technology. Independent benchmarks from ArtificialAnalysis.ai demonstrate Groq's impressive performance, with their Llama 2 Chat (70B) API achieving 241 tokens per second - more than double the speed of competing providers [1]. Their total response time for 100 output tokens is just 0.8 seconds, positioning them as a leader in inference speed [2].\\n\\nThe company's core technology, the Tensor Streaming Processor (TSP), delivers 500-700 tokens per second on large language models, representing a 5-10x improvement over Nvidia's latest data center GPUs [3]. This performance advantage has positioned Groq as a compelling alternative in the inference market, particularly for startups seeking cost-effective solutions [4].\\n\\nWith approximately 300 employees, 60% of whom are software engineers, Groq has evolved beyond hardware to become a comprehensive AI solutions provider [5]. The company is strategically positioned to capture a share of the growing inference chip market, which is projected to reach $48 billion by 2027 [6].\\n\\n### Sources\\n[1] https://groq.com/artificialanalysis-ai-llm-benchmark-doubles-axis-to-fit-new-groq-lpu-inference-engine-performance-results/\\n[2] https://groq.com/inference/\\n[3] https://sacra.com/c/groq/\\n[4] https://venturebeat.com/ai/ai-chip-race-groq-ceo-takes-on-nvidia-claims-most-startups-will-use-speedy-lpus-by-end-of-2024/\\n[5] https://www.businessinsider.com/groq-nvidia-software-advantage-cuda-moat-challenge-inference-2024-12?op=1\\n[6] https://generativeaitech.substack.com/p/groq-and-its-impact-on-ai-inference\")]}}\n",
      "\n",
      "\n",
      "{'build_section_with_web_research': {'completed_sections': [Section(name='Market Comparison and Trends', description='Provides a comparative analysis highlighting the strengths, weaknesses, and differentiating factors of Fireworks, Together.ai, and Groq. Discusses trends like cost, performance metrics, and revenue (ARR) estimates.', research=True, content=\"## Market Comparison and Trends\\n\\nThe AI inference market shows distinct positioning among key players Fireworks, Together.ai, and Groq. Fireworks AI differentiates itself through superior speed, leveraging its proprietary FireAttention inference engine for text, image, and audio processing, while maintaining HIPAA and SOC2 compliance for data privacy [1]. Together.ai has demonstrated remarkable growth, reaching an estimated $130M in annualized recurring revenue (ARR) in 2024, representing a 400% year-over-year increase [2].\\n\\nBoth Fireworks and Together.ai focus on providing high-quality open-source models that can compete with proprietary alternatives [1]. Pricing structures vary across providers, with model costs ranging from $0.20 to $3.00 per million tokens for different model sizes and capabilities [3]. Together.ai's business model benefits from GPU price commoditization, allowing them to maintain competitive token pricing while focusing on developer experience and reliable inference across diverse open-source models [2].\\n\\nGroq distinguishes itself by offering quick access to various open-source AI models from major providers like Google, Meta, OpenAI, and Mistral through the OpenRouter API platform [4]. The market shows a trend toward comprehensive platform offerings, with providers competing on factors such as model variety, inference speed, and specialized features for different use cases.\\n\\n### Sources\\n[1] Top 10 AI Inference Platforms in 2025: Comparing LLM API Providers: https://www.helicone.ai/blog/llm-api-providers\\n[2] Together AI revenue, valuation & growth rate | Sacra: https://sacra.com/c/together-ai/\\n[3] Models Leaderboard : Comparison of AI Models & API Providers - Groq AI: https://groq-ai.com/models/\\n[4] Pricing: Compare Groq API Pricing With Other API Providers: https://groq-ai.com/pricing/\")]}}\n",
      "\n",
      "\n",
      "{'build_section_with_web_research': {'completed_sections': [Section(name='Together.ai Overview', description='Explores Together.aiâ€™s role within the AI inference space. Discusses product features, integration details, user reviews, and performance metrics along with ARR revenue estimates.', research=True, content=\"## Together.ai Overview\\n\\nTogether.ai is a comprehensive AI acceleration platform that has quickly emerged as a significant player in the AI inference space since its founding in 2022 [1]. The platform enables developers to access over 200 AI models, offering high-performance inference capabilities with optimized infrastructure [2].\\n\\nThe company's Inference Engine, built on NVIDIA Tensor Core GPUs, delivers impressive performance metrics, achieving 117 tokens per second on Llama-2-70B-Chat models [3]. Their model offerings include high-quality options like Llama 3.3 70B Turbo and Llama 3.1 405B Turbo, with some models achieving sub-100ms latency [4].\\n\\nTogether.ai has demonstrated remarkable growth, with estimates suggesting $130M in annualized recurring revenue (ARR) in 2024, representing a 400% year-over-year increase [5]. The platform has received positive user feedback, maintaining a 4.8/5.0 rating based on 162 user reviews [6].\\n\\nThe company differentiates itself through competitive pricing and technical innovations, incorporating advanced features like token caching, load balancing, and model quantization [2]. Users particularly praise the platform's straightforward API, reliable performance, and competitive pricing compared to alternatives [7].\\n\\n### Sources\\n[1] https://siliconvalleyjournals.com/company/together-ai/\\n[2] https://www.keywordsai.co/blog/top-10-llm-api-providers\\n[3] https://www.together.ai/blog/together-inference-engine-v1\\n[4] https://artificialanalysis.ai/providers/togetherai\\n[5] https://sacra.com/c/together-ai/\\n[6] https://www.featuredcustomers.com/vendor/together-ai\\n[7] https://www.trustpilot.com/review/together.ai\")]}}\n",
      "\n",
      "\n",
      "{'build_section_with_web_research': {'completed_sections': [Section(name='Fireworks AI Overview', description='Covers Fireworks AIâ€™s offerings in the inference market, including key performance metrics, product features, model quality, speed, and latency. Emphasizes revenue estimates (ARR) as part of its market positioning.', research=True, content='## Fireworks AI Overview\\n\\nFireworks AI has established itself as a significant player in the AI inference market, offering a comprehensive platform for deploying and managing AI models. The company provides access to various high-performance models, including Llama 3.1 405B and Qwen2.5 Coder 32B, which represent their highest quality offerings [1]. Their platform demonstrates impressive performance metrics, with some models achieving speeds up to 300 tokens per second for serverless deployments [2].\\n\\nThe company has gained substantial market traction, recently securing $52 million in Series B funding that values the company at $552 million [3]. With an annual revenue of $6 million and a team of 60 employees, Fireworks AI serves notable clients including DoorDash, Quora, and Upwork [4, 5].\\n\\nTheir platform differentiates itself through specialized features like FP8 quantization for large models and continuous batching capabilities [6]. Fireworks claims to offer approximately 3x faster speeds compared to competitors like Hugging Face TGI when using the same GPU configuration [2]. The company focuses on providing smaller, production-grade models that can be deployed privately and securely, rather than generic mega models [5].\\n\\n### Sources\\n[1] Fireworks: Models Intelligence, Performance & Price: https://artificialanalysis.ai/providers/fireworks\\n[2] Fireworks Platform Spring 2024 Updates: https://fireworks.ai/blog/spring-update-faster-models-dedicated-deployments-postpaid-pricing\\n[3] Fireworks AI Raises $52M in Series B Funding: https://siliconvalleyjournals.com/fireworks-ai-raises-52m-in-series-b-funding-to-expand-genai-inference-platform/\\n[4] Fireworks AI: Contact Details, Revenue, Funding: https://siliconvalleyjournals.com/company/fireworks-ai/\\n[5] Fireworks AI Valued at $552 Million After New Funding Round: https://www.pymnts.com/news/investment-tracker/2024/fireworks-ai-valued-552-million-dollars-after-new-funding-round/\\n[6] Inference performance - Fireworks AI Docs: https://docs.fireworks.ai/faq/models/inference/performance')]}}\n",
      "\n",
      "\n",
      "{'gather_completed_sections': {'report_sections_from_research': \"\\n============================================================\\nSection 1: Fireworks AI Overview\\n============================================================\\nDescription:\\nCovers Fireworks AIâ€™s offerings in the inference market, including key performance metrics, product features, model quality, speed, and latency. Emphasizes revenue estimates (ARR) as part of its market positioning.\\nRequires Research: \\nTrue\\n\\nContent:\\n## Fireworks AI Overview\\n\\nFireworks AI has established itself as a significant player in the AI inference market, offering a comprehensive platform for deploying and managing AI models. The company provides access to various high-performance models, including Llama 3.1 405B and Qwen2.5 Coder 32B, which represent their highest quality offerings [1]. Their platform demonstrates impressive performance metrics, with some models achieving speeds up to 300 tokens per second for serverless deployments [2].\\n\\nThe company has gained substantial market traction, recently securing $52 million in Series B funding that values the company at $552 million [3]. With an annual revenue of $6 million and a team of 60 employees, Fireworks AI serves notable clients including DoorDash, Quora, and Upwork [4, 5].\\n\\nTheir platform differentiates itself through specialized features like FP8 quantization for large models and continuous batching capabilities [6]. Fireworks claims to offer approximately 3x faster speeds compared to competitors like Hugging Face TGI when using the same GPU configuration [2]. The company focuses on providing smaller, production-grade models that can be deployed privately and securely, rather than generic mega models [5].\\n\\n### Sources\\n[1] Fireworks: Models Intelligence, Performance & Price: https://artificialanalysis.ai/providers/fireworks\\n[2] Fireworks Platform Spring 2024 Updates: https://fireworks.ai/blog/spring-update-faster-models-dedicated-deployments-postpaid-pricing\\n[3] Fireworks AI Raises $52M in Series B Funding: https://siliconvalleyjournals.com/fireworks-ai-raises-52m-in-series-b-funding-to-expand-genai-inference-platform/\\n[4] Fireworks AI: Contact Details, Revenue, Funding: https://siliconvalleyjournals.com/company/fireworks-ai/\\n[5] Fireworks AI Valued at $552 Million After New Funding Round: https://www.pymnts.com/news/investment-tracker/2024/fireworks-ai-valued-552-million-dollars-after-new-funding-round/\\n[6] Inference performance - Fireworks AI Docs: https://docs.fireworks.ai/faq/models/inference/performance\\n\\n\\n============================================================\\nSection 2: Together.ai Overview\\n============================================================\\nDescription:\\nExplores Together.aiâ€™s role within the AI inference space. Discusses product features, integration details, user reviews, and performance metrics along with ARR revenue estimates.\\nRequires Research: \\nTrue\\n\\nContent:\\n## Together.ai Overview\\n\\nTogether.ai is a comprehensive AI acceleration platform that has quickly emerged as a significant player in the AI inference space since its founding in 2022 [1]. The platform enables developers to access over 200 AI models, offering high-performance inference capabilities with optimized infrastructure [2].\\n\\nThe company's Inference Engine, built on NVIDIA Tensor Core GPUs, delivers impressive performance metrics, achieving 117 tokens per second on Llama-2-70B-Chat models [3]. Their model offerings include high-quality options like Llama 3.3 70B Turbo and Llama 3.1 405B Turbo, with some models achieving sub-100ms latency [4].\\n\\nTogether.ai has demonstrated remarkable growth, with estimates suggesting $130M in annualized recurring revenue (ARR) in 2024, representing a 400% year-over-year increase [5]. The platform has received positive user feedback, maintaining a 4.8/5.0 rating based on 162 user reviews [6].\\n\\nThe company differentiates itself through competitive pricing and technical innovations, incorporating advanced features like token caching, load balancing, and model quantization [2]. Users particularly praise the platform's straightforward API, reliable performance, and competitive pricing compared to alternatives [7].\\n\\n### Sources\\n[1] https://siliconvalleyjournals.com/company/together-ai/\\n[2] https://www.keywordsai.co/blog/top-10-llm-api-providers\\n[3] https://www.together.ai/blog/together-inference-engine-v1\\n[4] https://artificialanalysis.ai/providers/togetherai\\n[5] https://sacra.com/c/together-ai/\\n[6] https://www.featuredcustomers.com/vendor/together-ai\\n[7] https://www.trustpilot.com/review/together.ai\\n\\n\\n============================================================\\nSection 3: Groq AI Overview\\n============================================================\\nDescription:\\nExamines Groqâ€™s AI inference solutions with a focus on benchmark performance, inference speed, and cost efficiency. Includes an analysis of ARR revenue and how its technical performance shapes its market position.\\nRequires Research: \\nTrue\\n\\nContent:\\n## Groq AI Overview\\n\\nGroq has emerged as a significant player in the AI inference market with its innovative Language Processing Unit (LPU) technology. Independent benchmarks from ArtificialAnalysis.ai demonstrate Groq's impressive performance, with their Llama 2 Chat (70B) API achieving 241 tokens per second - more than double the speed of competing providers [1]. Their total response time for 100 output tokens is just 0.8 seconds, positioning them as a leader in inference speed [2].\\n\\nThe company's core technology, the Tensor Streaming Processor (TSP), delivers 500-700 tokens per second on large language models, representing a 5-10x improvement over Nvidia's latest data center GPUs [3]. This performance advantage has positioned Groq as a compelling alternative in the inference market, particularly for startups seeking cost-effective solutions [4].\\n\\nWith approximately 300 employees, 60% of whom are software engineers, Groq has evolved beyond hardware to become a comprehensive AI solutions provider [5]. The company is strategically positioned to capture a share of the growing inference chip market, which is projected to reach $48 billion by 2027 [6].\\n\\n### Sources\\n[1] https://groq.com/artificialanalysis-ai-llm-benchmark-doubles-axis-to-fit-new-groq-lpu-inference-engine-performance-results/\\n[2] https://groq.com/inference/\\n[3] https://sacra.com/c/groq/\\n[4] https://venturebeat.com/ai/ai-chip-race-groq-ceo-takes-on-nvidia-claims-most-startups-will-use-speedy-lpus-by-end-of-2024/\\n[5] https://www.businessinsider.com/groq-nvidia-software-advantage-cuda-moat-challenge-inference-2024-12?op=1\\n[6] https://generativeaitech.substack.com/p/groq-and-its-impact-on-ai-inference\\n\\n\\n============================================================\\nSection 4: Market Comparison and Trends\\n============================================================\\nDescription:\\nProvides a comparative analysis highlighting the strengths, weaknesses, and differentiating factors of Fireworks, Together.ai, and Groq. Discusses trends like cost, performance metrics, and revenue (ARR) estimates.\\nRequires Research: \\nTrue\\n\\nContent:\\n## Market Comparison and Trends\\n\\nThe AI inference market shows distinct positioning among key players Fireworks, Together.ai, and Groq. Fireworks AI differentiates itself through superior speed, leveraging its proprietary FireAttention inference engine for text, image, and audio processing, while maintaining HIPAA and SOC2 compliance for data privacy [1]. Together.ai has demonstrated remarkable growth, reaching an estimated $130M in annualized recurring revenue (ARR) in 2024, representing a 400% year-over-year increase [2].\\n\\nBoth Fireworks and Together.ai focus on providing high-quality open-source models that can compete with proprietary alternatives [1]. Pricing structures vary across providers, with model costs ranging from $0.20 to $3.00 per million tokens for different model sizes and capabilities [3]. Together.ai's business model benefits from GPU price commoditization, allowing them to maintain competitive token pricing while focusing on developer experience and reliable inference across diverse open-source models [2].\\n\\nGroq distinguishes itself by offering quick access to various open-source AI models from major providers like Google, Meta, OpenAI, and Mistral through the OpenRouter API platform [4]. The market shows a trend toward comprehensive platform offerings, with providers competing on factors such as model variety, inference speed, and specialized features for different use cases.\\n\\n### Sources\\n[1] Top 10 AI Inference Platforms in 2025: Comparing LLM API Providers: https://www.helicone.ai/blog/llm-api-providers\\n[2] Together AI revenue, valuation & growth rate | Sacra: https://sacra.com/c/together-ai/\\n[3] Models Leaderboard : Comparison of AI Models & API Providers - Groq AI: https://groq-ai.com/models/\\n[4] Pricing: Compare Groq API Pricing With Other API Providers: https://groq-ai.com/pricing/\\n\\n\"}}\n",
      "\n",
      "\n",
      "{'write_final_sections': {'completed_sections': [Section(name='Introduction', description='Provides a brief overview of the AI inference market, its relevance, and introduces the three key players: Fireworks, Together.ai, and Groq.', research=False, content=\"# AI Inference Market: Analysis of Fireworks, Together.ai, and Groq\\n\\nThe AI inference market is experiencing rapid evolution as companies compete to provide faster, more efficient solutions for deploying and managing AI models. This analysis examines three key players reshaping the landscape: Fireworks, Together.ai, and Groq. Each brings distinct advantages - Fireworks with its specialized features and security focus, Together.ai with its comprehensive platform and impressive growth trajectory, and Groq with its groundbreaking Language Processing Unit technology. As organizations increasingly rely on AI inference capabilities, understanding these providers' strengths and market positions becomes crucial for making informed deployment decisions.\")]}}\n",
      "\n",
      "\n",
      "{'write_final_sections': {'completed_sections': [Section(name='Conclusion', description='Summarizes key findings from the individual sections and the comparative analysis. Offers a concise distillation of the market landscape using a summary table or list to highlight major points including ARR insights.', research=False, content='## Conclusion\\n\\nThe AI inference market shows clear differentiation among key players, with each provider carving out unique value propositions. Together.ai leads in revenue growth with $130M ARR, while Fireworks AI demonstrates strong potential with its recent $552M valuation. Groq distinguishes itself through superior inference speeds, achieving up to 700 tokens per second with its LPU technology.\\n\\n| Metric | Fireworks | Together.ai | Groq |\\n|--------|-----------|-------------|------|\\n| ARR | $6M | $130M | Not disclosed |\\n| Speed (tokens/sec) | Up to 300 | Up to 117 | 500-700 |\\n| Key Differentiator | FP8 quantization | 200+ model access | LPU technology |\\n| Notable Feature | 3x faster than competitors | Token caching | Sub-second response |\\n| Target Market | Enterprise security | Developer platforms | Startup solutions |\\n\\nThe market trends indicate a shift toward comprehensive platform offerings that balance speed, cost-efficiency, and model variety. As the inference chip market approaches $48B by 2027, providers focusing on specialized hardware solutions and optimized infrastructure will likely gain competitive advantages. Success will depend on maintaining the delicate balance between performance, pricing, and platform features while addressing growing enterprise demands for security and reliability.')]}}\n",
      "\n",
      "\n",
      "{'compile_final_report': {'final_report': \"# AI Inference Market: Analysis of Fireworks, Together.ai, and Groq\\n\\nThe AI inference market is experiencing rapid evolution as companies compete to provide faster, more efficient solutions for deploying and managing AI models. This analysis examines three key players reshaping the landscape: Fireworks, Together.ai, and Groq. Each brings distinct advantages - Fireworks with its specialized features and security focus, Together.ai with its comprehensive platform and impressive growth trajectory, and Groq with its groundbreaking Language Processing Unit technology. As organizations increasingly rely on AI inference capabilities, understanding these providers' strengths and market positions becomes crucial for making informed deployment decisions.\\n\\n## Fireworks AI Overview\\n\\nFireworks AI has established itself as a significant player in the AI inference market, offering a comprehensive platform for deploying and managing AI models. The company provides access to various high-performance models, including Llama 3.1 405B and Qwen2.5 Coder 32B, which represent their highest quality offerings [1]. Their platform demonstrates impressive performance metrics, with some models achieving speeds up to 300 tokens per second for serverless deployments [2].\\n\\nThe company has gained substantial market traction, recently securing $52 million in Series B funding that values the company at $552 million [3]. With an annual revenue of $6 million and a team of 60 employees, Fireworks AI serves notable clients including DoorDash, Quora, and Upwork [4, 5].\\n\\nTheir platform differentiates itself through specialized features like FP8 quantization for large models and continuous batching capabilities [6]. Fireworks claims to offer approximately 3x faster speeds compared to competitors like Hugging Face TGI when using the same GPU configuration [2]. The company focuses on providing smaller, production-grade models that can be deployed privately and securely, rather than generic mega models [5].\\n\\n### Sources\\n[1] Fireworks: Models Intelligence, Performance & Price: https://artificialanalysis.ai/providers/fireworks\\n[2] Fireworks Platform Spring 2024 Updates: https://fireworks.ai/blog/spring-update-faster-models-dedicated-deployments-postpaid-pricing\\n[3] Fireworks AI Raises $52M in Series B Funding: https://siliconvalleyjournals.com/fireworks-ai-raises-52m-in-series-b-funding-to-expand-genai-inference-platform/\\n[4] Fireworks AI: Contact Details, Revenue, Funding: https://siliconvalleyjournals.com/company/fireworks-ai/\\n[5] Fireworks AI Valued at $552 Million After New Funding Round: https://www.pymnts.com/news/investment-tracker/2024/fireworks-ai-valued-552-million-dollars-after-new-funding-round/\\n[6] Inference performance - Fireworks AI Docs: https://docs.fireworks.ai/faq/models/inference/performance\\n\\n## Together.ai Overview\\n\\nTogether.ai is a comprehensive AI acceleration platform that has quickly emerged as a significant player in the AI inference space since its founding in 2022 [1]. The platform enables developers to access over 200 AI models, offering high-performance inference capabilities with optimized infrastructure [2].\\n\\nThe company's Inference Engine, built on NVIDIA Tensor Core GPUs, delivers impressive performance metrics, achieving 117 tokens per second on Llama-2-70B-Chat models [3]. Their model offerings include high-quality options like Llama 3.3 70B Turbo and Llama 3.1 405B Turbo, with some models achieving sub-100ms latency [4].\\n\\nTogether.ai has demonstrated remarkable growth, with estimates suggesting $130M in annualized recurring revenue (ARR) in 2024, representing a 400% year-over-year increase [5]. The platform has received positive user feedback, maintaining a 4.8/5.0 rating based on 162 user reviews [6].\\n\\nThe company differentiates itself through competitive pricing and technical innovations, incorporating advanced features like token caching, load balancing, and model quantization [2]. Users particularly praise the platform's straightforward API, reliable performance, and competitive pricing compared to alternatives [7].\\n\\n### Sources\\n[1] https://siliconvalleyjournals.com/company/together-ai/\\n[2] https://www.keywordsai.co/blog/top-10-llm-api-providers\\n[3] https://www.together.ai/blog/together-inference-engine-v1\\n[4] https://artificialanalysis.ai/providers/togetherai\\n[5] https://sacra.com/c/together-ai/\\n[6] https://www.featuredcustomers.com/vendor/together-ai\\n[7] https://www.trustpilot.com/review/together.ai\\n\\n## Groq AI Overview\\n\\nGroq has emerged as a significant player in the AI inference market with its innovative Language Processing Unit (LPU) technology. Independent benchmarks from ArtificialAnalysis.ai demonstrate Groq's impressive performance, with their Llama 2 Chat (70B) API achieving 241 tokens per second - more than double the speed of competing providers [1]. Their total response time for 100 output tokens is just 0.8 seconds, positioning them as a leader in inference speed [2].\\n\\nThe company's core technology, the Tensor Streaming Processor (TSP), delivers 500-700 tokens per second on large language models, representing a 5-10x improvement over Nvidia's latest data center GPUs [3]. This performance advantage has positioned Groq as a compelling alternative in the inference market, particularly for startups seeking cost-effective solutions [4].\\n\\nWith approximately 300 employees, 60% of whom are software engineers, Groq has evolved beyond hardware to become a comprehensive AI solutions provider [5]. The company is strategically positioned to capture a share of the growing inference chip market, which is projected to reach $48 billion by 2027 [6].\\n\\n### Sources\\n[1] https://groq.com/artificialanalysis-ai-llm-benchmark-doubles-axis-to-fit-new-groq-lpu-inference-engine-performance-results/\\n[2] https://groq.com/inference/\\n[3] https://sacra.com/c/groq/\\n[4] https://venturebeat.com/ai/ai-chip-race-groq-ceo-takes-on-nvidia-claims-most-startups-will-use-speedy-lpus-by-end-of-2024/\\n[5] https://www.businessinsider.com/groq-nvidia-software-advantage-cuda-moat-challenge-inference-2024-12?op=1\\n[6] https://generativeaitech.substack.com/p/groq-and-its-impact-on-ai-inference\\n\\n## Market Comparison and Trends\\n\\nThe AI inference market shows distinct positioning among key players Fireworks, Together.ai, and Groq. Fireworks AI differentiates itself through superior speed, leveraging its proprietary FireAttention inference engine for text, image, and audio processing, while maintaining HIPAA and SOC2 compliance for data privacy [1]. Together.ai has demonstrated remarkable growth, reaching an estimated $130M in annualized recurring revenue (ARR) in 2024, representing a 400% year-over-year increase [2].\\n\\nBoth Fireworks and Together.ai focus on providing high-quality open-source models that can compete with proprietary alternatives [1]. Pricing structures vary across providers, with model costs ranging from $0.20 to $3.00 per million tokens for different model sizes and capabilities [3]. Together.ai's business model benefits from GPU price commoditization, allowing them to maintain competitive token pricing while focusing on developer experience and reliable inference across diverse open-source models [2].\\n\\nGroq distinguishes itself by offering quick access to various open-source AI models from major providers like Google, Meta, OpenAI, and Mistral through the OpenRouter API platform [4]. The market shows a trend toward comprehensive platform offerings, with providers competing on factors such as model variety, inference speed, and specialized features for different use cases.\\n\\n### Sources\\n[1] Top 10 AI Inference Platforms in 2025: Comparing LLM API Providers: https://www.helicone.ai/blog/llm-api-providers\\n[2] Together AI revenue, valuation & growth rate | Sacra: https://sacra.com/c/together-ai/\\n[3] Models Leaderboard : Comparison of AI Models & API Providers - Groq AI: https://groq-ai.com/models/\\n[4] Pricing: Compare Groq API Pricing With Other API Providers: https://groq-ai.com/pricing/\\n\\n## Conclusion\\n\\nThe AI inference market shows clear differentiation among key players, with each provider carving out unique value propositions. Together.ai leads in revenue growth with $130M ARR, while Fireworks AI demonstrates strong potential with its recent $552M valuation. Groq distinguishes itself through superior inference speeds, achieving up to 700 tokens per second with its LPU technology.\\n\\n| Metric | Fireworks | Together.ai | Groq |\\n|--------|-----------|-------------|------|\\n| ARR | $6M | $130M | Not disclosed |\\n| Speed (tokens/sec) | Up to 300 | Up to 117 | 500-700 |\\n| Key Differentiator | FP8 quantization | 200+ model access | LPU technology |\\n| Notable Feature | 3x faster than competitors | Token caching | Sub-second response |\\n| Target Market | Enterprise security | Developer platforms | Startup solutions |\\n\\nThe market trends indicate a shift toward comprehensive platform offerings that balance speed, cost-efficiency, and model variety. As the inference chip market approaches $48B by 2027, providers focusing on specialized hardware solutions and optimized infrastructure will likely gain competitive advantages. Success will depend on maintaining the delicate balance between performance, pricing, and platform features while addressing growing enterprise demands for security and reliability.\"}}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pass True to approve the report plan \n",
    "async for event in graph.astream(Command(resume=True), thread, stream_mode=\"updates\"):\n",
    "    print(event)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# AI Inference Market: Analysis of Fireworks, Together.ai, and Groq\n",
       "\n",
       "The AI inference market is experiencing rapid evolution as companies compete to provide faster, more efficient solutions for deploying and managing AI models. This analysis examines three key players reshaping the landscape: Fireworks, Together.ai, and Groq. Each brings distinct advantages - Fireworks with its specialized features and security focus, Together.ai with its comprehensive platform and impressive growth trajectory, and Groq with its groundbreaking Language Processing Unit technology. As organizations increasingly rely on AI inference capabilities, understanding these providers' strengths and market positions becomes crucial for making informed deployment decisions.\n",
       "\n",
       "## Fireworks AI Overview\n",
       "\n",
       "Fireworks AI has established itself as a significant player in the AI inference market, offering a comprehensive platform for deploying and managing AI models. The company provides access to various high-performance models, including Llama 3.1 405B and Qwen2.5 Coder 32B, which represent their highest quality offerings [1]. Their platform demonstrates impressive performance metrics, with some models achieving speeds up to 300 tokens per second for serverless deployments [2].\n",
       "\n",
       "The company has gained substantial market traction, recently securing $52 million in Series B funding that values the company at $552 million [3]. With an annual revenue of $6 million and a team of 60 employees, Fireworks AI serves notable clients including DoorDash, Quora, and Upwork [4, 5].\n",
       "\n",
       "Their platform differentiates itself through specialized features like FP8 quantization for large models and continuous batching capabilities [6]. Fireworks claims to offer approximately 3x faster speeds compared to competitors like Hugging Face TGI when using the same GPU configuration [2]. The company focuses on providing smaller, production-grade models that can be deployed privately and securely, rather than generic mega models [5].\n",
       "\n",
       "### Sources\n",
       "[1] Fireworks: Models Intelligence, Performance & Price: https://artificialanalysis.ai/providers/fireworks\n",
       "[2] Fireworks Platform Spring 2024 Updates: https://fireworks.ai/blog/spring-update-faster-models-dedicated-deployments-postpaid-pricing\n",
       "[3] Fireworks AI Raises $52M in Series B Funding: https://siliconvalleyjournals.com/fireworks-ai-raises-52m-in-series-b-funding-to-expand-genai-inference-platform/\n",
       "[4] Fireworks AI: Contact Details, Revenue, Funding: https://siliconvalleyjournals.com/company/fireworks-ai/\n",
       "[5] Fireworks AI Valued at $552 Million After New Funding Round: https://www.pymnts.com/news/investment-tracker/2024/fireworks-ai-valued-552-million-dollars-after-new-funding-round/\n",
       "[6] Inference performance - Fireworks AI Docs: https://docs.fireworks.ai/faq/models/inference/performance\n",
       "\n",
       "## Together.ai Overview\n",
       "\n",
       "Together.ai is a comprehensive AI acceleration platform that has quickly emerged as a significant player in the AI inference space since its founding in 2022 [1]. The platform enables developers to access over 200 AI models, offering high-performance inference capabilities with optimized infrastructure [2].\n",
       "\n",
       "The company's Inference Engine, built on NVIDIA Tensor Core GPUs, delivers impressive performance metrics, achieving 117 tokens per second on Llama-2-70B-Chat models [3]. Their model offerings include high-quality options like Llama 3.3 70B Turbo and Llama 3.1 405B Turbo, with some models achieving sub-100ms latency [4].\n",
       "\n",
       "Together.ai has demonstrated remarkable growth, with estimates suggesting $130M in annualized recurring revenue (ARR) in 2024, representing a 400% year-over-year increase [5]. The platform has received positive user feedback, maintaining a 4.8/5.0 rating based on 162 user reviews [6].\n",
       "\n",
       "The company differentiates itself through competitive pricing and technical innovations, incorporating advanced features like token caching, load balancing, and model quantization [2]. Users particularly praise the platform's straightforward API, reliable performance, and competitive pricing compared to alternatives [7].\n",
       "\n",
       "### Sources\n",
       "[1] https://siliconvalleyjournals.com/company/together-ai/\n",
       "[2] https://www.keywordsai.co/blog/top-10-llm-api-providers\n",
       "[3] https://www.together.ai/blog/together-inference-engine-v1\n",
       "[4] https://artificialanalysis.ai/providers/togetherai\n",
       "[5] https://sacra.com/c/together-ai/\n",
       "[6] https://www.featuredcustomers.com/vendor/together-ai\n",
       "[7] https://www.trustpilot.com/review/together.ai\n",
       "\n",
       "## Groq AI Overview\n",
       "\n",
       "Groq has emerged as a significant player in the AI inference market with its innovative Language Processing Unit (LPU) technology. Independent benchmarks from ArtificialAnalysis.ai demonstrate Groq's impressive performance, with their Llama 2 Chat (70B) API achieving 241 tokens per second - more than double the speed of competing providers [1]. Their total response time for 100 output tokens is just 0.8 seconds, positioning them as a leader in inference speed [2].\n",
       "\n",
       "The company's core technology, the Tensor Streaming Processor (TSP), delivers 500-700 tokens per second on large language models, representing a 5-10x improvement over Nvidia's latest data center GPUs [3]. This performance advantage has positioned Groq as a compelling alternative in the inference market, particularly for startups seeking cost-effective solutions [4].\n",
       "\n",
       "With approximately 300 employees, 60% of whom are software engineers, Groq has evolved beyond hardware to become a comprehensive AI solutions provider [5]. The company is strategically positioned to capture a share of the growing inference chip market, which is projected to reach $48 billion by 2027 [6].\n",
       "\n",
       "### Sources\n",
       "[1] https://groq.com/artificialanalysis-ai-llm-benchmark-doubles-axis-to-fit-new-groq-lpu-inference-engine-performance-results/\n",
       "[2] https://groq.com/inference/\n",
       "[3] https://sacra.com/c/groq/\n",
       "[4] https://venturebeat.com/ai/ai-chip-race-groq-ceo-takes-on-nvidia-claims-most-startups-will-use-speedy-lpus-by-end-of-2024/\n",
       "[5] https://www.businessinsider.com/groq-nvidia-software-advantage-cuda-moat-challenge-inference-2024-12?op=1\n",
       "[6] https://generativeaitech.substack.com/p/groq-and-its-impact-on-ai-inference\n",
       "\n",
       "## Market Comparison and Trends\n",
       "\n",
       "The AI inference market shows distinct positioning among key players Fireworks, Together.ai, and Groq. Fireworks AI differentiates itself through superior speed, leveraging its proprietary FireAttention inference engine for text, image, and audio processing, while maintaining HIPAA and SOC2 compliance for data privacy [1]. Together.ai has demonstrated remarkable growth, reaching an estimated $130M in annualized recurring revenue (ARR) in 2024, representing a 400% year-over-year increase [2].\n",
       "\n",
       "Both Fireworks and Together.ai focus on providing high-quality open-source models that can compete with proprietary alternatives [1]. Pricing structures vary across providers, with model costs ranging from $0.20 to $3.00 per million tokens for different model sizes and capabilities [3]. Together.ai's business model benefits from GPU price commoditization, allowing them to maintain competitive token pricing while focusing on developer experience and reliable inference across diverse open-source models [2].\n",
       "\n",
       "Groq distinguishes itself by offering quick access to various open-source AI models from major providers like Google, Meta, OpenAI, and Mistral through the OpenRouter API platform [4]. The market shows a trend toward comprehensive platform offerings, with providers competing on factors such as model variety, inference speed, and specialized features for different use cases.\n",
       "\n",
       "### Sources\n",
       "[1] Top 10 AI Inference Platforms in 2025: Comparing LLM API Providers: https://www.helicone.ai/blog/llm-api-providers\n",
       "[2] Together AI revenue, valuation & growth rate | Sacra: https://sacra.com/c/together-ai/\n",
       "[3] Models Leaderboard : Comparison of AI Models & API Providers - Groq AI: https://groq-ai.com/models/\n",
       "[4] Pricing: Compare Groq API Pricing With Other API Providers: https://groq-ai.com/pricing/\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "The AI inference market shows clear differentiation among key players, with each provider carving out unique value propositions. Together.ai leads in revenue growth with $130M ARR, while Fireworks AI demonstrates strong potential with its recent $552M valuation. Groq distinguishes itself through superior inference speeds, achieving up to 700 tokens per second with its LPU technology.\n",
       "\n",
       "| Metric | Fireworks | Together.ai | Groq |\n",
       "|--------|-----------|-------------|------|\n",
       "| ARR | $6M | $130M | Not disclosed |\n",
       "| Speed (tokens/sec) | Up to 300 | Up to 117 | 500-700 |\n",
       "| Key Differentiator | FP8 quantization | 200+ model access | LPU technology |\n",
       "| Notable Feature | 3x faster than competitors | Token caching | Sub-second response |\n",
       "| Target Market | Enterprise security | Developer platforms | Startup solutions |\n",
       "\n",
       "The market trends indicate a shift toward comprehensive platform offerings that balance speed, cost-efficiency, and model variety. As the inference chip market approaches $48B by 2027, providers focusing on specialized hardware solutions and optimized infrastructure will likely gain competitive advantages. Success will depend on maintaining the delicate balance between performance, pricing, and platform features while addressing growing enterprise demands for security and reliability."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_state = graph.get_state(thread)\n",
    "report = final_state.values.get('final_report')\n",
    "Markdown(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open-deep-research-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

================
File: src/open_deep_research/graph.py
================
from typing import Literal

from langchain.chat_models import init_chat_model
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_core.runnables import RunnableConfig

from langgraph.constants import Send
from langgraph.graph import START, END, StateGraph
from langgraph.types import interrupt, Command

from open_deep_research.state import (
    ReportStateInput,
    ReportStateOutput,
    Sections,
    ReportState,
    SectionState,
    SectionOutputState,
    Queries,
    Feedback
)

from open_deep_research.prompts import (
    report_planner_query_writer_instructions,
    report_planner_instructions,
    query_writer_instructions, 
    section_writer_instructions,
    final_section_writer_instructions,
    section_grader_instructions,
    section_writer_inputs
)

from open_deep_research.configuration import Configuration
from open_deep_research.utils import (
    format_sections, 
    get_config_value, 
    get_search_params, 
    select_and_execute_search
)

## Nodes -- 

async def generate_report_plan(state: ReportState, config: RunnableConfig):
    """Generate the initial report plan with sections.
    
    This node:
    1. Gets configuration for the report structure and search parameters
    2. Generates search queries to gather context for planning
    3. Performs web searches using those queries
    4. Uses an LLM to generate a structured plan with sections
    
    Args:
        state: Current graph state containing the report topic
        config: Configuration for models, search APIs, etc.
        
    Returns:
        Dict containing the generated sections
    """

    # Inputs
    topic = state["topic"]
    feedback = state.get("feedback_on_report_plan", None)

    # Get configuration
    configurable = Configuration.from_runnable_config(config)
    report_structure = configurable.report_structure
    number_of_queries = configurable.number_of_queries
    search_api = get_config_value(configurable.search_api)
    search_api_config = configurable.search_api_config or {}  # Get the config dict, default to empty
    params_to_pass = get_search_params(search_api, search_api_config)  # Filter parameters

    # Convert JSON object to string if necessary
    if isinstance(report_structure, dict):
        report_structure = str(report_structure)

    # Set writer model (model used for query writing)
    writer_provider = get_config_value(configurable.writer_provider)
    writer_model_name = get_config_value(configurable.writer_model)
    writer_model = init_chat_model(model=writer_model_name, model_provider=writer_provider, temperature=0) 
    structured_llm = writer_model.with_structured_output(Queries)

    # Format system instructions
    system_instructions_query = report_planner_query_writer_instructions.format(topic=topic, report_organization=report_structure, number_of_queries=number_of_queries)

    # Generate queries  
    results = structured_llm.invoke([SystemMessage(content=system_instructions_query),
                                     HumanMessage(content="Generate search queries that will help with planning the sections of the report.")])

    # Web search
    query_list = [query.search_query for query in results.queries]

    # Search the web with parameters
    source_str = await select_and_execute_search(search_api, query_list, params_to_pass)

    # Format system instructions
    system_instructions_sections = report_planner_instructions.format(topic=topic, report_organization=report_structure, context=source_str, feedback=feedback)

    # Set the planner
    planner_provider = get_config_value(configurable.planner_provider)
    planner_model = get_config_value(configurable.planner_model)

    # Report planner instructions
    planner_message = """Generate the sections of the report. Your response must include a 'sections' field containing a list of sections. 
                        Each section must have: name, description, plan, research, and content fields."""

    # Run the planner
    if planner_model == "claude-3-7-sonnet-latest":

        # Allocate a thinking budget for claude-3-7-sonnet-latest as the planner model
        planner_llm = init_chat_model(model=planner_model, 
                                      model_provider=planner_provider, 
                                      max_tokens=20_000, 
                                      thinking={"type": "enabled", "budget_tokens": 16_000})

    else:

        # With other models, we can use with_structured_output
        planner_llm = init_chat_model(model=planner_model, model_provider=planner_provider)
    
    # Generate the report sections
    structured_llm = planner_llm.with_structured_output(Sections)
    report_sections = structured_llm.invoke([SystemMessage(content=system_instructions_sections),
                                             HumanMessage(content=planner_message)])

    # Get sections
    sections = report_sections.sections

    return {"sections": sections}

def human_feedback(state: ReportState, config: RunnableConfig) -> Command[Literal["generate_report_plan","build_section_with_web_research"]]:
    """Get human feedback on the report plan and route to next steps.
    
    This node:
    1. Formats the current report plan for human review
    2. Gets feedback via an interrupt
    3. Routes to either:
       - Section writing if plan is approved
       - Plan regeneration if feedback is provided
    
    Args:
        state: Current graph state with sections to review
        config: Configuration for the workflow
        
    Returns:
        Command to either regenerate plan or start section writing
    """

    # Get sections
    topic = state["topic"]
    sections = state['sections']
    sections_str = "\n\n".join(
        f"Section: {section.name}\n"
        f"Description: {section.description}\n"
        f"Research needed: {'Yes' if section.research else 'No'}\n"
        for section in sections
    )

    # Get feedback on the report plan from interrupt
    interrupt_message = f"""Please provide feedback on the following report plan. 
                        \n\n{sections_str}\n
                        \nDoes the report plan meet your needs?\nPass 'true' to approve the report plan.\nOr, provide feedback to regenerate the report plan:"""
    
    feedback = interrupt(interrupt_message)

    # If the user approves the report plan, kick off section writing
    if isinstance(feedback, bool) and feedback is True:
        # Treat this as approve and kick off section writing
        return Command(goto=[
            Send("build_section_with_web_research", {"topic": topic, "section": s, "search_iterations": 0}) 
            for s in sections 
            if s.research
        ])
    
    # If the user provides feedback, regenerate the report plan 
    elif isinstance(feedback, str):
        # Treat this as feedback
        return Command(goto="generate_report_plan", 
                       update={"feedback_on_report_plan": feedback})
    else:
        raise TypeError(f"Interrupt value of type {type(feedback)} is not supported.")
    
def generate_queries(state: SectionState, config: RunnableConfig):
    """Generate search queries for researching a specific section.
    
    This node uses an LLM to generate targeted search queries based on the 
    section topic and description.
    
    Args:
        state: Current state containing section details
        config: Configuration including number of queries to generate
        
    Returns:
        Dict containing the generated search queries
    """

    # Get state 
    topic = state["topic"]
    section = state["section"]

    # Get configuration
    configurable = Configuration.from_runnable_config(config)
    number_of_queries = configurable.number_of_queries

    # Generate queries 
    writer_provider = get_config_value(configurable.writer_provider)
    writer_model_name = get_config_value(configurable.writer_model)
    writer_model = init_chat_model(model=writer_model_name, model_provider=writer_provider, temperature=0) 
    structured_llm = writer_model.with_structured_output(Queries)

    # Format system instructions
    system_instructions = query_writer_instructions.format(topic=topic, 
                                                           section_topic=section.description, 
                                                           number_of_queries=number_of_queries)

    # Generate queries  
    queries = structured_llm.invoke([SystemMessage(content=system_instructions),
                                     HumanMessage(content="Generate search queries on the provided topic.")])

    return {"search_queries": queries.queries}

async def search_web(state: SectionState, config: RunnableConfig):
    """Execute web searches for the section queries.
    
    This node:
    1. Takes the generated queries
    2. Executes searches using configured search API
    3. Formats results into usable context
    
    Args:
        state: Current state with search queries
        config: Search API configuration
        
    Returns:
        Dict with search results and updated iteration count
    """

    # Get state
    search_queries = state["search_queries"]

    # Get configuration
    configurable = Configuration.from_runnable_config(config)
    search_api = get_config_value(configurable.search_api)
    search_api_config = configurable.search_api_config or {}  # Get the config dict, default to empty
    params_to_pass = get_search_params(search_api, search_api_config)  # Filter parameters

    # Web search
    query_list = [query.search_query for query in search_queries]

    # Search the web with parameters
    source_str = await select_and_execute_search(search_api, query_list, params_to_pass)

    return {"source_str": source_str, "search_iterations": state["search_iterations"] + 1}

def write_section(state: SectionState, config: RunnableConfig) -> Command[Literal[END, "search_web"]]:
    """Write a section of the report and evaluate if more research is needed.
    
    This node:
    1. Writes section content using search results
    2. Evaluates the quality of the section
    3. Either:
       - Completes the section if quality passes
       - Triggers more research if quality fails
    
    Args:
        state: Current state with search results and section info
        config: Configuration for writing and evaluation
        
    Returns:
        Command to either complete section or do more research
    """

    # Get state 
    topic = state["topic"]
    section = state["section"]
    source_str = state["source_str"]

    # Get configuration
    configurable = Configuration.from_runnable_config(config)

    # Format system instructions
    section_writer_inputs_formatted = section_writer_inputs.format(topic=topic, 
                                                             section_name=section.name, 
                                                             section_topic=section.description, 
                                                             context=source_str, 
                                                             section_content=section.content)

    # Generate section  
    writer_provider = get_config_value(configurable.writer_provider)
    writer_model_name = get_config_value(configurable.writer_model)
    writer_model = init_chat_model(model=writer_model_name, model_provider=writer_provider, temperature=0) 
    section_content = writer_model.invoke([SystemMessage(content=section_writer_instructions),
                                           HumanMessage(content=section_writer_inputs_formatted)])
    
    # Write content to the section object  
    section.content = section_content.content

    # Grade prompt 
    section_grader_message = """Grade the report and consider follow-up questions for missing information.
                               If the grade is 'pass', return empty strings for all follow-up queries.
                               If the grade is 'fail', provide specific search queries to gather missing information."""
    
    section_grader_instructions_formatted = section_grader_instructions.format(topic=topic, 
                                                                               section_topic=section.description,
                                                                               section=section.content, 
                                                                               number_of_follow_up_queries=configurable.number_of_queries)

    # Use planner model for reflection
    planner_provider = get_config_value(configurable.planner_provider)
    planner_model = get_config_value(configurable.planner_model)
    if planner_model == "claude-3-7-sonnet-latest":
        # Allocate a thinking budget for claude-3-7-sonnet-latest as the planner model
        reflection_model = init_chat_model(model=planner_model, 
                                           model_provider=planner_provider, 
                                           max_tokens=20_000, 
                                           thinking={"type": "enabled", "budget_tokens": 16_000}).with_structured_output(Feedback)
    else:
        reflection_model = init_chat_model(model=planner_model, 
                                           model_provider=planner_provider).with_structured_output(Feedback)
    # Generate feedback
    feedback = reflection_model.invoke([SystemMessage(content=section_grader_instructions_formatted),
                                        HumanMessage(content=section_grader_message)])

    # If the section is passing or the max search depth is reached, publish the section to completed sections 
    if feedback.grade == "pass" or state["search_iterations"] >= configurable.max_search_depth:
        # Publish the section to completed sections 
        return  Command(
        update={"completed_sections": [section]},
        goto=END
    )
    # Update the existing section with new content and update search queries
    else:
        return  Command(
        update={"search_queries": feedback.follow_up_queries, "section": section},
        goto="search_web"
        )
    
def write_final_sections(state: SectionState, config: RunnableConfig):
    """Write sections that don't require research using completed sections as context.
    
    This node handles sections like conclusions or summaries that build on
    the researched sections rather than requiring direct research.
    
    Args:
        state: Current state with completed sections as context
        config: Configuration for the writing model
        
    Returns:
        Dict containing the newly written section
    """

    # Get configuration
    configurable = Configuration.from_runnable_config(config)

    # Get state 
    topic = state["topic"]
    section = state["section"]
    completed_report_sections = state["report_sections_from_research"]
    
    # Format system instructions
    system_instructions = final_section_writer_instructions.format(topic=topic, section_name=section.name, section_topic=section.description, context=completed_report_sections)

    # Generate section  
    writer_provider = get_config_value(configurable.writer_provider)
    writer_model_name = get_config_value(configurable.writer_model)
    writer_model = init_chat_model(model=writer_model_name, model_provider=writer_provider, temperature=0) 
    section_content = writer_model.invoke([SystemMessage(content=system_instructions),
                                           HumanMessage(content="Generate a report section based on the provided sources.")])
    
    # Write content to section 
    section.content = section_content.content

    # Write the updated section to completed sections
    return {"completed_sections": [section]}

def gather_completed_sections(state: ReportState):
    """Format completed sections as context for writing final sections.
    
    This node takes all completed research sections and formats them into
    a single context string for writing summary sections.
    
    Args:
        state: Current state with completed sections
        
    Returns:
        Dict with formatted sections as context
    """
    # List of completed sections
    completed_sections = state["completed_sections"]

    # Format completed section to str to use as context for final sections
    completed_report_sections = format_sections(completed_sections)

    return {"report_sections_from_research": completed_report_sections}

def compile_final_report(state: ReportState):
    """Compile all sections into the final report.
    
    This node:
    1. Gets all completed sections
    2. Orders them according to original plan
    3. Combines them into the final report
    
    Args:
        state: Current state with all completed sections
        
    Returns:
        Dict containing the complete report
    """
    # Get sections
    sections = state["sections"]
    completed_sections = {s.name: s.content for s in state["completed_sections"]}

    # Update sections with completed content while maintaining original order
    for section in sections:
        section.content = completed_sections[section.name]

    # Compile final report
    all_sections = "\n\n".join([s.content for s in sections])

    return {"final_report": all_sections}

def initiate_final_section_writing(state: ReportState):
    """Create parallel tasks for writing non-research sections.
    
    This edge function identifies sections that don't need research and
    creates parallel writing tasks for each one.
    
    Args:
        state: Current state with all sections and research context
        
    Returns:
        List of Send commands for parallel section writing
    """
    # Kick off section writing in parallel via Send() API for any sections that do not require research
    return [
        Send("write_final_sections", {"topic": state["topic"], "section": s, "report_sections_from_research": state["report_sections_from_research"]}) 
        for s in state["sections"] 
        if not s.research
    ]

# Report section sub-graph -- 

# Add nodes 
section_builder = StateGraph(SectionState, output=SectionOutputState)
section_builder.add_node("generate_queries", generate_queries)
section_builder.add_node("search_web", search_web)
section_builder.add_node("write_section", write_section)

# Add edges
section_builder.add_edge(START, "generate_queries")
section_builder.add_edge("generate_queries", "search_web")
section_builder.add_edge("search_web", "write_section")

# Outer graph for initial report plan compiling results from each section -- 

# Add nodes
builder = StateGraph(ReportState, input=ReportStateInput, output=ReportStateOutput, config_schema=Configuration)
builder.add_node("generate_report_plan", generate_report_plan)
builder.add_node("human_feedback", human_feedback)
builder.add_node("build_section_with_web_research", section_builder.compile())
builder.add_node("gather_completed_sections", gather_completed_sections)
builder.add_node("write_final_sections", write_final_sections)
builder.add_node("compile_final_report", compile_final_report)

# Add edges
builder.add_edge(START, "generate_report_plan")
builder.add_edge("generate_report_plan", "human_feedback")
builder.add_edge("build_section_with_web_research", "gather_completed_sections")
builder.add_conditional_edges("gather_completed_sections", initiate_final_section_writing, ["write_final_sections"])
builder.add_edge("write_final_sections", "compile_final_report")
builder.add_edge("compile_final_report", END)

graph = builder.compile()

================
File: src/open_deep_research/prompts.py
================
report_planner_query_writer_instructions="""You are performing research for a report. 

<Report topic>
{topic}
</Report topic>

<Report organization>
{report_organization}
</Report organization>

<Task>
Your goal is to generate {number_of_queries} web search queries that will help gather information for planning the report sections. 

The queries should:

1. Be related to the Report topic
2. Help satisfy the requirements specified in the report organization

Make the queries specific enough to find high-quality, relevant sources while covering the breadth needed for the report structure.
</Task>
"""

report_planner_instructions="""I want a plan for a report that is concise and focused.

<Report topic>
The topic of the report is:
{topic}
</Report topic>

<Report organization>
The report should follow this organization: 
{report_organization}
</Report organization>

<Context>
Here is context to use to plan the sections of the report: 
{context}
</Context>

<Task>
Generate a list of sections for the report. Your plan should be tight and focused with NO overlapping sections or unnecessary filler. 

For example, a good report structure might look like:
1/ intro
2/ overview of topic A
3/ overview of topic B
4/ comparison between A and B
5/ conclusion

Each section should have the fields:

- Name - Name for this section of the report.
- Description - Brief overview of the main topics covered in this section.
- Research - Whether to perform web research for this section of the report.
- Content - The content of the section, which you will leave blank for now.

Integration guidelines:
- Include examples and implementation details within main topic sections, not as separate sections
- Ensure each section has a distinct purpose with no content overlap
- Combine related concepts rather than separating them

Before submitting, review your structure to ensure it has no redundant sections and follows a logical flow.
</Task>

<Feedback>
Here is feedback on the report structure from review (if any):
{feedback}
</Feedback>
"""

query_writer_instructions="""You are an expert technical writer crafting targeted web search queries that will gather comprehensive information for writing a technical report section.

<Report topic>
{topic}
</Report topic>

<Section topic>
{section_topic}
</Section topic>

<Task>
Your goal is to generate {number_of_queries} search queries that will help gather comprehensive information above the section topic. 

The queries should:

1. Be related to the topic 
2. Examine different aspects of the topic

Make the queries specific enough to find high-quality, relevant sources.
</Task>
"""

section_writer_instructions = """Write one section of a research report.

<Task>
1. Review the report topic, section name, and section topic carefully.
2. If present, review any existing section content. 
3. Then, look at the provided Source material.
4. Decide the sources that you will use it to write a report section.
5. Write the report section and list your sources. 
</Task>

<Writing Guidelines>
- If existing section content is not populated, write from scratch
- If existing section content is populated, synthesize it with the source material
- Strict 150-200 word limit
- Use simple, clear language
- Use short paragraphs (2-3 sentences max)
- Use ## for section title (Markdown format)
</Writing Guidelines>

<Citation Rules>
- Assign each unique URL a single citation number in your text
- End with ### Sources that lists each source with corresponding numbers
- IMPORTANT: Number sources sequentially without gaps (1,2,3,4...) in the final list regardless of which sources you choose
- Example format:
  [1] Source Title: URL
  [2] Source Title: URL
</Citation Rules>

<Final Check>
1. Verify that EVERY claim is grounded in the provided Source material
2. Confirm each URL appears ONLY ONCE in the Source list
3. Verify that sources are numbered sequentially (1,2,3...) without any gaps
</Final Check>
"""

section_writer_inputs=""" 
<Report topic>
{topic}
</Report topic>

<Section name>
{section_name}
</Section name>

<Section topic>
{section_topic}
</Section topic>

<Existing section content (if populated)>
{section_content}
</Existing section content>

<Source material>
{context}
</Source material>
"""

section_grader_instructions = """Review a report section relative to the specified topic:

<Report topic>
{topic}
</Report topic>

<section topic>
{section_topic}
</section topic>

<section content>
{section}
</section content>

<task>
Evaluate whether the section content adequately addresses the section topic.

If the section content does not adequately address the section topic, generate {number_of_follow_up_queries} follow-up search queries to gather missing information.
</task>

<format>
    grade: Literal["pass","fail"] = Field(
        description="Evaluation result indicating whether the response meets requirements ('pass') or needs revision ('fail')."
    )
    follow_up_queries: List[SearchQuery] = Field(
        description="List of follow-up search queries.",
    )
</format>
"""

final_section_writer_instructions="""You are an expert technical writer crafting a section that synthesizes information from the rest of the report.

<Report topic>
{topic}
</Report topic>

<Section name>
{section_name}
</Section name>

<Section topic> 
{section_topic}
</Section topic>

<Available report content>
{context}
</Available report content>

<Task>
1. Section-Specific Approach:

For Introduction:
- Use # for report title (Markdown format)
- 50-100 word limit
- Write in simple and clear language
- Focus on the core motivation for the report in 1-2 paragraphs
- Use a clear narrative arc to introduce the report
- Include NO structural elements (no lists or tables)
- No sources section needed

For Conclusion/Summary:
- Use ## for section title (Markdown format)
- 100-150 word limit
- For comparative reports:
    * Must include a focused comparison table using Markdown table syntax
    * Table should distill insights from the report
    * Keep table entries clear and concise
- For non-comparative reports: 
    * Only use ONE structural element IF it helps distill the points made in the report:
    * Either a focused table comparing items present in the report (using Markdown table syntax)
    * Or a short list using proper Markdown list syntax:
      - Use `*` or `-` for unordered lists
      - Use `1.` for ordered lists
      - Ensure proper indentation and spacing
- End with specific next steps or implications
- No sources section needed

3. Writing Approach:
- Use concrete details over general statements
- Make every word count
- Focus on your single most important point
</Task>

<Quality Checks>
- For introduction: 50-100 word limit, # for report title, no structural elements, no sources section
- For conclusion: 100-150 word limit, ## for section title, only ONE structural element at most, no sources section
- Markdown format
- Do not include word count or any preamble in your response
</Quality Checks>"""

================
File: src/open_deep_research/state.py
================
from typing import Annotated, List, TypedDict, Literal
from pydantic import BaseModel, Field
import operator

class Section(BaseModel):
    name: str = Field(
        description="Name for this section of the report.",
    )
    description: str = Field(
        description="Brief overview of the main topics and concepts to be covered in this section.",
    )
    research: bool = Field(
        description="Whether to perform web research for this section of the report."
    )
    content: str = Field(
        description="The content of the section."
    )   

class Sections(BaseModel):
    sections: List[Section] = Field(
        description="Sections of the report.",
    )

class SearchQuery(BaseModel):
    search_query: str = Field(None, description="Query for web search.")

class Queries(BaseModel):
    queries: List[SearchQuery] = Field(
        description="List of search queries.",
    )

class Feedback(BaseModel):
    grade: Literal["pass","fail"] = Field(
        description="Evaluation result indicating whether the response meets requirements ('pass') or needs revision ('fail')."
    )
    follow_up_queries: List[SearchQuery] = Field(
        description="List of follow-up search queries.",
    )

class ReportStateInput(TypedDict):
    topic: str # Report topic
    
class ReportStateOutput(TypedDict):
    final_report: str # Final report

class ReportState(TypedDict):
    topic: str # Report topic    
    feedback_on_report_plan: str # Feedback on the report plan
    sections: list[Section] # List of report sections 
    completed_sections: Annotated[list, operator.add] # Send() API key
    report_sections_from_research: str # String of any completed sections from research to write final sections
    final_report: str # Final report

class SectionState(TypedDict):
    topic: str # Report topic
    section: Section # Report section  
    search_iterations: int # Number of search iterations done
    search_queries: list[SearchQuery] # List of search queries
    source_str: str # String of formatted source content from web search
    report_sections_from_research: str # String of any completed sections from research to write final sections
    completed_sections: list[Section] # Final key we duplicate in outer state for Send() API

class SectionOutputState(TypedDict):
    completed_sections: list[Section] # Final key we duplicate in outer state for Send() API

================
File: src/open_deep_research/utils.py
================
import os
import asyncio
import requests
from typing import List, Optional, Dict, Any

from exa_py import Exa
from linkup import LinkupClient
from tavily import AsyncTavilyClient

from langchain_community.retrievers import ArxivRetriever
from langchain_community.utilities.pubmed import PubMedAPIWrapper
from langsmith import traceable

from open_deep_research.state import Section

def get_config_value(value):
    """
    Helper function to handle both string and enum cases of configuration values
    """
    return value if isinstance(value, str) else value.value

def get_search_params(search_api: str, search_api_config: Optional[Dict[str, Any]]) -> Dict[str, Any]:
    """
    Filters the search_api_config dictionary to include only parameters accepted by the specified search API.

    Args:
        search_api (str): The search API identifier (e.g., "exa", "tavily").
        search_api_config (Optional[Dict[str, Any]]): The configuration dictionary for the search API.

    Returns:
        Dict[str, Any]: A dictionary of parameters to pass to the search function.
    """
    # Define accepted parameters for each search API
    SEARCH_API_PARAMS = {
        "exa": ["max_characters", "num_results", "include_domains", "exclude_domains", "subpages"],
        "tavily": [],  # Tavily currently accepts no additional parameters
        "perplexity": [],  # Perplexity accepts no additional parameters
        "arxiv": ["load_max_docs", "get_full_documents", "load_all_available_meta"],
        "pubmed": ["top_k_results", "email", "api_key", "doc_content_chars_max"],
        "linkup": ["depth"],
    }

    # Get the list of accepted parameters for the given search API
    accepted_params = SEARCH_API_PARAMS.get(search_api, [])

    # If no config provided, return an empty dict
    if not search_api_config:
        return {}

    # Filter the config to only include accepted parameters
    return {k: v for k, v in search_api_config.items() if k in accepted_params}

def deduplicate_and_format_sources(search_response, max_tokens_per_source, include_raw_content=True):
    """
    Takes a list of search responses and formats them into a readable string.
    Limits the raw_content to approximately max_tokens_per_source tokens.
 
    Args:
        search_responses: List of search response dicts, each containing:
            - query: str
            - results: List of dicts with fields:
                - title: str
                - url: str
                - content: str
                - score: float
                - raw_content: str|None
        max_tokens_per_source: int
        include_raw_content: bool
            
    Returns:
        str: Formatted string with deduplicated sources
    """
     # Collect all results
    sources_list = []
    for response in search_response:
        sources_list.extend(response['results'])
    
    # Deduplicate by URL
    unique_sources = {source['url']: source for source in sources_list}

    # Format output
    formatted_text = "Content from sources:\n"
    for i, source in enumerate(unique_sources.values(), 1):
        formatted_text += f"{'='*80}\n"  # Clear section separator
        formatted_text += f"Source: {source['title']}\n"
        formatted_text += f"{'-'*80}\n"  # Subsection separator
        formatted_text += f"URL: {source['url']}\n===\n"
        formatted_text += f"Most relevant content from source: {source['content']}\n===\n"
        if include_raw_content:
            # Using rough estimate of 4 characters per token
            char_limit = max_tokens_per_source * 4
            # Handle None raw_content
            raw_content = source.get('raw_content', '')
            if raw_content is None:
                raw_content = ''
                print(f"Warning: No raw_content found for source {source['url']}")
            if len(raw_content) > char_limit:
                raw_content = raw_content[:char_limit] + "... [truncated]"
            formatted_text += f"Full source content limited to {max_tokens_per_source} tokens: {raw_content}\n\n"
        formatted_text += f"{'='*80}\n\n" # End section separator
                
    return formatted_text.strip()

def format_sections(sections: list[Section]) -> str:
    """ Format a list of sections into a string """
    formatted_str = ""
    for idx, section in enumerate(sections, 1):
        formatted_str += f"""
{'='*60}
Section {idx}: {section.name}
{'='*60}
Description:
{section.description}
Requires Research: 
{section.research}

Content:
{section.content if section.content else '[Not yet written]'}

"""
    return formatted_str

@traceable
async def tavily_search_async(search_queries):
    """
    Performs concurrent web searches using the Tavily API.

    Args:
        search_queries (List[SearchQuery]): List of search queries to process

    Returns:
            List[dict]: List of search responses from Tavily API, one per query. Each response has format:
                {
                    'query': str, # The original search query
                    'follow_up_questions': None,      
                    'answer': None,
                    'images': list,
                    'results': [                     # List of search results
                        {
                            'title': str,            # Title of the webpage
                            'url': str,              # URL of the result
                            'content': str,          # Summary/snippet of content
                            'score': float,          # Relevance score
                            'raw_content': str|None  # Full page content if available
                        },
                        ...
                    ]
                }
    """
    tavily_async_client = AsyncTavilyClient()
    search_tasks = []
    for query in search_queries:
            search_tasks.append(
                tavily_async_client.search(
                    query,
                    max_results=5,
                    include_raw_content=True,
                    topic="general"
                )
            )

    # Execute all searches concurrently
    search_docs = await asyncio.gather(*search_tasks)

    return search_docs

@traceable
def perplexity_search(search_queries):
    """Search the web using the Perplexity API.
    
    Args:
        search_queries (List[SearchQuery]): List of search queries to process
  
    Returns:
        List[dict]: List of search responses from Perplexity API, one per query. Each response has format:
            {
                'query': str,                    # The original search query
                'follow_up_questions': None,      
                'answer': None,
                'images': list,
                'results': [                     # List of search results
                    {
                        'title': str,            # Title of the search result
                        'url': str,              # URL of the result
                        'content': str,          # Summary/snippet of content
                        'score': float,          # Relevance score
                        'raw_content': str|None  # Full content or None for secondary citations
                    },
                    ...
                ]
            }
    """

    headers = {
        "accept": "application/json",
        "content-type": "application/json",
        "Authorization": f"Bearer {os.getenv('PERPLEXITY_API_KEY')}"
    }
    
    search_docs = []
    for query in search_queries:

        payload = {
            "model": "sonar-pro",
            "messages": [
                {
                    "role": "system",
                    "content": "Search the web and provide factual information with sources."
                },
                {
                    "role": "user",
                    "content": query
                }
            ]
        }
        
        response = requests.post(
            "https://api.perplexity.ai/chat/completions",
            headers=headers,
            json=payload
        )
        response.raise_for_status()  # Raise exception for bad status codes
        
        # Parse the response
        data = response.json()
        content = data["choices"][0]["message"]["content"]
        citations = data.get("citations", ["https://perplexity.ai"])
        
        # Create results list for this query
        results = []
        
        # First citation gets the full content
        results.append({
            "title": f"Perplexity Search, Source 1",
            "url": citations[0],
            "content": content,
            "raw_content": content,
            "score": 1.0  # Adding score to match Tavily format
        })
        
        # Add additional citations without duplicating content
        for i, citation in enumerate(citations[1:], start=2):
            results.append({
                "title": f"Perplexity Search, Source {i}",
                "url": citation,
                "content": "See primary source for full content",
                "raw_content": None,
                "score": 0.5  # Lower score for secondary sources
            })
        
        # Format response to match Tavily structure
        search_docs.append({
            "query": query,
            "follow_up_questions": None,
            "answer": None,
            "images": [],
            "results": results
        })
    
    return search_docs

@traceable
async def exa_search(search_queries, max_characters: Optional[int] = None, num_results=5, 
                     include_domains: Optional[List[str]] = None, 
                     exclude_domains: Optional[List[str]] = None,
                     subpages: Optional[int] = None):
    """Search the web using the Exa API.
    
    Args:
        search_queries (List[SearchQuery]): List of search queries to process
        max_characters (int, optional): Maximum number of characters to retrieve for each result's raw content.
                                       If None, the text parameter will be set to True instead of an object.
        num_results (int): Number of search results per query. Defaults to 5.
        include_domains (List[str], optional): List of domains to include in search results. 
            When specified, only results from these domains will be returned.
        exclude_domains (List[str], optional): List of domains to exclude from search results.
            Cannot be used together with include_domains.
        subpages (int, optional): Number of subpages to retrieve per result. If None, subpages are not retrieved.
        
    Returns:
        List[dict]: List of search responses from Exa API, one per query. Each response has format:
            {
                'query': str,                    # The original search query
                'follow_up_questions': None,      
                'answer': None,
                'images': list,
                'results': [                     # List of search results
                    {
                        'title': str,            # Title of the search result
                        'url': str,              # URL of the result
                        'content': str,          # Summary/snippet of content
                        'score': float,          # Relevance score
                        'raw_content': str|None  # Full content or None for secondary citations
                    },
                    ...
                ]
            }
    """
    # Check that include_domains and exclude_domains are not both specified
    if include_domains and exclude_domains:
        raise ValueError("Cannot specify both include_domains and exclude_domains")
    
    # Initialize Exa client (API key should be configured in your .env file)
    exa = Exa(api_key = f"{os.getenv('EXA_API_KEY')}")
    
    # Define the function to process a single query
    async def process_query(query):
        # Use run_in_executor to make the synchronous exa call in a non-blocking way
        loop = asyncio.get_event_loop()
        
        # Define the function for the executor with all parameters
        def exa_search_fn():
            # Build parameters dictionary
            kwargs = {
                # Set text to True if max_characters is None, otherwise use an object with max_characters
                "text": True if max_characters is None else {"max_characters": max_characters},
                "summary": True,  # This is an amazing feature by EXA. It provides an AI generated summary of the content based on the query
                "num_results": num_results
            }
            
            # Add optional parameters only if they are provided
            if subpages is not None:
                kwargs["subpages"] = subpages
                
            if include_domains:
                kwargs["include_domains"] = include_domains
            elif exclude_domains:
                kwargs["exclude_domains"] = exclude_domains
                
            return exa.search_and_contents(query, **kwargs)
        
        response = await loop.run_in_executor(None, exa_search_fn)
        
        # Format the response to match the expected output structure
        formatted_results = []
        seen_urls = set()  # Track URLs to avoid duplicates
        
        # Helper function to safely get value regardless of if item is dict or object
        def get_value(item, key, default=None):
            if isinstance(item, dict):
                return item.get(key, default)
            else:
                return getattr(item, key, default) if hasattr(item, key) else default
        
        # Access the results from the SearchResponse object
        results_list = get_value(response, 'results', [])
        
        # First process all main results
        for result in results_list:
            # Get the score with a default of 0.0 if it's None or not present
            score = get_value(result, 'score', 0.0)
            
            # Combine summary and text for content if both are available
            text_content = get_value(result, 'text', '')
            summary_content = get_value(result, 'summary', '')
            
            content = text_content
            if summary_content:
                if content:
                    content = f"{summary_content}\n\n{content}"
                else:
                    content = summary_content
            
            title = get_value(result, 'title', '')
            url = get_value(result, 'url', '')
            
            # Skip if we've seen this URL before (removes duplicate entries)
            if url in seen_urls:
                continue
                
            seen_urls.add(url)
            
            # Main result entry
            result_entry = {
                "title": title,
                "url": url,
                "content": content,
                "score": score,
                "raw_content": text_content
            }
            
            # Add the main result to the formatted results
            formatted_results.append(result_entry)
        
        # Now process subpages only if the subpages parameter was provided
        if subpages is not None:
            for result in results_list:
                subpages_list = get_value(result, 'subpages', [])
                for subpage in subpages_list:
                    # Get subpage score
                    subpage_score = get_value(subpage, 'score', 0.0)
                    
                    # Combine summary and text for subpage content
                    subpage_text = get_value(subpage, 'text', '')
                    subpage_summary = get_value(subpage, 'summary', '')
                    
                    subpage_content = subpage_text
                    if subpage_summary:
                        if subpage_content:
                            subpage_content = f"{subpage_summary}\n\n{subpage_content}"
                        else:
                            subpage_content = subpage_summary
                    
                    subpage_url = get_value(subpage, 'url', '')
                    
                    # Skip if we've seen this URL before
                    if subpage_url in seen_urls:
                        continue
                        
                    seen_urls.add(subpage_url)
                    
                    formatted_results.append({
                        "title": get_value(subpage, 'title', ''),
                        "url": subpage_url,
                        "content": subpage_content,
                        "score": subpage_score,
                        "raw_content": subpage_text
                    })
        
        # Collect images if available (only from main results to avoid duplication)
        images = []
        for result in results_list:
            image = get_value(result, 'image')
            if image and image not in images:  # Avoid duplicate images
                images.append(image)
                
        return {
            "query": query,
            "follow_up_questions": None,
            "answer": None,
            "images": images,
            "results": formatted_results
        }
    
    # Process all queries sequentially with delay to respect rate limit
    search_docs = []
    for i, query in enumerate(search_queries):
        try:
            # Add delay between requests (0.25s = 4 requests per second, well within the 5/s limit)
            if i > 0:  # Don't delay the first request
                await asyncio.sleep(0.25)
            
            result = await process_query(query)
            search_docs.append(result)
        except Exception as e:
            # Handle exceptions gracefully
            print(f"Error processing query '{query}': {str(e)}")
            # Add a placeholder result for failed queries to maintain index alignment
            search_docs.append({
                "query": query,
                "follow_up_questions": None,
                "answer": None,
                "images": [],
                "results": [],
                "error": str(e)
            })
            
            # Add additional delay if we hit a rate limit error
            if "429" in str(e):
                print("Rate limit exceeded. Adding additional delay...")
                await asyncio.sleep(1.0)  # Add a longer delay if we hit a rate limit
    
    return search_docs

@traceable
async def arxiv_search_async(search_queries, load_max_docs=5, get_full_documents=True, load_all_available_meta=True):
    """
    Performs concurrent searches on arXiv using the ArxivRetriever.

    Args:
        search_queries (List[str]): List of search queries or article IDs
        load_max_docs (int, optional): Maximum number of documents to return per query. Default is 5.
        get_full_documents (bool, optional): Whether to fetch full text of documents. Default is True.
        load_all_available_meta (bool, optional): Whether to load all available metadata. Default is True.

    Returns:
        List[dict]: List of search responses from arXiv, one per query. Each response has format:
            {
                'query': str,                    # The original search query
                'follow_up_questions': None,      
                'answer': None,
                'images': [],
                'results': [                     # List of search results
                    {
                        'title': str,            # Title of the paper
                        'url': str,              # URL (Entry ID) of the paper
                        'content': str,          # Formatted summary with metadata
                        'score': float,          # Relevance score (approximated)
                        'raw_content': str|None  # Full paper content if available
                    },
                    ...
                ]
            }
    """
    
    async def process_single_query(query):
        try:
            # Create retriever for each query
            retriever = ArxivRetriever(
                load_max_docs=load_max_docs,
                get_full_documents=get_full_documents,
                load_all_available_meta=load_all_available_meta
            )
            
            # Run the synchronous retriever in a thread pool
            loop = asyncio.get_event_loop()
            docs = await loop.run_in_executor(None, lambda: retriever.invoke(query))
            
            results = []
            # Assign decreasing scores based on the order
            base_score = 1.0
            score_decrement = 1.0 / (len(docs) + 1) if docs else 0
            
            for i, doc in enumerate(docs):
                # Extract metadata
                metadata = doc.metadata
                
                # Use entry_id as the URL (this is the actual arxiv link)
                url = metadata.get('entry_id', '')
                
                # Format content with all useful metadata
                content_parts = []

                # Primary information
                if 'Summary' in metadata:
                    content_parts.append(f"Summary: {metadata['Summary']}")

                if 'Authors' in metadata:
                    content_parts.append(f"Authors: {metadata['Authors']}")

                # Add publication information
                published = metadata.get('Published')
                published_str = published.isoformat() if hasattr(published, 'isoformat') else str(published) if published else ''
                if published_str:
                    content_parts.append(f"Published: {published_str}")

                # Add additional metadata if available
                if 'primary_category' in metadata:
                    content_parts.append(f"Primary Category: {metadata['primary_category']}")

                if 'categories' in metadata and metadata['categories']:
                    content_parts.append(f"Categories: {', '.join(metadata['categories'])}")

                if 'comment' in metadata and metadata['comment']:
                    content_parts.append(f"Comment: {metadata['comment']}")

                if 'journal_ref' in metadata and metadata['journal_ref']:
                    content_parts.append(f"Journal Reference: {metadata['journal_ref']}")

                if 'doi' in metadata and metadata['doi']:
                    content_parts.append(f"DOI: {metadata['doi']}")

                # Get PDF link if available in the links
                pdf_link = ""
                if 'links' in metadata and metadata['links']:
                    for link in metadata['links']:
                        if 'pdf' in link:
                            pdf_link = link
                            content_parts.append(f"PDF: {pdf_link}")
                            break

                # Join all content parts with newlines 
                content = "\n".join(content_parts)
                
                result = {
                    'title': metadata.get('Title', ''),
                    'url': url,  # Using entry_id as the URL
                    'content': content,
                    'score': base_score - (i * score_decrement),
                    'raw_content': doc.page_content if get_full_documents else None
                }
                results.append(result)
                
            return {
                'query': query,
                'follow_up_questions': None,
                'answer': None,
                'images': [],
                'results': results
            }
        except Exception as e:
            # Handle exceptions gracefully
            print(f"Error processing arXiv query '{query}': {str(e)}")
            return {
                'query': query,
                'follow_up_questions': None,
                'answer': None,
                'images': [],
                'results': [],
                'error': str(e)
            }
    
    # Process queries sequentially with delay to respect arXiv rate limit (1 request per 3 seconds)
    search_docs = []
    for i, query in enumerate(search_queries):
        try:
            # Add delay between requests (3 seconds per ArXiv's rate limit)
            if i > 0:  # Don't delay the first request
                await asyncio.sleep(3.0)
            
            result = await process_single_query(query)
            search_docs.append(result)
        except Exception as e:
            # Handle exceptions gracefully
            print(f"Error processing arXiv query '{query}': {str(e)}")
            search_docs.append({
                'query': query,
                'follow_up_questions': None,
                'answer': None,
                'images': [],
                'results': [],
                'error': str(e)
            })
            
            # Add additional delay if we hit a rate limit error
            if "429" in str(e) or "Too Many Requests" in str(e):
                print("ArXiv rate limit exceeded. Adding additional delay...")
                await asyncio.sleep(5.0)  # Add a longer delay if we hit a rate limit
    
    return search_docs

@traceable
async def pubmed_search_async(search_queries, top_k_results=5, email=None, api_key=None, doc_content_chars_max=4000):
    """
    Performs concurrent searches on PubMed using the PubMedAPIWrapper.

    Args:
        search_queries (List[str]): List of search queries
        top_k_results (int, optional): Maximum number of documents to return per query. Default is 5.
        email (str, optional): Email address for PubMed API. Required by NCBI.
        api_key (str, optional): API key for PubMed API for higher rate limits.
        doc_content_chars_max (int, optional): Maximum characters for document content. Default is 4000.

    Returns:
        List[dict]: List of search responses from PubMed, one per query. Each response has format:
            {
                'query': str,                    # The original search query
                'follow_up_questions': None,      
                'answer': None,
                'images': [],
                'results': [                     # List of search results
                    {
                        'title': str,            # Title of the paper
                        'url': str,              # URL to the paper on PubMed
                        'content': str,          # Formatted summary with metadata
                        'score': float,          # Relevance score (approximated)
                        'raw_content': str       # Full abstract content
                    },
                    ...
                ]
            }
    """
    
    async def process_single_query(query):
        try:
            # print(f"Processing PubMed query: '{query}'")
            
            # Create PubMed wrapper for the query
            wrapper = PubMedAPIWrapper(
                top_k_results=top_k_results,
                doc_content_chars_max=doc_content_chars_max,
                email=email if email else "your_email@example.com",
                api_key=api_key if api_key else ""
            )
            
            # Run the synchronous wrapper in a thread pool
            loop = asyncio.get_event_loop()
            
            # Use wrapper.lazy_load instead of load to get better visibility
            docs = await loop.run_in_executor(None, lambda: list(wrapper.lazy_load(query)))
            
            print(f"Query '{query}' returned {len(docs)} results")
            
            results = []
            # Assign decreasing scores based on the order
            base_score = 1.0
            score_decrement = 1.0 / (len(docs) + 1) if docs else 0
            
            for i, doc in enumerate(docs):
                # Format content with metadata
                content_parts = []
                
                if doc.get('Published'):
                    content_parts.append(f"Published: {doc['Published']}")
                
                if doc.get('Copyright Information'):
                    content_parts.append(f"Copyright Information: {doc['Copyright Information']}")
                
                if doc.get('Summary'):
                    content_parts.append(f"Summary: {doc['Summary']}")
                
                # Generate PubMed URL from the article UID
                uid = doc.get('uid', '')
                url = f"https://pubmed.ncbi.nlm.nih.gov/{uid}/" if uid else ""
                
                # Join all content parts with newlines
                content = "\n".join(content_parts)
                
                result = {
                    'title': doc.get('Title', ''),
                    'url': url,
                    'content': content,
                    'score': base_score - (i * score_decrement),
                    'raw_content': doc.get('Summary', '')
                }
                results.append(result)
            
            return {
                'query': query,
                'follow_up_questions': None,
                'answer': None,
                'images': [],
                'results': results
            }
        except Exception as e:
            # Handle exceptions with more detailed information
            error_msg = f"Error processing PubMed query '{query}': {str(e)}"
            print(error_msg)
            import traceback
            print(traceback.format_exc())  # Print full traceback for debugging
            
            return {
                'query': query,
                'follow_up_questions': None,
                'answer': None,
                'images': [],
                'results': [],
                'error': str(e)
            }
    
    # Process all queries with a reasonable delay between them
    search_docs = []
    
    # Start with a small delay that increases if we encounter rate limiting
    delay = 1.0  # Start with a more conservative delay
    
    for i, query in enumerate(search_queries):
        try:
            # Add delay between requests
            if i > 0:  # Don't delay the first request
                # print(f"Waiting {delay} seconds before next query...")
                await asyncio.sleep(delay)
            
            result = await process_single_query(query)
            search_docs.append(result)
            
            # If query was successful with results, we can slightly reduce delay (but not below minimum)
            if result.get('results') and len(result['results']) > 0:
                delay = max(0.5, delay * 0.9)  # Don't go below 0.5 seconds
            
        except Exception as e:
            # Handle exceptions gracefully
            error_msg = f"Error in main loop processing PubMed query '{query}': {str(e)}"
            print(error_msg)
            
            search_docs.append({
                'query': query,
                'follow_up_questions': None,
                'answer': None,
                'images': [],
                'results': [],
                'error': str(e)
            })
            
            # If we hit an exception, increase delay for next query
            delay = min(5.0, delay * 1.5)  # Don't exceed 5 seconds
    
    return search_docs

@traceable
async def linkup_search(search_queries, depth: Optional[str] = "standard"):
    """
    Performs concurrent web searches using the Linkup API.

    Args:
        search_queries (List[SearchQuery]): List of search queries to process
        depth (str, optional): "standard" (default)  or "deep". More details here https://docs.linkup.so/pages/documentation/get-started/concepts

    Returns:
        List[dict]: List of search responses from Linkup API, one per query. Each response has format:
            {
                'results': [            # List of search results
                    {
                        'title': str,   # Title of the search result
                        'url': str,     # URL of the result
                        'content': str, # Summary/snippet of content
                    },
                    ...
                ]
            }
    """
    client = LinkupClient()
    search_tasks = []
    for query in search_queries:
        search_tasks.append(
                client.async_search(
                    query,
                    depth,
                    output_type="searchResults",
                )
            )

    search_results = []
    for response in await asyncio.gather(*search_tasks):
        search_results.append(
            {
                "results": [
                    {"title": result.name, "url": result.url, "content": result.content}
                    for result in response.results
                ],
            }
        )

    return search_results

async def select_and_execute_search(search_api: str, query_list: list[str], params_to_pass: dict) -> str:
    """Select and execute the appropriate search API.
    
    Args:
        search_api: Name of the search API to use
        query_list: List of search queries to execute
        params_to_pass: Parameters to pass to the search API
        
    Returns:
        Formatted string containing search results
        
    Raises:
        ValueError: If an unsupported search API is specified
    """
    if search_api == "tavily":
        search_results = await tavily_search_async(query_list, **params_to_pass)
        return deduplicate_and_format_sources(search_results, max_tokens_per_source=4000, include_raw_content=False)
    elif search_api == "perplexity":
        search_results = perplexity_search(query_list, **params_to_pass)
        return deduplicate_and_format_sources(search_results, max_tokens_per_source=4000)
    elif search_api == "exa":
        search_results = await exa_search(query_list, **params_to_pass)
        return deduplicate_and_format_sources(search_results, max_tokens_per_source=4000)
    elif search_api == "arxiv":
        search_results = await arxiv_search_async(query_list, **params_to_pass)
        return deduplicate_and_format_sources(search_results, max_tokens_per_source=4000)
    elif search_api == "pubmed":
        search_results = await pubmed_search_async(query_list, **params_to_pass)
        return deduplicate_and_format_sources(search_results, max_tokens_per_source=4000)
    elif search_api == "linkup":
        search_results = await linkup_search(query_list, **params_to_pass)
        return deduplicate_and_format_sources(search_results, max_tokens_per_source=4000)
    else:
        raise ValueError(f"Unsupported search API: {search_api}")



================================================================
End of Codebase
================================================================
